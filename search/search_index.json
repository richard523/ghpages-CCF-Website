{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"Livestream/","title":"Livestream Event","text":"<p>Our upcoming experts panel event on the Neuroethics of Whole Brain Emulation is on Sunday, June 30, 2024 at 10 am PDT (1 pm EDT, 19:00 CET).</p> <p>To participate in the event live, please join the Google Meet session at http://meet.google.com/apd-juyw-fby</p> <p>Audience participation is possible during Q&amp;A intervals after each topic.</p> <p>Visit our Ethics site at https://sites.google.com/carboncopies.org/ethics for more information.</p> <p>For more information about past events, please visit our event page page.</p> <p>Please stay informed by joining us on Facebook, Twitter, and more, see our contact page.</p>"},{"location":"About/DueDiligence/","title":"Due Diligence services","text":"<p>Are you considering funding, supporting or investing in a project or startup company pitching technology development in the domain of whole brain emulation (WBE) or related brain-computer interface (BCI) and other neurotech technologies?</p> <p>Are you in the process of carrying out your due diligence research to evaluate the pitch?</p> <p>Are you a press organization or journalist, and you are conducting research for an article or media project about a cutting-edge startup, science project or highly ambitious proposal?</p> <p>The Carboncopies Foundation is the only organization dedicated to the full extent of the field, from its metaphysical presuppositions and implications, through data collection technologies, to neuronal modeling and system functionalization, ethical considerations, and the world-wide network of leading experts and institutions involved. We have been doing this since 2010 and our researchers have scientific and technical qualifications and insight focused on all aspects of whole brain emulation.</p> <p>As a 501(c)(3) non-profit education and research foundation, our mission demands that we fully support any and all efforts to advance the field and to achieve whole brain emulation. We are happy to work with you to fully evaluate concepts, proposals, teams and pitches to achieve unbiased, scientifically competent and confidential insight.</p> <p>In many cases, these services are provided free of charge, as part of our research and education mission.</p> <p>We welcome your due diligence inquiries. Reach out to us through contact@carboncopies.org.</p>"},{"location":"About/DueDiligence/#associated-domains","title":"Associated Domains","text":"<p>The Carboncopies Foundation owns and operates the following domains:</p> <ul> <li>carboncopies.org</li> <li>braingenix.org</li> </ul>"},{"location":"About/FAQ/","title":"Your Questions are Welcome!","text":"<p>Don't see your question about whole brain emulation, mind uploading, neural prosthesis, neural interfaces, etc, answered in the FAQ below? Please send us your question at questions@carboncopies.org.</p>"},{"location":"About/FAQ/#what-is-the-difference-between-whole-brain-emulation-and-mind-uploading","title":"What is the difference between whole brain emulation and mind uploading?","text":"<p>Mind uploading / uploaded mind: Cognitive processes that switch from taking place in a biological brain to functioning in an engineered, artificial brain. The term is a conceptual description of a possibility.</p> <p>Whole brain emulation: A technological protocol that may someday be able to reverse-engineer a biological brain in order to functionally emulate neurobiological processes on a different substrate (or \"platform\"). Emulation will be done in a way that will generate the cognitive experience that was achieved by the original brain.</p> <p>To learn more, see our blog post on Whole Brain Emulation.</p>"},{"location":"About/FAQ/#what-does-it-mean-for-a-mind-to-be-substrate-independent-a-sim","title":"What does it mean for a mind to be substrate-independent (a SIM)?","text":"<p>Empirical evidence in neuroscience supports the scientific theory that mental experience is generated through the neurobiological mechanisms of the nervous system.</p> <p>If neural function can be recreated in a different, non-biological substrate while still producing the same meaningful results as in the original implementation, mental experience no longer depends on a single biological substrate. In that sense, the processes of the mind are then substrate-independent. Where the terms substrate-independent are insufficiently precise, we might instead say that the functions are 'portable onto multiple implementation platforms' or 'implementable in multiple operating substrates'.</p> <p>Other operating substrates could possibly include software or hardware implementations. A software implementation could run on a digital computer, whereas a hardware implementation could be driven by application-specific integrated circuits (ASICs), possibly resulting in an architecture that resembles neuromorphic chips. Most likely, there are effective implementations that have not yet been conceived of.</p> <p>The idea that mental functions can be replicated is supported by empirical evidence. Mental functions operate on signal patterns that are generated in all modes of cognitive activity, e.g. by our senses, during memory retrieval, and during goal-oriented or conscious behavior. Targeted manipulations of the biophysical processes in neural tissue produce specific changes in these signal patterns, which in turn lead to specific changes in behavior or experience. The biophysical processes and signal operations can be described in terms of classical physics and expressed as information-processing equations. The resulting set of equations can be carried out in a computational model, which can be implemented in a multitude of ways.</p> <p>We propose that there is a separation of scales for the functions of the mind. Replacing the implementation substrate is subjectively undetectable and acceptable. The nuanced arguments in this matter involve considerations such as predicting a plausible range of responses for a complex system and allowing for variability below the detection threshold or a chosen threshold (which can allow a multi-scale problem to reduce to a separation of scales problem).</p> <p>Alternative operating substrates can have advantageous characteristics. For example: for new capabilities, they can greatly simplify direct monitoring of, interaction with, and modification of any aspect of any function of the mind; for reliability and safety, they can facilitate making backup copies of mental state; for improved performance, they can enable increased processing speeds.</p>"},{"location":"About/FAQ/#how-is-sim-related-to-ideas-about-mind-uploading","title":"How is SIM related to ideas about mind uploading?","text":"<p>The popular term \"mind uploading\" is the hypothetical process of copying mental characteristics (functions of mind, including long-term memory and the experience of identity) from a particular brain to some other device where the mind can continue to function. This implies the creation of substrate-independent functions of the mind, a substrate-independent mind (SIM).</p> <p>In science fiction, the term \u201cmind uploading\u201d is sometimes used in a slightly different context. It is meant to imply that the necessary data for a SIM is obtained from a brain to be stored as a backup, but without the implementation of an artificial brain for the SIM to function.</p> <p>The detailed process involved in the implementation of a substrate-independent mind onto an artificial brain is called whole brain emulation (WBE). This process spans from data collection to the interpretation of the data as a functional model for the SIM.</p>"},{"location":"About/FAQ/#what-is-whole-brain-emulation-wbe","title":"What is whole brain emulation? (WBE)","text":"<p>Whole brain emulation (WBE) is the technical process by which a substrate-independent mind (SIM) is derived from the neurobiology of a brain and expressed as a working model for an artificial brain. It is a reverse-engineering of the brain.</p> <p>To emulate a whole brain it is necessary to know at least the neural circuit map (also known as the connectome), local dynamic response functions (typically observed through electrophysiology), and local functions governing changes in circuit structure or response functions (\u201cmemory\u201d).</p> <p>The same knowledge (and the associated data acquisition and interpretation) is essential to efforts in fundamental brain research, research and development for clinical neurotechnology, new directions in artificial intelligence, and much more. A number of prominent academic projects are dedicated to whole brain circuit mapping (e.g. the Human Brain Project) and whole brain activity mapping (e.g. the Brain Initiative). In academic parlance, the shorter term \u201cbrain emulation\u201d is sometimes used.</p>"},{"location":"About/FAQ/#how-is-neural-prosthesis-related-to-whole-brain-emulation","title":"How is neural prosthesis related to whole brain emulation?","text":"<p>The requirements for whole brain emulation are almost identical to the requirements for the creation of accurate and medically useful cognitive neural prosthetic devices, such as the hippocampal neural prosthesis being developed at the University of Southern California.</p> <p>A highly accurate and patient-specific neural prosthesis could be called a partial brain emulation, and a whole brain emulation could be called a full-brain neural prosthesis or a complete collection of patient-specific neural prostheses.</p> <p>When a neural prosthesis is not patient-specific to a significant degree, such as a retinal prosthesis that the visual system learns to use, there are still many domains of research and development that overlap with those for whole brain emulation - although the relationship is less direct.</p>"},{"location":"About/FAQ/#how-can-mind-uploading-via-whole-brain-emulation-be-accomplished","title":"How can mind uploading via whole brain emulation be accomplished?","text":"<p>At present, two primary conceptual approaches have been proposed:</p> <ol> <li>WBE from neural prosthesis: Gradually replace each small piece of a brain with a highly accurate patient-specific neuroprosthetic device until every part of that brain has been replaced, at which point the entire brain (possibly still residing within the skull) is artificial.</li> <li>WBE from preserved brain: Carefully preserve a biological brain, cut it into many extremely small sections, analyze each section and use the information obtained to reconstruct a working artificial brain.</li> </ol> <p>The same two approaches are presented as a series of successive steps in the following diagram panels:  </p>"},{"location":"About/FAQ/#is-it-even-possible-to-store-brain-information-in-order-to-transfer-it","title":"Is it even possible to store brain information in order to transfer it?","text":"<p>Yes. Any information can be stored. Information is information is information. Claude Shannon and contemporary scientists demonstrated that and many ancillary insights around 1948. Furthermore, practical storage and transfer of brain information in various quantities, at various sample rates, in various forms (e.g. brain activity, brain structure, brain physiology) and from various locations in the brain have been demonstrated many times in neuroscience and neuromedicine. Some examples include studies on brain-computer interfaces, brain scans in neurology (such as fMRI), interpretation of brain activity (work by Jack Gallant and others), brain mapping in connectomics, neuroprosthetics, and many more.</p> <p>Information storage is not particularly difficult. The main challenges are:</p> <ol> <li> <p>Taking the necessary accurate measurements (data acquisition from a brain).</p> </li> <li> <p>Reconstructing artificial brain functions based on and fine-tuned in accordance with those measurements.</p> </li> </ol> <p>To understand this more easily, consider a simpler, visualizable example. Let\u2019s assume that you wish to create a correct and working \u201cupload\u201d of a watch:</p> <ul> <li>You have at your disposal the computers of today and other scientific technology.     If you can open up the watch and take careful measurements of its components, you could take all of the data and create a piece of software on a computer to emulate each of those components.</li> <li>You could tune this model using the data you collected and carry out tests to ensure that the resulting software runs, producing exactly the same output as the watch. It should tell time with the same precision (or imprecision), and it should respond the same way to presses of the buttons.</li> </ul> <p>As you can see in that example, storing data is not a problem. The challenges you need to overcome are to make the necessary measurements and to construct the emulation of the watch to the specifications of that data.</p>"},{"location":"About/FAQ/#would-it-be-possible-to-create-a-genetic-twin-clone-of-a-human-being-and-then-to-upload-the-mind-of-that-human-being-into-the-new-physical-twin","title":"WOULD IT BE POSSIBLE TO CREATE A GENETIC TWIN (CLONE) OF A HUMAN BEING AND THEN TO UPLOAD THE MIND OF THAT HUMAN BEING INTO THE NEW PHYSICAL TWIN?","text":"<p>Creating a genetic clone appears to be technologically possible today. Uploading a human mind into such a clone is not yet possible.</p> <p>Setting aside all of the other challenges to mind uploading, no technology exists with which a biological brain could be forced to \u201crewire\u201d its connectome into the patterns of the neural circuitry that produces another mind. In other words, there is no known way to force a cloned brain to transform into the equivalent of another brain, such as the brain of the person who provided the genetic material for cloning.</p> <p>Converting from the (digital) data for an uploaded mind to an implementation of that whole brain emulation in a new biological substrate would require additional technological development. The development of this technology is not, at present, a focus area for the Carboncopies Foundation. Primarily, this is because the challenges of data acquisition and whole brain emulation are already quite formidable. Secondly, there is no evidence that mapping back to a biological brain is necessary to achieve successful mind uploading. </p>"},{"location":"About/FAQ/#is-carboncopies-associated-with-transhumanism","title":"IS CARBONCOPIES ASSOCIATED WITH TRANSHUMANISM?","text":"<p>The Carboncopies Foundation is, at its heart, an academic organization. We are concerned with scientific research and development in the field of whole brain emulation. Carboncopies is not associated with transhumanism, and we do not speak for the transhumanist movement. Although some members adhere to transhumanist philosophy, it is not a definitive feature of our organization.</p>"},{"location":"About/FAQ/#will-whole-brain-emulation-incorporate-hormones-or-neurotransmitters-if-so-how-will-this-be-possible","title":"WILL WHOLE BRAIN EMULATION INCORPORATE HORMONES OR NEUROTRANSMITTERS? IF SO, HOW WILL THIS BE POSSIBLE?","text":"<p>Although we do not yet know what level of detail will be required for successful whole brain emulation, it would certainly be possible to emulate the effects of neurotransmitters or hormones. Since neurochemicals can modulate the membrane potential or firing rate of neurons, they could be included as additional values in synapse models.</p>"},{"location":"About/FAQ/#in-a-future-with-mind-uploading-could-i-have-a-body-other-than-human","title":"IN A FUTURE WITH MIND UPLOADING, COULD I HAVE A BODY OTHER THAN HUMAN?","text":"<p>Mind uploading to a different type of body would be possible in principle. A change in embodiment would likely require adjustment and learning.</p> <p>Imagine if your brain, with all of its present experiences, was transferred into a robot body that was not morphologically identical to your present body. You would not be accustomed to this embodiment. A range of automatic translations might be implemented so that you retain normal bodily sensations and motor control. It is likely that a new embodiment would require a period of adjustment in a similar manner to an individual receiving a new prosthetic leg.</p> <p>Embodiments frequently considered for mind uploading include, but are certainly not limited to:</p> <ul> <li>A human body cloned from your original DNA.</li> <li>A robotic body of a humanoid form.</li> <li>A robotic body of a distinctly non-humanoid form, e.g. 'being' a spaceship or a robot 'swarm'.</li> <li>A virtual body in a virtual reality.</li> </ul> <p>Many other embodiments are theoretically possible. Human beings already have the ability to learn and to adjust to feeling comfortable in a wide range of body extensions. Consider how natural it may feel for a sufficiently experienced driver to drive a car, to sense the boundaries of the vehicle. A seasoned kayaker may perceive their kayak as a body of sorts, and a skier may feel skies as a similar extension. Those with mirror-touch synesthesia have expansive bodily representations: their sense of touch and proprioception expands to encompass the individuals in their visual fields. For some, this extended body schema includes animals and inanimate objects as well as humans. </p>"},{"location":"About/FAQ/#how-can-i-volunteer-to-help-make-whole-brain-emulation-and-mind-uploading-a-reality","title":"HOW CAN I VOLUNTEER TO HELP MAKE WHOLE BRAIN EMULATION AND MIND UPLOADING A REALITY?","text":"<p>Our team is always welcoming enthusiastic and dedicated volunteers. This is where you can shine! Our volunteers are the life of the Foundation, the driving force behind our growth and the acceleration of our activities that in turn accelerate progress towards a future with whole brain emulation.</p> <p>Please visit our Openings page! Thank you for donating your valuable time!</p>"},{"location":"About/FAQ/#is-there-a-way-i-can-volunteer-for-experimental-studies-or-clinical-trials-that-help-bring-about-whole-brain-emulation-and-mind-uploading","title":"IS THERE A WAY I CAN VOLUNTEER FOR EXPERIMENTAL STUDIES OR CLINICAL TRIALS THAT HELP BRING ABOUT WHOLE BRAIN EMULATION AND MIND UPLOADING?","text":"<p>By law, the process of soliciting volunteer patients and engaging those patients in medical experimental studies or clinical research trials is very tightly controlled by government regulations and ethics boards. Researchers and medical professionals can conduct those experiments only within the clearly described protocols of an approved clinical study or trial and will publish a call for volunteers or directly reach out to patients when such a study is underway.</p> <p>If you are interested in such studies and trials you can find published advertisements on university websites and in medical journals. You can also find clinical trials at: https://clinicaltrials.gov/ct2/search/index</p> <p>When there are studies or clinical trials that relate closely to the goals of the Carboncopies Foundation, or when there are studies or trials that the Carboncopies Foundation is directly involved in, we will publish all the details on our website at carboncopies.org</p>"},{"location":"About/FAQ/#how-much-will-it-cost-to-achieve-whole-brain-emulation-and-to-make-mind-uploading-an-option-for-all","title":"HOW MUCH WILL IT COST TO ACHIEVE WHOLE BRAIN EMULATION AND TO MAKE MIND UPLOADING AN OPTION FOR ALL?","text":"<p>The total cost is very hard to estimate. To know how much something costs, we need to know exactly what needs to be done in terms of resources and labor.</p> <p>Much of the work on whole brain emulation involves scientific research. The outcomes of future experiments are unknown, and more research is required to determine how exactly WBE will be executed.</p> <p>Instead of looking at it as an engineering project (like building a bridge), look at it as a medical science program (for example, a program that aims to understand and cure various forms of cancer). The first mind uploads will be of small animals. At some later point, human volunteers will have their minds uploaded in a controlled medical research trial. Ultimately, there will be a cautious, gradual process for mind uploading. This process and its outcomes will get better over time. When it is fully developed, the procedure will also become cheaper.</p> <p>Based on the costs of other medical science programs, it is possible that the total costs involved will be in the range of multiple billions of dollars.</p> <p>This would be the cost of fully developing whole brain emulation as a widely accessible technology - at this point, patients could emulate their brains as a routine option of medical care. The expenses of the Carboncopies Foundation are much more modest. Our mission is to educate, to connect researchers in new projects, and to curate the roadmap towards WBE. We are run as a volunteer supported non-profit.</p>"},{"location":"About/Fraud-Alert/","title":"Fraud Alert: Protect Yourself from Scams","text":"<p>It has come to our attention that there have been fraudulent attempts to solicit donations and engage with our community under a false identity. We want to assure you that Carboncopies Foundation is not associated with this fraudulent activity in any way.</p> <p>Your security is our priority. To ensure you are interacting with official Carboncopies Foundation representatives and channels, please take note of the following:</p>"},{"location":"About/Fraud-Alert/#official-channels-and-donation-methods","title":"Official Channels and Donation Methods","text":"<p>Our official channels for communication and donation are listed below. Any communication or solicitation for donations outside of these channels should be considered suspicious.</p> <ul> <li>Website: https://carboncopies.org</li> <li>Email: contact@carboncopies.org</li> <li>Donation Page: https://carboncopies.org/Donate</li> </ul> <p>We accept donations through the following methods:</p> <ul> <li>Our official donation page on our website.</li> <li>Paypal</li> </ul>"},{"location":"About/Fraud-Alert/#verifying-legitimate-communications","title":"Verifying Legitimate Communications","text":"<ul> <li>All official emails from Carboncopies Foundation will originate from the @carboncopies.org domain.</li> <li>We will never ask you for your password or other sensitive personal information via email.</li> <li>If you are unsure about a communication you have received, please contact us directly at contact@carboncopies.org to verify its authenticity.</li> </ul>"},{"location":"About/Fraud-Alert/#reporting-suspicious-activity","title":"Reporting Suspicious Activity","text":"<p>If you encounter any suspicious activity or believe you have been contacted by someone fraudulently claiming to represent Carboncopies Foundation, please report it to us immediately at contact@carboncopies.org.</p> <p>Please include any relevant information, such as screenshots of the communication, email addresses, and any other details that may help us in our investigation.</p> <p>We appreciate your vigilance and support in helping us maintain a safe and secure community.</p>"},{"location":"About/Mission/","title":"Mission","text":""},{"location":"About/Mission/#our-vision","title":"Our Vision","text":"<p>Quote</p> <p>An expedited future where whole brain emulation benefits humanity and individuals.</p>"},{"location":"About/Mission/#our-mission","title":"Our Mission","text":"<p>Quote</p> <p>To identify, facilitate, and conduct the research which will deliver whole brain emulation.</p>"},{"location":"About/Mission/#what-is-whole-brain-emulation-wbe","title":"What is whole brain emulation (WBE)?","text":"<p>Whole brain emulation is a technological protocol that may someday be able to reverse-engineer a biological brain in order to functionally emulate its neurobiological processes on a different substrate (or \"platform\"). Emulation will be done in a way that will generate the cognitive experience that was achieved by the original brain.</p> <p>The human experience thrives on the capabilities of the human brain, and is at the same time constrained by its limitations. Our most human qualities are our resourcefulness, our ability to understand ourselves and the universe we live in, and our ability to create and to improve both our environment and ourselves. We wear clothes, we live in houses, we teach our children, we heal the sick. Consequently, we live longer and better, and we can do and experience far more than our ancestors ever could. It is especially human to overcome natural limitations.</p> <p>What we are personally aware of, what we can understand, where and how we are able to live, and what we may accomplish are still determined by a body and brain that evolved to fit a niche in the early Pleistocene, 2.5 million years ago. Our machines are now able to think and plan in 15 dimensions, to process and respond to events in a universe at the micro- and nanosecond temporal scale. They can comfortably inhabit and travel through the vacuum of space. However, we ourselves cannot do those things and are therefore effectively shut out of those realities. In fact, we cannot even reliably and accurately remember things - our retrieved memories are constructed approximations. The machines we design are able to upgrade and advance. Outcomes and experience with a computer program can improve simply by running it on a better processor. Unfortunately, the biology of a brain is not equipped for back-ups or fundamental improvements.</p> <p>Progress in the field of neural prosthesis shows that, in principle, if we can record enough data about detailed brain structure and dynamic brain activity, then we can produce a neuroprosthetic system that is able to serve the same functions as the brain. This system could safely back up its state and receive incremental upgrades to its physical design and implementation. Whole brain emulation could be applied in this manner to brain-specific neuroprosthetic systems, and eventually, patient-specific clinical neuroprosthetics.</p> <p>To learn more, please see this blog article.</p>"},{"location":"About/Mission/#what-is-the-goal-of-the-carboncopies-foundation","title":"What is the goal of the Carboncopies Foundation?","text":"<p>The Carboncopies Foundation is guided by a steadfast vision of an expedited future where whole brain emulation benefits humanity and individuals. We believe that the possibilities and opportunities presented by the science and technology of whole brain emulation are essential components for the most promising routes to overcoming our greatest challenges and fundamental limitations as a culture, as a society, and as individuals.</p> <p>The positive implications of whole brain emulation are profound and wide-ranging. They include accelerated neuroscience research, developments in artificial intelligence, and consequent applications in clinical neuroscience and neurological medicine. For this reason, our vision is not just to achieve whole brain emulation, but to do so as soon as possible, with many beneficial outcomes along the way. The sooner these technologies become real options, the better the odds that generations alive today can benefit.</p> <p>At the same time, the Foundation is keenly aware that the introduction of significant technological advances can present risks as well. This is why the core of our vision is that whole brain emulation must benefit humanity as a whole as well as individuals. We take great care in our work to ensure that the development and application of whole brain emulation is comprehensively thought through, that they will improve quality of life, and that the availability of advancements will be universal and fair. We are a very diverse and international non-profit organization. Our members come from a wide range of countries and cultures, and we invite participation from every demographic.</p>"},{"location":"About/Mission/#what-does-carboncopies-do","title":"What does Carboncopies do?","text":"<p>There is a long way to go before whole brain emulation can become a reality, and with it, the freedom to explore inconceivable new avenues of creative and intelligent development. Significant strides must be made in the fields of neurobiology, brain imaging, data analysis, computational neuroscience, computational model design, and even in disciplines such as the philosophy of mind.</p> <p>At the Carboncopies Foundation, it is our mission to identify, facilitate, and directly conduct the research that will deliver whole brain emulation. We have built \u2014 and always continue to grow \u2014 a network of scientists across disciplines to match the needs of R&amp;D; toward whole brain emulation. Researchers on our team are familiar with cutting-edge technologies. They closely follow pioneering advances in the areas listed above that affect the development of brain emulation and partial or complete neural prosthesis. Events organized and materials published by the Foundation shine a light on issues that are most in need of better comprehension, attention and support. Whenever possible, we endeavor to facilitate, launch, and support projects. In specific cases, the scientists and engineers on our team engage directly with the research required.</p> <p>There is no magic bullet in the development of whole brain emulation. There is no guarantee that exponential advances in technology will save the day. Whole brain emulation cannot be achieved unless we fully recognize and understand the enormity of this ambitious goal. Success depends entirely on rigorous adherence to the tenets of the scientific method and its application, on vigorous collaboration, and on deliberative and ongoing peer review.</p>"},{"location":"About/Mission/#who-are-we","title":"Who are we?","text":"<p>The Carboncopies Foundation is a 501(c)(3) non-profit organization that provides support to scientists working on challenges critical to whole brain emulation. Legally incorporated in California, USA, we are an international organization with team members on almost every continent. Our team members contribute a wide range of backgrounds and experience levels; take a look at our Team page to meet us, and let us know if you'd like to get involved!</p> <p></p>"},{"location":"About/OfficialDocuments/","title":"Official Documents","text":"<p>This page is pending the addition of official documents, such as the IRS determination letter and annual reports.</p>"},{"location":"About/PressInquiries/","title":"Press Inquiries","text":"<p>The Carboncopies Foundation is a 501(c)(3) non-profit organization that provides support to scientists working on challenges critical to whole brain emulation (WBE). We believe that the possibilities and opportunities afforded by WBE represent the most promising technological path to overcoming our fundamental limitations as a species and as individuals. You can find more details about what we do in our Mission.</p> <p>Our work has already been featured in numerous publications, and is frequently sought after due to the active role Carboncopies plays in research and vision for up and coming technology.</p>"},{"location":"About/PressInquiries/#available-materials","title":"Available Materials","text":"<p>Carboncopies hosts workshops that attract experts in various fields relating to neuroscience and computer science as a continuing effort to expand the discussion on Whole Brain Emulation.</p> <p>Hours of these workshops are available online and are open for use by the press. If explanation or expansion on a topic is needed please contact us.</p> <p>The following quote was taken from transcripts of the Carboncopies Podcast.</p> <p>Quote</p> <p>The other really immediate need for understanding circuits is that most neuropsychiatric disorders arise from disruptions of neural circuitry. Autism, Schizophrenia, depression, addiction and Bipolar Disorder, are probably in large part indeed caused by [these] disruptions.</p> <p>- Prof. Tony Zador</p>"},{"location":"About/PressInquiries/#some-content-to-get-you-started","title":"Some content to get you started","text":"<p>A great introduction to Whole Brain Emulation was offered in January 2018 at our first Workshop event of the year by Randal Koene. This content is accessible in three formats: video, audio, and text.</p>"},{"location":"About/PressInquiries/#do-you-need-more-just-ask","title":"Do you need more? Just ask!","text":"<p>Carboncopies can be reached for interview or content inquiries via the contact page.</p>"},{"location":"About/impact/","title":"Making an impact with the Carboncopies Foundation","text":"<p>The following lists an excerpt of our activities over the years, demonstrating some of the different ways in which the Carboncopies Foundation strives to make a positive impact on the development of whole brain emulation and on its outcomes.</p>"},{"location":"About/impact/#the-brain-emulation-challenge","title":"The Brain Emulation Challenge","text":"<p>An ongoing project of Carboncopies Research, our Bain Emulation Challenge is taking on the principal hurdle standing in the way of actual end-to-end examples of brain emulation: The translation from brain data to working dynamic systems that are verifiably correct.</p>"},{"location":"About/impact/#research-projects-at-the-ccf","title":"Research projects at the CCF","text":"<p>An overview of currently active research projects at the Carboncopies Foundation, giving insight into the way the Foundation chooses its targets for direct research involvement by identifying key gaps in need of being addressed or incentivized.</p> <p>Research at the Carboncopies Foundation</p> <p>And participation in cutting edge science:</p> <ul> <li>Fast imaging of millimeter-scale areas with beam deflection transmission electron microscopy.</li> </ul>"},{"location":"About/impact/#our-goals-and-what-we-do","title":"Our goals and what we do","text":"<p>Our About page strives to explain our effort to ensure beneficial outcomes and a positive impact on the world, as well as our methods, such as when it becomes clear that direct Carboncopies activities in research are appropriate and necessary.</p> <p>Goals and what we do</p>"},{"location":"About/impact/#educating-about-whole-brain-emulation","title":"Educating about whole brain emulation","text":"<p>A mini-course on whole brain emulation.</p> <p>Various talks given at institutions and events, such as:</p> <ul> <li>Whole brain emulation, reverse engineering a mind (a detailing)</li> </ul> <p>And foundational publications:</p> <ul> <li>Fundamentals of Whole Brain Emulation: State, Transition and Update Representations.</li> </ul>"},{"location":"About/impact/#collecting-expert-insights","title":"Collecting expert insights","text":"<p>Our events gather experts in domains critical for whole brain emulation. For example:</p> <ul> <li>Roadmap workshop: Consciousness, with Christof Koch, Michael Graziano and others.</li> <li>Roadmap workshop: Patient specific selection, fitting and verification.</li> </ul>"},{"location":"About/Team/Us/","title":"Meet Our Team","text":"<p>The Carboncopies Foundation is a 100% volunteer-driven organization.  We are supported and operated solely by some of the most talented volunteers around the world, and without their generous time and dedication this organization would not be possible!</p>"},{"location":"About/Team/Us/#board-members","title":"Board Members","text":""},{"location":"About/Team/Us/#dr-kenneth-hayworth","title":"Dr. Kenneth Hayworth","text":"Board Member <p>President and Co-Founder of the Brain Preservation Foundation</p>"},{"location":"About/Team/Us/#gabriel-johansson","title":"Gabriel Johansson","text":"<p>Secretary</p> <p>Gabriel works as a strategist within the public sector and has previous experience with running NGO operations including project management, event planning and organizational development. His main interest is the impact Carboncopies goals, and related research, will have on society and human life.</p>"},{"location":"About/Team/Us/#dr-randal-koene","title":"Dr. Randal Koene","text":"<p>President and Chief Science Officer</p> <p>Neuroscientist and co-founder of carboncopies.org</p>"},{"location":"About/Team/Us/#thomas-liao","title":"Thomas Liao","text":"<p>Director of BrainGenix</p>"},{"location":"About/Team/Us/#alexander-mclin","title":"Alexander McLin","text":"<p>Chair of the Board</p>"},{"location":"About/Team/Us/#stefania-schino","title":"Stefania Schino","text":"<p>Chief Financial Officer</p> <p>Received her bachelor's degree in Accounting and Finance from Bari University of Economy.</p>"},{"location":"About/Team/Us/#alicia-smallwood","title":"Alicia Smallwood","text":"<p>Board Member</p> <p>Currently studying mathematics at University of Wisconsin - Milwaukee.</p>"},{"location":"About/Team/Us/#dr-keith-wiley","title":"Dr. Keith Wiley","text":"<p>Board Member</p> <p>Received his Ph.D. in Computer Science and Bachelor's in Psychology.</p>"},{"location":"About/Team/Us/#team-members","title":"Team Members","text":""},{"location":"About/Team/Us/#jason-wong","title":"Jason Wong","text":"Director of HR/Talent Aquisition, Director of Communications <p>Third year undergraduate student at the UC Santa Cruz studying Economics</p>"},{"location":"About/Team/Us/#dr-michael-cerullo","title":"Dr. Michael Cerullo","text":"<p>Michael A. Cerullo, M.D. graduated from the Saint Louis University School of Medicine in 2000.</p>"},{"location":"About/Team/Us/#keiland-cooper","title":"Keiland Cooper","text":"<p>Researcher</p> <p>Neuroscientist and artificial intelligence researcher.</p>"},{"location":"About/Team/Us/#bill-croughan","title":"Bill Croughan","text":"<p>Researcher</p> <p>Bill double-majored in math and computer science at Carnegie Mellon University. He is currently earning his PhD at UC Berkeley, developing and applying quantitative methods to study the function and mechanism of hippocampal replay events.</p>"},{"location":"About/Team/Us/#matthew-t-dearing","title":"Matthew T. Dearing","text":"<p>AI/ML applications developer and Ph.D. student in computer science at the Illinois Institute of Technology.</p>"},{"location":"About/Team/Us/#daniel-c-elton-phd","title":"Daniel C. Elton, PhD","text":"<p>Staff Scientist at the National Institutes of Health Clinical Center, working on applications of AI to medical imaging.</p>"},{"location":"About/Team/Us/#joshua-french","title":"Joshua French","text":"<p>BrainGenix Department</p>"},{"location":"About/Team/Us/#amna-ghani","title":"Amna Ghani","text":"<p>Doctoral candidate in Computational Neuroscience.</p>"},{"location":"About/Team/Us/#samuel-hosovsky","title":"Samuel Hosovsky","text":"<p>BrainGenix Department</p> <p>Samuel is a technology consultant primarily in enterprise marketing and data solutions. He studied Computer Science at Charles University of Prague and is finishing a part-time Master's programme in Computing and Information Systems. His research is focused on resolving the computational challenges in cleansing, transforming but mostly interpreting experimental data for the purpose of WBE.</p>"},{"location":"About/Team/Us/#john-jose","title":"John Jose","text":"<p>John is a current master's student in electrical engineering with a focus on computing systems.</p>"},{"location":"About/Team/Us/#sara-kochanny","title":"Sara Kochanny","text":"<p>Researcher</p> <p>Sara received her Bachelor's in Biology from New York University. She currently works at the University of Chicago, where her time is split between using deep learning for Cancer Informatics and as a Research Coordinator for a brain-machine interface clinical trial. She is interested in developing neural interfaces that modify sensory inputs to the brain and augment an individual's subjective experience of their reality.</p>"},{"location":"About/Team/Us/#zachary-lazzara","title":"Zachary Lazzara","text":"<p>BrainGenix Department</p> <p>I've been interested in the concept of whole brain emulation and mind uploading for as long as I can remember.</p>"},{"location":"About/Team/Us/#brad-leu","title":"Brad Leu","text":"<p>BrainGenix Department</p> <p>Brad is a data engineer with a long career in information technology.</p>"},{"location":"About/Team/Us/#charl-linssen","title":"Charl Linssen","text":"<p>Researcher</p> <p>Lead neuroscientist on the NEST project.</p>"},{"location":"About/Team/Us/#mika-mautner-rohde","title":"Mika Mautner-Rohde","text":"<p>Researcher</p> <p>Currently pursuing his bachelor degree in cognitive neuroscience at the University of Amsterdam. His interest in the Carboncopies Foundation is predominantly in the area of academic research projects, with a focus on the biology of the brain. These are projects that can advance the science closer to a realization of the fascinating possibility of whole brain emulation. As a waypoint he sees significant potential in brain-computer interfaces.</p>"},{"location":"About/Team/Us/#arseniy-mukovozov","title":"Arseniy Mukovozov","text":"<p>Computer scientist.</p>"},{"location":"About/Team/Us/#bill-nguyen","title":"Bill Nguyen","text":"<p>Bill studies the brain at UC Santa Barbara.</p>"},{"location":"About/Team/Us/#oge-nnadi","title":"Oge Nnadi","text":"<p>Media contact at the BPF.</p>"},{"location":"About/Team/Us/#prishita-ray","title":"Prishita Ray","text":"<p>Researcher</p> <p>I currently lead the Neuron Emulation System division of the BrainGenix Department at Carboncopies.</p>"},{"location":"About/Team/Us/#ilya-sapranidi","title":"Ilya Sapranidi","text":"<p>Researcher</p> <p>A researcher and tech entrepreneur with a background in complex systems, that focuses on advancing machine intelligence.</p>"},{"location":"About/Team/Us/#joe-strout","title":"Joe Strout","text":"<p>Joe Strout is a software engineer with an M.S. in Neuroscience from UCSD.</p>"},{"location":"About/Team/Us/#angela-thornton","title":"Angela Thornton","text":"<p>Researcher</p>"},{"location":"About/Team/Us/#fasiha-iffat","title":"Fasiha Iffat","text":"<p>Third year Baruch undergraduate student majoring in psychology and minoring in english.</p>"},{"location":"About/Team/Us/#shuma-begum","title":"Shuma Begum","text":"<p>Third year Baruch undergraduate student majoring in psychology and minoring in english</p>"},{"location":"About/Team/Us/#advisors","title":"Advisors","text":""},{"location":"About/Team/Us/#prof-theodore-berger","title":"Prof. Theodore Berger","text":""},{"location":"About/Team/Us/#dr-diana-deca","title":"Dr. Diana Deca","text":""},{"location":"About/Team/Us/#dr-ben-goertzel","title":"Dr. Ben Goertzel","text":""},{"location":"About/Team/Us/#todd-huffman","title":"Todd Huffman","text":""},{"location":"About/Team/Us/#james-ingallinera","title":"James Ingallinera","text":""},{"location":"About/Team/Us/#dr-eugen-leitl","title":"Dr. Eugen Leitl","text":""},{"location":"About/Team/Us/#prof-anthony-zador","title":"Prof. Anthony Zador","text":""},{"location":"About/Team/Bios/AngelaThornton/","title":"Angela Thornton","text":"<p>PhD candidate at University of Nottingham exploring the personal and public narrative around the hypothetical journey to Whole Brain Emulation and the ultimate creation of a Substrate Independent Mind</p> <p>I gained my first degree (BSc Psychology) over 30 years ago and have had a long and successful career in commercial market research. My interests and experience span a range of sectors since I have conducted research with both consumers and businesses. I have considerable experience in healthcare, but I also have worked in partnership with creative agencies on branding and communications and have a strong personal interest in arts and culture.</p> <p>In 2018 I fulfilled a long-held dream of returning to academia and completed a MSc in Psychological Research Methods at the University of Nottingham (UoN) where I gained a distinction. I chose this course as a stepping stone to a fully funded PhD at Horizon Centre of Doctoral Training \u2013 also based at the UoN \u2013 and started my PhD journey in 2019. My thesis looks to explore the personal and public narrative around the hypothetical journey to Whole Brain Emulation and the ultimate creation of a Substrate Independent Mind.</p> <p>I am delighted to be part of the Carboncopies team and look forward to working towards a shared vision of bringing the science to a concept that for many emerged from science fiction.</p>"},{"location":"About/Team/Bios/RandalKoene/","title":"Randal A. Koene","text":"<p>Randal A. Koene (randalkoene.com) is a Dutch neuroscientist and neuroengineer, and co-founder of carboncopies.org, the outreach and roadmapping organization for advancing Substrate-Independent Minds (SIM). Between 2008 and 2010, Koene was Director of the Department of Neuroengineering at the Fatronik-Tecnalia Institute in Spain, the third largest private research organization in Europe. Koene earned his Ph.D. in Computational Neuroscience at the Department of Psychology at McGill University, and his M.Sc. in Electrical Engineering with a specialization in Information Theory at Delft University of Technology. He is a former Professor at the Center for Memory and Brain of Boston University, and is co-founder of the Neural Engineering Corporation of Massachusetts. Koene established the MindUploading.org website and first proposed the term and specific approach called whole brain emulation, the purpose of which is the technological accomplishment of mind transfer to a different substrate. His professional research objective is the implementation of whole brain emulation: creating the large-scale high-resolution representations and emulations of activity in neuronal circuitry that are needed in patient-specific neuroprostheses. He is a member of the Oxford working group that convened in 2007 to create the first roadmap toward whole brain emulation.</p> <p>Koene has professional expertise in computational neuroscience, psychology, information theory, electrical engineering and physics. He organizes neural engineering efforts to obtain and replicate function and structure information that resides in the neural substrate for use in neuroprostheses and neural interfaces. Based on NETMORPH, Koene's computational framework for the simulated morphological development of neuronal circuitry, his lab is creating a Virtual Brain Laboratory to give neuroscientists, neuroengineers and clinicians large-scale high-resolution quantitative tools analogous to the computational tools that have become essential in fields such as genetics, chemistry or the aero-space industry. This effort bridges scales and will help determine how significant functions are encoded robustly in neural ensembles, and how those functions can nevertheless depend in specific ways on the detailed biophysics of particular component physiology. - From Wikipedia.org</p>"},{"location":"About/Team/Bios/RandalKoene/#available-media","title":"Available Media","text":"<p>As a forerunner in the field of Whole Brain Emulation, Randal has given countless discourses and spoken in various settings/locations. Of his presentations, many are available in video format. (see below)</p> <p>He is also known to participate in panels and interviews including the Carboncopies Podcast.</p>"},{"location":"About/Team/Bios/RandalKoene/#talks","title":"Talks","text":"<p>See video playlist of a selection of talks given by Randal.</p>"},{"location":"About/Team/Bios/RandalKoene/#interviews","title":"Interviews","text":"<p>See video playlist of a collection of interviews given by Randal.</p>"},{"location":"About/Team/Bios/StefaniaSchino/","title":"Stefania Schino","text":"<p>Received her bachelor\u2019s degree in Accounting and Finance from Bari University of Economy.</p> <p>Received her bachelor\u2019s degree in Accounting and Finance from Bari University of Economy with expertise in project management, strategy and funding for the creation of new businesses and European funding. Her area of interest includes innovative technologies for life extension and transhumanism.</p>"},{"location":"About/Team/Bios/RandalKoene/Interviews/","title":"Randal A. Koene","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#interviews","title":"Interviews","text":"<p>The following is a collection of interviews given by Randal A. Koene.</p>"},{"location":"About/Team/Bios/RandalKoene/Interviews/#future-science-project","title":"Future Science Project","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#intelligenge-identity-substrates","title":"Intelligenge Identity Substrates","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#philosophical-aspects","title":"Philosophical aspects","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#the-objective-centrist","title":"The Objective Centrist","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#gf2045","title":"GF2045","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#colin-hales-conversation","title":"Colin Hales Conversation","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#le-neuroscientifique","title":"le neuroscientifique","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#substrate-independent-minds","title":"Substrate Independent Minds","text":""},{"location":"About/Team/Bios/RandalKoene/Interviews/#singularity-summit","title":"Singularity Summit","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/","title":"Randal A. Koene","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#talks","title":"Talks","text":"<p>The following is a selection of talks given by Randal A. Koene.</p>"},{"location":"About/Team/Bios/RandalKoene/Talks/#tedx-tallinn","title":"TEDx Tallinn","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#gf2045-2013","title":"GF2045 2013","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#an-intro-to-wbe","title":"An Intro to WBE","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#kernel-neuralink","title":"Kernel &amp; Neuralink","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#brain-preservation","title":"Brain Preservation","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#model-validation","title":"Model Validation","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#brain-ai-hybrids","title":"Brain, AI, &amp; Hybrids","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#singularity-summit","title":"Singularity Summit","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#extending-life","title":"Extending Life","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#system-identification","title":"System Identification","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#transhumanism","title":"Transhumanism","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#sim","title":"SIM","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#the-binding-problem","title":"The Binding Problem","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#gf4025-ii","title":"GF4025 II","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#gf2045-iii","title":"GF2045 III","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#advancing-sim","title":"Advancing SIM","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#complex-requirem","title":"Complex Requirem\u2026","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#the-time-is-now","title":"The Time Is Now","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#modern-cosmism","title":"Modern Cosmism","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#agi-neurosci","title":"AGI &amp; Neurosci\u2026","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#wic-2011","title":"WIC 2011","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#25-watt-bio-comp","title":"25 Watt Bio-Comp\u2026","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#asim-2010","title":"ASIM 2010","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#the-big-picture","title":"The Big Picture","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#unusual-concepts","title":"Unusual Concepts","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#future-of-agi","title":"Future of AGI","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#wbe","title":"WBE","text":""},{"location":"About/Team/Bios/RandalKoene/Talks/#dil2al","title":"\u201cdil2al\u201d","text":""},{"location":"Blog/Recent/","title":"Recent Blog Posts","text":"<p>Check out our most recent blog posts!</p> <ul> <li>How Could Whole Brain Emulation Affect Us? (Posted 2024-08-21)</li> <li>What is Whole Brain Emulation? (Posted 2024-08-21)</li> <li>Why Whole Brain Emulation isn't a threat to humanity (Posted 2024-06-23)</li> <li>A reason to hedge on whole-brain emulation for AGI (Posted 2024-06-18)</li> </ul>"},{"location":"Blog/Posts/Astronauts/Post/","title":"Why We Should Send Uploaded Astronauts On Interstellar Missions","text":""},{"location":"Blog/Posts/Astronauts/Post/#why-we-should-send-uploaded-astronauts-on-interstellar-missions","title":"Why We Should Send Uploaded Astronauts On Interstellar Missions","text":""},{"location":"Blog/Posts/Astronauts/Post/#a-review-of-the-article-by-giulio-prisco","title":"A Review of the Article by Giulio Prisco","text":"<p>Sending people to planets beyond our solar system has been a growing interest for space exploration. The future colonization of an Earth-like planet is inevitably necessary for mankind's long-term survival. A major milestone in advancing this endeavor was reached with the creation of the 100 Year Starship joint research project between NASA and the U.S. Defense Advanced Research Projects Agency (DARPA). The project resulted in the Icarus Interstellar organization, which carries out research and development for the purpose of interstellar travel.</p> <p>While finding ways to support interstellar travel for flesh-and-blood astronauts can lead to advancements in life-sustaining spacecraft, it is no easy challenge to engineer massive starships with all the essentials to sustain hundreds of human generations toward the goal of reaching an Earth-like planet to keep humanity going. It's not impossible, but what if we didn't need to be concerned with the biological requirement and could just focus on supporting the minds of the future space travelers? This is where mind uploading becomes the most logical solution. Professionally known as Whole Brain Emulation, this solution would eliminate the challenges of many otherwise crucial factors, such as artificially generated gravity, replenish-able food and water, recycled breathable air, air pressure containment, and the overcoming of other life cycle limitations. Given these conditions, Whole Brain Emulation would provide a means for people to no longer need an Earth-like planet to survive.</p> <p>Still, the crew of digital astronauts will need some replenishing resources, such as power (the main resource for keeping all machinery functional, even if the crew is dormant for the travel) and raw material for repairs and technological modifications. Furthermore, the ship and its crew will have a mass that must be propelled across several light years. Using chemical burning rockets would take about 100,000 years to get to the next nearest star, Proxima Centauri. To address this issue, the Icarus team has proposed a method of fusion-based propulsion offering 1 million times more energy than current rockets.</p> <p>\"Light sails\", which take advantage of the possible lightweight craft containing a digital crew, provide another propulsion solution. This project, led by the Planetary Society, uses large solar panel type sails to catch the momentum of light particles from starlight. The organization currently has launched 2 light sail prototypes now in orbit around the earth. Light sails can also be propelled with much greater efficiency, acceleration, and eventual speed than their host solar light can provide by utilizing lasers at the source of the trip. However, there is no way to decelerate such a spacecraft as it approaches its destination; such a mission would be a flyby. That said, once a remote colony is established, it could offer a laser-braking system to receive incoming laser-propelled light sail spacecraft.</p> <p>Another option for interstellar exploration would be to send AI instead of emulated humans. While this may aid in the field of space exploration by data transferred back to Earth, it doesn't solve the challenge of mankind's objective to colonize the rest of the universe, nor the challenge of finding a new home after the lifespan of the Earth as run its course.</p> <p>While it's easy for the average person on the street to be more concerned about getting to work on Monday than about getting to Proxima Centauri in several centuries, time is running out to find a home for generations in the future. Earth will not be here forever and it will be habitable for even less time (see previous blog post, a review on The Greatest Long-term Threats Facing Humanity). It is human nature to expand and explore. This problem is well understood by scientists such as  those of the Icarus organization. Furthermore, if Whole Brain Emulation is developed in \"Joe's\" lifetime, \"Joe\" will have a reason to be invested in interstellar travel.</p>"},{"location":"Blog/Posts/Astronauts/Post/#opinion-by-michael-ulrich","title":"Opinion (by Michael Ulrich):","text":"<p>Whole Brain Emulation is absolutely essential for long-term space travel. The advantage of having a small payload isn't just a factor of the mass of the digital crew. Using fusion propulsion or light sails can help resolve the fuel issue, but the crew will likely want to bring a lot of things with them. For example, the ideal life of an emulated person differs from person to person. Some may be perfectly fine with living as a computer program, spending all their time in a virtual world. Others may prefer to maintain a level of interaction with the real world, much as they did in original organic form. This group will want to bring engineered vessels (i.e., bodies) along to inhabit when they reach their destination exoplanet. If they want to build a civilization of embodied persons who can roam the world in suitable form, then they will want to bring the necessary equipment with which to bootstrap a high-tech infrastructure.</p> <p>The main point is that we will have a lot of baggage to pack for the trip regardless of whether we're emulated. This will require a massive ship which will need power and technical support resources. Alternatively, having the means to build an infrastructure could be started by bringing the minimum essential utilities derived from a calculated chain of development. A builder \u201cseed\u201d nanobot that could exponentially reproduce itself would greatly aid a payload constraint.</p>"},{"location":"Blog/Posts/BrainBits/Post/","title":"How Pieces of Live Human Brain are Helping Scientists Map Nerve Cells","text":""},{"location":"Blog/Posts/BrainBits/Post/#how-pieces-of-live-human-brain-are-helping-scientists-map-nerve-cells","title":"How Pieces of Live Human Brain are Helping Scientists Map Nerve Cells","text":""},{"location":"Blog/Posts/BrainBits/Post/#a-summary-of-the-article-by-laura-sanders-reporting-on-the-experimental-project-by-nick-dee","title":"A summary of the article by Laura Sanders reporting on the experimental project by Nick Dee","text":"<p>When you think of how scientists study a piece of brain tissue it is easy to imagine them pulling a pale green mass out of an old jar of formaldehyde. This picture, however, is far from the kind of experiments being undertaken at the Allen Institute for Brain Science. Nick Dee, and his team of neuroscientists, are experimenting with recently extracted brain samples still containing living cells. Studying these living brain cells is useful for understanding the cell's connections with one another. The goal for Nick and his team is to determine all kinds of neurons in a human brain as well as mapping how the cells communicate with each other.</p> <p>In this article, the author observed the team experimenting with brain samples recently taken form a 41-year old woman. The piece of brain removed was targeted to be causing her severe seizures. The samples of living tissue must be taken quickly to the lab to be sliced. The samples are then put under several microscopes to look for the healthiest cells efficient for the experiments.</p> <p>The first experiments involved observing the cell's behavior. Using a technique called patch-clamp a thin glass tube is latched on to selected neurons. These neurons can be given an artificial message via an electric current. The goal of this experiment is to see how the cells communicate with other cells. With a multi-station rig, with several neurons latched onto it, the neuron signals can be monitored while the electrostatic artificial signals are injected into several locations of the brain slice. The neurons that react when other neurons are given an electric pulse offer evidence that those correlating neurons communicated with each other while still inside the patient's head. During this experiment the cell shapes are mapped using dye.</p> <p>Following this procedure, the nuclei from the experimented neurons are extracted. Every nucleus reveals which genes were active in the living cells just before the nuclei were extracted. These experiments have revealed appearances of rare cells that researchers believe are associated with Alzheimer's disease and psychiatric conditions called Economo neurons.</p> <p>The live cell studies also observed notable differences with humans and mice. For instance, humans have a neuron called an h-channel neuron which is covered with a protein. These channels help cells respond to electrical signals. They can be affected by drugs, such as drugs for epilepsy, and could potentially be a significant building block for human high-level cognitive functions.</p> <p>Documenting all of these live neuron experiments may lead to an understanding of why certain individuals suffer from certain disorders.</p> <p>An important observation is that the overall number of cell types in a human cortex is very similar to that of a mouse cortex. Given this understanding, the answer for why humans are so smart, compared to animals like mice, must be something other than humans having many specialized neurons. The answer may be just the few rare neurons, such as the Economo neurons, or neuron types yet to be discovered. Other neuroscientists think our intellect may be due to cells that aren't even neurons at all such as glial cells.</p> <p>The proceeding experiments on the samples, conducted weeks or months later, involve delivering genes to the live cells. Some cell samples used for this experiment are able to survive for several months. Viruses deliver the genes to the cells. These genes are responsible for making certain groups of cells glow to make them easier to study and experiment with changing their behavior. Experiments like these may lead to ways to possibilities in controlling curtain cell behavior such as the effect of Economo genes. Furthermore, these observations can also provide insight into how information flows through cells.</p> <p>With living cell experiments the scientific understanding of brain function is greatly expanding. Understanding the uniqueness of the human mind is essential for constructing a complete neural network map and ultimately modeling that network. While brain samples with living cells are rare, they may hold answers to solving questions in neuroscience that non-living brain samples simply cannot.</p> <p>Research projects like this one by Nick are the fundamental steps being taken to completing the goals for connectomics. Connectomics is one crucial part of Whole Brain Emulation in which completing a map of the neuron communications, as well as understanding the physical domains of consciousness, will be the base for modeling a human brain in an artificial substrate. The Carboncopies Foundation promotes this type of research.</p> <p>For more information see the article in Science News: How Pieces of Live Human Brain are Helping Scientists Map Nerve Cells</p>"},{"location":"Blog/Posts/BrainFacts/Post/","title":"BrainFacts.org","text":""},{"location":"Blog/Posts/BrainFacts/Post/#brainfactsorg","title":"BrainFacts.org","text":""},{"location":"Blog/Posts/BrainFacts/Post/#a-review-on-the-public-information-initiative-website","title":"A Review on the Public Information Initiative Website","text":"<p>The human brain likely holds a place in the list of top ten marvels of the universe. It\u2019s where we experience everything, and in that way it\u2019s the place in which we live, and yet we still have much to understand about it. It\u2019s no wonder that neuroscience captures the curiosity of many seeking to understand this blob of grey matter capable of shaping the outcomes of the Earth and beyond.</p> <p>A great place for anyone to start seeking further understanding about their knowledge container would be a convenient website with shared research information from neuroscience contributors around the world. BrainFacts.org, founded by Nick Spitzer, Ph.D, answers that calling. Finding research on a particular subject is very easy and new articles are published constantly. It is also the main site the neuroscience community goes to for information about the brain.</p> <p>Every brain research subject is given generous attention. Main topics include: Thinking, Sensing &amp; Behaving, Diseases and Disorders, Brain Anatomy &amp; Function, Neuroscience in Society, and information about experiments and research techniques.</p> <p>As a fun learning tool, there is a 3D model of the brain where the user can select different sections to display information about that brain location\u2019s function. For those looking for more complex neuroscience information there is a tab for core concepts of brain research. Furthermore, there is a tab for educators providing project ideas, teaching guides, and advice. Within this tab, news about neuroscience events can give information on where they are and how to participate.</p> <p>BrainFacts.org has also published their own book: Brain Facts, a primer on the brain and nervous system which is mentioned on their site.</p> <p>Public outreach is a primary focus for BrainFacts.org. With several social media pages to choose from, and their newsletter subscriptions, it is very convenient to stay informed about the latest articles.</p> <p>For an organization committed to the public outreach of brain research information, BrainFacts.org is a shining example of dedication. As a similar organization, Carboncopies.org is dedicated to public outreach on the research and development of whole brain emulation.</p> <p>\u201cJoin us as we explore the universe between our ears. Because when you know your brain, you know yourself.\u201d \u2013 BrainFacts.org</p> <p>For more information, visit their website: BrainFacts.org</p>"},{"location":"Blog/Posts/BrainFunction/Post/","title":"Quantum Mechanics and Higher Brain Functions","text":""},{"location":"Blog/Posts/BrainFunction/Post/#quantum-mechanics-and-higher-brain-functions","title":"Quantum Mechanics and Higher Brain Functions","text":""},{"location":"Blog/Posts/BrainFunction/Post/#a-review-of-the-article-by-christof-koch-and-klaus-hepp","title":"A review of the article by Christof Koch and Klaus Hepp","text":"<p>At some point in your life you may find yourself pondering your individual relevance to the world around you. You may start to question whether your disposition was a result of bad decision making, or if fate simply delt it's hand for you. You think about it until you get to the point where you're wondering if any choices you've made were a result of your own free will, or if they were all simply predetermined by the laws of physics; namely, every action produces only one other possible reaction.</p> <p>Some scientists like to believe that if your brain has the properties of exhibiting quantum mechanical functions, then free will might actually be a real thing and we're not just slaves to causality. This research article, The relation between quantum mechanics and higher brain functions: Lessons from quantum computation and neurobiology, by Christof Koch and Klaus Hepp, outlines arguments against the proposition that the brain exhibits properties of quantum mechanical physics that effect the consciousness.</p> <p>So, what are Quantum Mechanics? Well, in short, it claims that not everything in the universe is causally determined by the logical sense of physics as we can understand them. In classical physics, every action has an equal and opposite reaction and every action can only produce one possible reaction based on mathematically observable universal laws. In quantum mechanics, when you get down to a subatomic scale and examine the movements of subatomic particles, specifically photons, they may not follow such classical physical laws. In the realm of quantum mechanics, the movement of photons are not causally determined by the same kind of physical laws that we are accustomed to, but rather, can move in several possible directions with no cause that can be logically understood. One such phenomenon example is how light has the property to act as both a wave and a particle.</p> <p>So, what are Higher Brain Functions? Higher brain functions are the functions of the brain that have complex operations that are more \"self-directed\" by the organism. In a human, good examples would be memory retrieval and self-awareness. In contrast, lower brain functions would be something more automatic like heart regulation or the sense of touch.</p> <p>Okay, then how do these two subjects tie in together? If it is possible for subatomic particles to not be causally determined, and if the higher brain functions taking place within us operate on causes made by quantum mechanical reactions, then that could mean that our higher brain functions also are not causally determined by physical laws. This characteristic would imply that our minds are not just slaves to the never-ending cycle of action-reaction physical movements that all matter in the universe is subjected to, but rather we might actually be determining agents to the outcomes of our own lives.</p> <p>Now, you might be thinking, \"Well, yes, it would be great if we had some kind of free will, and that our minds are not just slaves to the laws of physics; but trying to claim that quantum mechanics is the divine source of our ability to have minds of our own seems like a desperate attempt to escape the idea that we are all just prisoners of fate.\" That could very well be the reason that most scientists disagree with the notion. If you're trying to find some comfort in the idea that you're just a slave to your brain's molecules with predetermined physical movements, then you may be interested in philosophical research on meaning and identity. This article, however, sticks with science and experimentation to provide arguments against the notion of quantum mechanics determining higher brain function.</p> <p>The arguments in this article all involve the primary issue of the boundary between quantum mechanics and classical mechanics. There is an issue when trying to link a path from consciousness perception to quantum mechanics to physical reactions. This is because quantum mechanics cannot be operated on by an input of the classical physical sense.</p> <p>Higher brain functions are understood by classical physics as a microscopically complex process of billions of firing over the cortex. Each having multiple synapses made of about a thousand different kinds of proteins. A single conscious thought involves an entire network of neurons all firing together.</p> <p>This article concludes by stating that the classical interpretation of higher brain functions remains the superior scientific field, however, it is stressed that the boarder between actual quantum mechanics and classical mechanics in the subatomic scale of the brain still needs to be researched. The article ends with a comforting perspective, \"To be conscious means to tell to oneself stories which allows us to function better in reality. Dysfunctions in the representation of the self lead to major psychiatric diseases. To understand one\u2019s self will help others,\" (Koch and Hepp, 2007).</p> <p>For further interest, please check out the article here:</p> <p>The relation between quantum mechanics and higher brain functions: Lessons from quantum computation and neurobiology</p> <p>If you're interested in research on identity and meaning please check out these suggestions:</p> <p>On Identity: from a philosophical point of view by Daniel Sollberger posted on the US National Library of Medicine National Institutes of Health</p> <p>Neural and Behavioral Evidence for the Role of Mental Simulation in Meaning of Life by Adam Waytz, Hal E. Hershfield, and Diana I Tamir posted on the US National Library of Medicine National Institutes of Health</p>"},{"location":"Blog/Posts/BrainHealth/Post/","title":"Brain Health and Brain Emulation","text":"<p>An analysis by Michael Ulrich of how brain health pertains to the efficacy of brain emulation</p> <p>So, you\u2019ve decided that you want to have an emulation of your brain created. In this hypothetical scenario, you know that whole brain emulation has been achieved and is publicly available; or at least you expect it to be available to you in a few decades. At this point, you\u2019re starting to think more about your brain\u2019s health because you want to preserve it at its maximum possible quality. Maybe you quit drinking altogether because of how alcohol affects cognitive ability over time, maybe you quit playing football out of fear of potential concussions, or maybe you decide to stay indoors as much as possible to avoid any chances of causing harm to your brain in any way. While the last possibility may be an extreme measure, it is good to practice lifestyle habits that help to conserve your memory, cognitive function, and awareness by keeping your brain in a healthy state. While this is nothing new to hear from a general health awareness point of view, keeping your brain healthy takes on new meaning if you\u2019re preparing yourself for a whole brain emulation procedure.</p> <p>How the health of a patient's brain affects the preservation and the scanning of the brain</p> <p>The ability to preserve an organ is the same for all ranges of health. The healthiest brain can be preserved just as well as the least healthy brain. At the point of preservation, a brain\u2019s health condition determines what can be scanned and ultimately emulated.</p> <p>Brain health includes the connectivity among synapses, the concentration of healthy cells, and the state of the neurochemical composition. For example, for a patient with concussions, it is possible that the connectivity of their synapses may not be as strong as a patient with no concussions. Additionally, for a patient who is an alcoholic, they would have compromised synapse connectivity as well as deteriorated neurons. These brain health conditions will be preserved with their brain.</p> <p>During tissue scanning, all aspects of the brain\u2019s cellular composition are recorded (including the deformations and deficits). All negative health conditions are now incorporated into the data that will be used to emulate that patient\u2019s brain.</p> <p>Effects of emulating one's brain at different ages</p> <p>Consider that once a patient's brain goes into the preservation phase the brain no longer has the ability to grow. By preservation phase, we mean that the brain is removed from the body and all cell activity is frozen to be scanned later or may be scanned immediately. Obviously, a preserved brain, like any well-preserved tissue sample, cannot be subjected to continued consequences of aging either, such as accumulating deficits from dementia or Alzheimer\u2019s disease.</p> <p>Because of this, without any further tinkering or enhancements, the emulated brain will have the same maturity level as when the biological brain was removed from the patient\u2019s body. For example, if the brain of a 10-year-old were preserved, scanned, and emulated, that mind would still have the cognitive ability of a 10-year-old. Furthermore, if the brain of a 97-year-old were preserved, scanned, and then emulated, that emulated mind would have similar cognitive capabilities of a 97-year-old.</p> <p>Is there a stage in a patient\u2019s life where they have the healthiest brain state?</p> <p>To answer this, consider the determining factors: how body health affects brain health, the likelihood of one\u2019s brain being harmed or damaged over time, the accumulation of said harm, and the effect of age on mental maturity and memory.</p> <p>With these factors, the best age for brain health is not necessarily the same as one\u2019s physical prime. Measuring body efficiency is not the same as measuring brain efficiency. For example, a patient may be in their physical prime in their early twenties, yet they are still maturing mentally and gaining valuable experience and memories that contribute to their individuality. Additionally, there is an age where mental abilities tend to decline. Since brains didn\u2019t naturally evolve to last indefinitely, old age will bring about disabilities as one ages. At this point the patient has gone past the point of peak brain health.</p> <p>Given these conditions, an estimation for an average patient\u2019s age for maximum brain health may be between 45 and 65, as an estimate. This is considering an age where mental maturity has peaked and mental deterioration due to aging has not yet occurred.</p> <p>What aspects of brain function  Can Be Artificially Incorporated into the Emulation?</p> <p>In the scenarios above, where we imagined brain emulation for patients with brain deficits, we were assuming that the brain emulation procedure simply does its best to create a brain emulation that reconstructs as faithfully as possible every detail of the brain in its original state.</p> <p>If, once these patients have emulated brains, they are  to be treated for their negative conditions (deficiencies and brain damage), then some aspects of brain function would have to be artificially corrected. For example, if a patient with Alzheimer\u2019s were to be given a brain emulation without Alzheimer's, then the emulated brain function would not be strictly identical to that of the  brain that was scanned. The features of the emulation (code, physical structure, and connections) would have to be designed and constructed within the parameters that simulate the original brain, but replacing features of the brain that Alzhiemer\u2019s disease would affect. As another example, if a patient with damaged brain regions were to be emulated without simulating the damaged regions, then all of the affected brain functions would need artificial additions in the emulated brain that would make up for the missing healthy components of the patient\u2019s emulated brain.</p> <p>The healthier the brain that is emulated, the fewer artificial additions will need to be designed and incorporated into the emulated brain if the patient\u2019s brain is not to be emulated with any disabilities.</p> <p>Why is brain health important if artificial corrections can be made?</p> <p>In addition to adding artificial components to the emulated brain of a patient to correct for disabilities, we can imagine that additions and enhancements can lead to more advanced capabilities. These abilities would be considered superhuman if characteristic cognitive abilities, such as memory fidelity and retention, awareness, and response time were optimized to the limits of the technology.</p> <p>We can alter our mental capabilities through enhancements in the emulated brain. We can ask why brain health would matter at all. To understand why, consider how natural brain health differs from brain enhancement.Brains have evolved to grow and mature in a normal human body over one\u2019s lifetime. The more that a brain is allowed to grow and mature naturally, the more complete its emulation will be.</p> <p>It can be looked at as a scale of cost efficiency. Healthy brains are at a great advantage in regards to their expected outcomes when  emulated with minimal corrections. Any modifications to correct for disabilities will need to be designed, coded, and implemented; which accompanying risks and time consumption. The less additional engineering a brain requires in order to be emulated, the less risk and cost will be involved. Even if a healthy brain will undergo enhancement procedures to receive superhuman abilities it will be less costly if it does not also need treatments to correct for any disabilities.</p> <p>A Higher Priority to Incorporate a Lifestyle that Promotes Brain Health</p> <p>There is not much difference in the answer to the question \u201cWhat must one do to keep one\u2019s brain healthy for emulation?\u201d than any other question about general brain health. There are some new factors to consider however.</p> <p>It is the natural tendency for humans to \u201cpay for it later\u201d with several health choices. It is part of an evolutionary trait that ultimately pertains to the survival of genetic code. In anthropology, humans have evolved to take care of their health in a way that maximizes the likelihood of  dominating the gene pool. Take this classic example: some people think that smoking is cool. If they smoke, they look cool and they look appealing to the opposite sex and eventually have kids. In later life, they may have severe health consequences, but they still played their procreative role by passing on their genes. Furthermore, many doctors are seen smoking during their breaks despite their commitment to promoting health. In this case the doctor values the stress relief of nicotine over the health risks the doctor must eventually face because of the \u201cpay for it later\u201d evolutionary trait to prioritize health habits based on a human body\u2019s traditional evolutionary purpose.</p> <p>Now we have to ask ourselves, \u201cHow is the brain health equation different when preparing for emulation?\u201d The difference is that in this case the brain\u2019s need for sustaining efficiency is not catering to the age determining efficiency of the human body. There is no reason to \u201cpay for it later\u201d when it comes to making decisions that affect brain health. In other words, your expectation is no longer that your brain health and cognitive life will last only as long as your body\u2019s health.</p> <p>With that in mind, someone who plans to live on through whole brain emulation and mind uploading, may be particularly inclined to make lifestyle choices that promote brain health.</p>"},{"location":"Blog/Posts/BrainQuantum/Post/","title":"Is the Brain a Quantum Computer?","text":""},{"location":"Blog/Posts/BrainQuantum/Post/#is-the-brain-a-quantum-computer","title":"Is the Brain a Quantum Computer?","text":""},{"location":"Blog/Posts/BrainQuantum/Post/#a-summary-of-an-argumentative-paper-by-litt-eliasmith-kroon-weinstein-and-thagard","title":"A summary of an argumentative paper by Litt, Eliasmith, Kroon, Weinstein, and Thagard","text":"<p>Consciousness, learning, perception, and memory are mental phenomena that are essential for defining the self and identity. With the rise of quantum computing, theorists have compared explaining mental phenomena to quantum computing in that non-local entanglement and superposition can lead to the possibility for such mental phenomena to exist. However, researchers at the University of Waterloo argue that quantum computing is not essential for explaining mental phenomena like consciousness. Their claim is that mental functions are best explained by neurocomputations rather than quantum mechanics.</p> <p>Quantum computing is based on the use of so-called qubits (quantum bits). Unlike standard bits, 1s and 0s, of classical computing, qubits can have both 1 and 0 existing simultaneously as the state of a single bit using superposition. The advantage of quantum computing over classical computing is processing speed for certain types of applications. Quantum computing maximizes the optimal processing number of computations per calculation.</p> <p>It is important to note that a complete understanding of the brain's structure, like a complete understanding of any physical thing, depends on quantum mechanics at the sub-atomic level. However, for explaining brain function, quantum mechanics are irrelevant. The logic gate (specific inputs lead to specific outputs) is the standard operation for classical computing. The timing for a neuron spike firing is relatable to the processing speed of a logic gate rather than a quantum computation. Furthermore, like neuron spikes in the brain, logic gates in classical computations are resistant to static noise. Based on the timing and power required for a neuron spiking, any quantum mechanical instances are considered as noise. The environment of an efficient quantum computer is also drastically contrasted to that of a brain.</p> <p>There is an important reason for keeping quantum computers in extremely cold environments. In order for qubits to maintain their superposition they must be well isolated from any interference. The lower the temperature, the more isolated the qubits are. The human brain is a warm and wet mass. The brain environment is no where near capable of sustaining isolated qubits. Furthermore, there is the fact that error correction is a real thing that brain neural spiking is capable of. Digital computers are also capable of error correction. Quantum qubits, however, are impossible to correct for error because the superposition would collapse. The natural evolution of the brain is far more efficient for survival than any quantum computing machine. Aside from the computational and the biological arguments, there is also the physiological argument.</p> <p>It has been theorized that the subconscious precursor process to a conscious thought is the collapse of qubits in microtubules in neurons due to quantum gravitational effects in space-time. These theories have been countered by developments in the continuous understanding of biochemical interactions at the molecular level. It is expected that quantum theories about consciousness will be superseded by the continuation of neurocomputational understanding. While there is no proof against the possibility that quantum mechanics have significant impact on the functionality of the brain, it has been evidenced that the explanation of brain function is far more relatable to classical computation in terms of computational, biological, and physiological arguments.</p> <p>\"Although the discovery of solid evidence for fundamentally quantum characteristics of mental phenomena would be tremendously exciting, current ideas fall well short of this standard.\" (Litt, Eliasmith, Kroon, Weinstein, and Thagard, 2006)</p> <p>For further details on the paper, and the arguments against quantum mechanics explaining brain function, please follow the link: Is the Brain a Quantum Computer?</p>"},{"location":"Blog/Posts/ChineseRoom/Post/","title":"Does the Chinese Room Thought Experiment disprove true AI and mind uploading?","text":""},{"location":"Blog/Posts/ChineseRoom/Post/#does-the-chinese-room-thought-experiment-disprove-true-ai-and-mind-uploading","title":"Does the Chinese Room Thought Experiment disprove true AI and mind uploading?","text":"<p>by Angel Okoro</p> <p>What about the Chinese Room thought experiment by Searle, doesn't that disprove true AI and mind uploading?</p> <p>The Chinese Room Argument is a thought experiment designed by philosopher John Searle and published in his article, Can Computers Think? This experiment is in opposition to strong-artificial intelligence (AI), specifically to claims that computers may someday be able to have cognitive states. Searle argues that cognitive states must have semantic content, yet programs are purely syntactic, and that computers are constrained by structures that disallow them from creating their own meaning.</p> <p>To make this argument, Searle imagines a \u201cChinese Room\u201d in which a person receives a string of Chinese characters, and using a computer, returns the appropriate response in Chinese. The person has no understanding of the Chinese language yet using syntactic and instructions, the person is able to mimic an understanding of Chinese. Searle demonstrates that an ability to follow formal instructions and produce appropriate responses does not equate to an understanding, due to the lack of semantic content. Similarly, a computer that substitutes for said person, would not understand Chinese.</p> <p>Criticisms of the Chinese Room argument fall into five categories: The Systems Reply, The Virtual Minds Reply, The Robot Reply, and The Brain Simulator Reply, and The Intuition Reply.</p> <p>The Systems Reply: Some critics argue that while the person in the room does not understand Chinese, the room as an entire system, which includes the database, the instructions, and the processing mechanisms, might be able to create its own understanding. Creators of this reply argue that the intelligence is a causal effect rather than an innate possession. Comparatively, the human brain does not carry intelligence on its own, but rather it gains intelligence through its induction to novel concepts.</p> <p>The Virtual Minds Reply: Like the Systems Reply, the Virtual Minds reply argues that understanding can be created by the system, even if the person in the room does not understand. However the Virtual Minds reply expands on this adding that the system may create its own sub-systems, distinct virtual agents, separate from the entire system and the room operator, that can understand Chinese independently. Philosophers of this thought argue the claim of strong AI should not be whether or not the computer understands Chinese, but rather if in the process of running the computer, an understanding of Chinese is created.</p> <p>The Robot Reply: The Robot Reply proposes that if the computer was to be embedded in a robotic body, which has access to the physical world, it could be stimulated by a variety of sensors and motors, similar to the human brain. In incorporating sensorimotor cues, the robot would be able to create understanding.</p> <p>The Intuition Reply: Searle\u2019s argument is based on the intuition that the computer cannot think or have understanding. Philosophers of this reply argue that a human-centric definition of understanding should not be relied upon to judge computers. The fact that humans cannot perceive understanding and semantic content in computers does not in itself negate their existence. Searle often makes arguments based on his own intuition and biases about the capabilities of inanimate objects, stating that \u201cwe find it natural to make metaphorical attributions of intentionality to them[objects]; but I take it no philosophical ice is cut by such examples.\u201d However, his arguments stop short of containing neutral, universal facts. Yet Searle often uses this same lack of impartiality to oppose the arguments of others. When debating the Systems Reply, Searle contends that, \u201cthe systems reply simply begs the question by insisting without argument that the system must understand Chinese.\u201d To Searle, insistence should only be admonished when applied to others.</p> <p>The Brain Simulator Reply: This reply considers a computer that operates in a different manner than current AI programs that rely on operations and instructions. This computer simulates the every nerve and every neuronal firing that would occur in the brain of a native Chinese speaker. Since the computer operates exactly as the brain of the native speaker, and processes information in the same way, it should also understand Chinese.</p> <p>Most rebuttals of this experiment are valid, however I would like to present my own reply- a blend of various previous replies.</p> <p>The Chinese Room is flawed due to its vague definitions of \u201csemantic knowledge\u201d and \u201cmeaning.\u201d The International Encyclopedia of the Social &amp; Behavioral Sciences defines semantic knowledge as \u201ca type of long-term memory consisting of concepts, facts, ideas, and beliefs.\u201d Semantic knowledge is an individual interpretation of words and objects. For example, answering the question \u2018What does the word bookshelf mean?\u2019 requires semantic memory. Recent advances in deep neural networks have enabled computers to better understand the world. Through unsupervised machine learning, computers can draw inferences from datasets without labeled responses or human supervision. For example, computer scientist Dr. Jason Yosinski at Cornell University developed a Deep Visualization Toolbox, a deep neural network, that uses mathematical manipulation to turn the input into the output through a series of non-linear hidden layers. In addition, this toolbox reveals the activations produced in the hidden layers.</p> <p>Let us go back to our example: \u201cwhat does the word bookshelf\u201d mean? The Deep Visualization Toolbox, learned to recognize printed text in a variety of sizes, colors, and fonts despite the fact that this was never manually coded into the network. The only reason the network learned features like text in the deep layers was to support final decisions in the output layer. For example, the text detector may provide evidence that the rectangle of a book and detecting multiple books next to each other might be indicative of a bookcase, which was in fact one of the input images used to train the toolbox. If we were to ask the toolbox for its own definition of a bookshelf, it might tell us that a bookshelf is an object with multiple rectangular objects that contain text. This coincides with the definition of semantic knowledge as an individual\u2019s stored interpretation, verifying that computers can in fact form semantic knowledge.</p> <p>Searle argues that not only does the computer lack knowledge, it also lacks \u201cintentionality\u201d. Searle defines intentionality as \u201cthat feature of certain mental states by which they are directed at or about objects and states of affairs in the world. Thus, beliefs, desires, and intentions are intentional states; undirected forms of anxiety and depression are not.\u201d To have intentionality, one must have mental states, such as thoughts and desires, ties to particular objects or concepts. It is not enough for the network to know of bookshelves, the network must have its own meaning, its own dispositions about bookshelves.</p> <p>However, one could argue that the lack of meaning comes from a lack of context, rather than from an innate inability of the computer itself. One could examine this through Mary's Room, a thought experiment proposed by the philosopher Frank Jackson. Mary knows everything there is to know about the physical properties of color, yet she has never experienced color, therefore she may or may not have a meaning for color. This thought experiment serves to question a materialistic explanation of understanding, and to question whether meaning requires context and experience. It is incontrovertible that Mary as a sighted human has the ability to perceive color and to assign it meaning, yet it can be debated whether she lacks meaning in her current state. If having the physical knowledge of color coupled with the ability to see color is enough to verify that Mary can assign meaning to color, that should hold for computers as well. To return to the Robot Reply and the Intuition Reply, perhaps the lack of intentionality and meanings spawns from a lack of personal sensation. If the computer was removed from the vacuum, placed into a \u201cbody\u201d that allowed for sensory input and context, perhaps it would develop meaning and intentionality for the objects in its surroundings.</p> <p>Baltes, Paul B., and Neil J. Smelser. International Encyclopedia of the Social &amp; Behavioral Sciences. Elsevier, 2001.</p> <p>Cole, David, \"The Chinese Room Argument\", The Stanford Encyclopedia of Philosophy (Spring 2020 Edition), Edward N. Zalta (ed.), URL = https://plato.stanford.edu/archives/spr2020/entries/chinese-room/.</p> <p>Jackson, F., 1982, \u201cEpiphenomenal Qualia\u201d, Philosophical Quarterly, 32: 127\u2013136.</p> <p>Nida-R\u00fcmelin, Martine and O Conaill, Donnchadh, \"Qualia: The Knowledge Argument\", The Stanford Encyclopedia of Philosophy (Winter 2019 Edition), Edward N. Zalta (ed.), URL = https://plato.stanford.edu/archives/win2019/entries/qualia-knowledge/.</p> <p>Searle, J., 1980, \u2018Minds, Brains and Programs\u2019, Behavioral and Brain Sciences, 3: 417\u201357</p> <p>Yosinski, J., &amp; Lipson, H. (2015). Understanding Neural Networks Through Deep Visualization. Deep Learning Workshop, 31 St International Conference on Machine Learning. URL = http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf</p>"},{"location":"Blog/Posts/Computation/Post/","title":"Single Neuron Dynamics and Computation","text":""},{"location":"Blog/Posts/Computation/Post/#single-neuron-dynamics-and-computation","title":"Single Neuron Dynamics and Computation","text":""},{"location":"Blog/Posts/Computation/Post/#an-article-review-on-research-in-neuron-plasticity-and-dendritic-arbor-anatomy-by-brunel-hakim-and-richardson","title":"An Article Review on Research in Neuron Plasticity and Dendritic Arbor Anatomy by Brunel, Hakim, and Richardson","text":"<p>When looking at the inner workings of the brain at its most basic component, the neuron, forms the basis of the brain\u2019s ability to send signals from one location to another.</p> <p>Neurons generate the electrostatic spike that signifies neural activity.</p> <p>Most people are familiar with the neuron being compared to a basic input-output signal, like an on-off switch.</p> <p>More recent additions to the study of neuron dynamics, however, shed some light on how the neuron is actually more complex in that neurons need to be able to adapt the way they receive and send electrostatic signals based on different rates and magnitudes of input signals as well as the spatial properties of the signal path.</p> <p>The cycle of a neuron making a spike is that the signal to the neuron is made interpretable by the temporal filter. This filter makes the information received into a linear stream of data. this information is then used by the neuron to generate the spike firing rate which releases the spike signal as a non-linear stream of information to be sent to a receiving neuron.</p> <p>The point here is that not all input signals are the same. Each stage of the signal interpretation has to compensate for variances in signal strengths and rates. The output desired from a neuron is one that is linear and stable.</p> <p>Neurons also have to deal with the issue of noise. Noise is the electrostatic surrounding influences apart from the main electrostatic signal. Much like trying to listen to a radio with lots of static, the neurons in the brain (specifically the kernels) need to be able to reduce the influence from electrostatic signals that are not part of the signal trying to get information from one neuron to another.</p> <p>Neurons balance input signals by generating electrostatic signals to balance the amplitude rate of signals taken as input. The take away point from this part is that neurons can naturally modify their composition to optimize the information that they are receiving based on noise level and input strength. More variances come into play when differing signals are taken by dendrites (complex neuron structures for complex signal processing).</p> <p>Synapses (gaps between neurons) can have characteristics that produce slow signals (100s of milliseconds) or fast signals (10s of milliseconds) based on historical properties of the synapse. This is the topic of short-term plasticity. For a synapse with depleted neurotransmitter vesicles the signal strength will be slower and for synapses with high amounts of trigger releasing abilities will produce faster signals.</p> <p>Where this helps the signal balancing is by countering the high or low input signals by altering the synapse firing rate controlled by the amount of neurotransmitter vesicles. This is synaptic filtering.</p> <p>As shown, neurons have plasticity characteristics that help them generate the signals based on the electrostatic environments that the neuron is subjected to.</p> <p>Simulating neuron plasticity will require treating neurons as more than just basic binary transmitters.</p> <p>To read the article, please follow this link: Single Neuron Dynamics and Computation</p>"},{"location":"Blog/Posts/EcosystemForEM/Post/","title":"An Ecosystem for Emulated Minds","text":""},{"location":"Blog/Posts/EcosystemForEM/Post/#an-ecosystem-for-emulated-minds","title":"An Ecosystem for Emulated Minds","text":"<p>A Topic Article by Michael Ulrich</p> <p>Human evolution has been directed by environmental conditions of Earth. As human beings, we need essential things from our environment to live such as breathable air, food and water, Earth-normal gravity and Earth-normal atmospheric pressure. These are things that all biological humans need to survive. However, if humanity merges with machines, our biological needs will become less relevant. If human beings are no longer biological creatures, and instead have minds with emulated brains residing in an artificial substrate, what does this mean for our environmental essentials for survival? With the emergence of a human society that contains brain emulation on the horizon, a change in the definition of an \"essential ecosystem for humans\" is inevitable.</p>"},{"location":"Blog/Posts/EcosystemForEM/Post/#the-bare-environmental-essentials-for-an-emulated-society","title":"The bare environmental essentials for an emulated society","text":"<p>Traditional human beings with animal bodies may be fragile and vulnerable compared to persons with emulated brains that store secure backups; yet even a world of digital people needs essential resources from the environment to survive. In comparing an emulated person residing in an artificial substrate to a software program on a computer, it could be rationally claimed that emulated people need electricity, hardware fabrication materials, and atmospheric pressures less than those that would crush a computer chip, and with temperatures lower than that whose which would melt a computer chip. Technology can be developed to protect these \"chip people\" to an extent; yet this will require more fabrication material and power.</p> <p>Taking a broader perspective, the essentials for a society of \"chip people\" to survive can be analogous to the essentials for a network of computers to collaborate and persist over spans of time greater than the time since the first gargantuan computers (e.g. Colossus in 1943) to today. Obviously,  persons with emulated brains will want to communicate with each other to some degree. Assuming that there is still individual consciousness in this hypothetical world, rather than a single massive hive mind with no separable identities, emulated persons will likely benefit from collaboration with one another to keep their emulated brains in top shape and without decay. Communication may be important if emulated persons will be responsible for helping biological persons to join the emulated population. An emulated ecology may need to be able to support communication between distinguishable emulated minds if communication results in some needed collaboration effort. Electricity and signal transmission are essential.</p> <p>Comparing the bare essentials for the survival and thriving of a society based on humans with emulated brains  with those for biological human societies, it is clear that environmental limitations imposed on biological humans are far more restrictive than those imposed on humans with emulated brains.</p>"},{"location":"Blog/Posts/EcosystemForEM/Post/#a-cambrian-explosion-like-evolutionary-divergence","title":"A Cambrian Explosion-like evolutionary divergence","text":"<p>It is clear that a list of bare essential ecological conditions are needed to sustain a society of people with emulated brains. The complete list of essentials for a given people with emulated brains, however, depends on the societal organizational structure defined by new path of evolutionary pressures a given group has taken. Perhaps, an emulated society has become totally digital versions of their minds. They exist in virtual environments and minimally influencing the physical world around their artificial substrates housing their minds. This kind of ecology might have minimal reasons to construct ways to control the natural environmental processes, whether that be a future Earth environment, the vacuum of space, or another planet. Their main ecological concern would be the conditions necessary to sustain their substrates. Alternatively, an emulated society may have kept their abilities to interact with the physical world freely by housing their emulated consciousnesses in engineered bodies with sensory inputs, robotic limbs, and mobility. Such a society of \"mechanical people\" would likely have additional ecological concerns compared to the example society of completely digital people living in virtual worlds. The environmentally influencing people would need ecological conditions capable of sustaining an infrastructure and the means to sustain their mechanical engineered bodies.</p> <p>These examples of future emulated societies are only two out of infinite possible outcomes for what human beings will become in the future. In a recording of the Carboncopies 2019 Winter Workshop Event, Dr. Ken Hayworth and Dr. Randal Koene discuss several possible outcomes for human evolution divergent paths with the introduction to realized Whole Brain Emulation. It is likely that many possible paths for humanity to take will happen at the same time, like a second Cambrian explosion of evolution. The likely groups of post-emulation societies could range from groups of pure biological humans avoiding emulation, to groups of humans who discarded their individual consciousnesses to merge with other emulated humans to become one massive singular consciousnesses.</p> <p>It is not illogical to predict some kind of conflicting living standards among the post-emulation human groups. While the mechanical individuals may want electricity for equipment to build roads, the singular mind might rather use the electricity resources to expand it's computing power. In any case, the future, and the vastness of the universe, could likely hold several different emulated societal ecosystems coexisting around each other.</p>"},{"location":"Blog/Posts/EcosystemForEM/Post/#how-about-biological-existence-in-a-world-with-uploading","title":"How about biological existence in a world with uploading?","text":"<p>There is a possibility that the emulated societies of the future will live alongside other human beings still catering to their biological way of life. A continuing population of biological human beings may persist for a variety of reasons. An important reason is free choice or preference. It is also possible that this situation might exist for some period of time due to delays in the availability of whole brain emulation technology, depending on factors such as local regulations, financial accessibility, or dissemination of knowledge, though we would hope that such imbalances would be minimized as much as possible in the process of the wide-spread introduction of the technology. Still, the emulated society will not let their advancements be held back by any restrictions that may be affected by the group of non-emulated peoples.. In some ways, biological human populations may find themselves at a disadvantage compared with their uploaded kin, even if uploaded society is more than happy to engage with, entertain and support their biological cousins. For instance, emulated people do not need to spend time and resources to produce food and water, they do not need breathable air, and they can survive in the vacuum of space. The group of biological humans remaining will still need to be concerned about these ecological essentials, in regards to sustainability, if they rely on their continuation to support these essentials. People with emulated brains will still need to acquire resources that are essential for their survival, such as energy and construction materials. In a practical outcome, the emulated society would develop methods for resource gathering that does not conflict with groups with fewer advantages. For instance, resources of materials can be gathered from asteroid mining and energy from solar arrays as opposed to destructive methods that would cause harm to the Earth\u2019s environment.</p> <p>In his comment on the ecology for mind uploading, Joe Strout mentions the future possibility of emulated people maintaining habitable environments for people who are still biological. With the technological aid of the emulated group, containment structures for environments with ecological essentials that biological humans need such as air, food and water, Earth-like gravity and atmospheric pressure, would allow the remaining biological human race to keep on living in the scenario of the Earth becoming otherwise inhabitable by overheating or contamination.</p>"},{"location":"Blog/Posts/EcosystemForEM/Post/#what-this-means-for-humanitys-relationship-with-earth-after-emulation-is-realized","title":"What this means for humanity's relationship with Earth after emulation is realized","text":"<p>Environmental preservation is prevalent in mainstream discussion. There is a real growing threat to the preservation of essential ecological conditions of Earth for the long-term survival of humanity. In the far future (millions of years), the environment of the earth will become more and more inhospitable to biological human beings. Aside from environmental hazards caused by industry, astrophysical phenomenon will cause Earth's atmosphere to be more hostile to the natural ecosystems. Further into the future from this point, whether by overheating or the sun ending it's main sequence cycle, the Earth will not be able to sustain life at all in the natural sense that humans have thus far depended on for ages. At this point, humanity will have expanded their ecosystems into  space.</p> <p>Given this far future certainty, the emulated populations will have greater chances at survival compared to biological humans. This is because their ecological essential requirements are more able to cope with the environmental changes that the Earth' will impose. The ecological systems of emulated societies will likely adapt with to the changing environment of Earth. As the atmosphere becomes too hot to sustain moisture, having the ability to not need water or breathable air will give emulated humans an advantage in survival. Furthermore, human expansion will likely have reached places far beyond the Earth such as other Earth-like planets in our galaxy, asteroids, and space stations orbiting the sun.</p> <p>With the introduction of Whole Brain Emulation, humanity's ecological requirements will change drastically. No longer will humans need essential environmental conditions to survive that their organic bodies demanded. This opens opportunities to explore further and survive longer in a changing ecological future.</p> <p>For further reading, please see the reference sources:</p> <p>Ecology of the Future by Dr. Joe Strout</p> <p>Carboncopies Foundation Winter Workshop of 2019: AI Safety and Whole Brain Emulation</p>"},{"location":"Blog/Posts/Enhancement/Post/","title":"Experimental Enhancement of Neurophysiological Function","text":""},{"location":"Blog/Posts/Enhancement/Post/#experimental-enhancement-of-neurophysiological-function","title":"Experimental Enhancement of Neurophysiological Function","text":""},{"location":"Blog/Posts/Enhancement/Post/#a-summary-of-an-opinion-article-by-diana-deca-and-randal-koene","title":"A summary of an opinion article by Diana Deca and Randal Koene","text":"<p>Enhancing brain function has long been a desirable goal by neuroscientists and trans-humanists alike. Experimental procedures using drugs, sensorimotor stimulants, and neural prostheses have shown practical results demonstrating how neural activity can be stimulated directly through influences outside a test subject's brain.</p> <p>Animal studies have shown that  stimulation methods using optical and electrical signals can enhance learning speed. Micro-stimulation of a monkey's frontal eye lids can induce eye fixation. Saccadic eye movement has been determined as a visual prosthetic for neuronal activity. Inhibition of the eye movements using stimulation improved learning capabilities in the test subjects. This kind of neuromodulation via optogenetics is now a common method in animal studies of neural function manipulation.</p> <p>Microstimulation of the neurons, instead of sensory stimulation, was also able to show improvements in learning capabilities. Electrical input can replace sensory input when applied directly to the neuronal network using electrodes. Electrical stimulation via electrodes in non-human primate studies was able to direct visual attention when FEF neurons were stimulated.. The effects of chronic self-stimulation through electrode activation were first demonstrated in  an experiment in which rats would pull a lever for drugs that interfere with their dopaminergic system.</p> <p>The ability to control prosthetic limbs has been tested in human and non-human primates using an understanding of motor control coding and cortical mapping. Implantable devices with multi-site neural interfaces can deliver electrical signals that control other devices such as a computer cursor, television remote control, and a prosthetic hand. The next phase for this kind of testing will apply neural interfaces to higher cognitive functions to control more dynamic machine operations such as an entire prosthetic arm.</p> <p>Neuroprosthetics have been developed to support memory encoding. The prosthesis was tested in rodent hippocampus and achieved enhanced memory performance. Similarly, application of the prosthetic model hippocampus to support input and output coding in hippocampal regions of non-human primates also showed improved memory and consequent improved performance in a decision task.. This procedure is currently being tested using volunteer human patients. Other prosthetic experiments include restoring motor function, emulating circuit function in the cerebellum, and retention of the eye-blink reflex in a rat subject.</p> <p>Exploring the neural enhancement techniques described above provides important insight to methods for the analysis of the brain\u2019s connectome and neural circuit function. The underlying neural mechanisms for neural stimulation are still unknown. Control of specific functions is obtainable through microstimulation and optogenetics. Neural prostheses and implants provide data that show neurophysiological substrate causality with learning and decision making. With these methods there are explanations for how neural enhancement may be possible through external sources..</p> <p>To explore more advanced features of neural circuit function and the underlying mechanisms, small animal subjects (e.g. the fruit-fly dosophila, the honey bee, etc) will be tested using these same procedures. Because of these subject's more simplified connectomics, observing the underlying neural mechanisms will be easier. With greater understanding of the neural mechanisms, there will be greater potential to enhance the neural functions of primates (and humans).</p> <p>For more information, please read the original article on the site of the academic journal Frontiers in Systems Neuroscience: Experimental Enhancement of Neurophysiological Function</p>"},{"location":"Blog/Posts/FromHere/Post/","title":"Where We Go From Here","text":""},{"location":"Blog/Posts/FromHere/Post/#where-we-go-from-here","title":"Where We Go From Here","text":""},{"location":"Blog/Posts/FromHere/Post/#an-introduction-to-the-carboncopies-foundation-2019-summer-event-updating-the-roadmap-to-whole-brain-emulation-part-2-where-we-go-from-here","title":"An Introduction to the Carboncopies Foundation 2019 Summer Event \"Updating the Roadmap to Whole Brain Emulation Part 2: Where We Go From Here.\"","text":""},{"location":"Blog/Posts/FromHere/Post/#by-dr-randal-koene","title":"by Dr. Randal Koene","text":"<p>Whole brain emulation is the technical term for a process by which the very specific functions of a brain can be recreated so that a mind with particular characteristics, memories and experiences is produced. It is the process for mind uploading.</p> <p>In all likelihood, whole brain emulation is physically possible, though very difficult by today\u2019s standards.</p> <p>The beginnings of what will be involved to achieve a whole brain emulation are visible today in the efforts of neuroscientists. Indeed, we could say that whole brain emulation should be a natural outcome of successful neuroscientific study as the domain of neuroscience matures toward a complete understanding and an ability to computationally model brain mechanisms.</p> <p>Consequently, my response when asked about the timeline for whole brain emulation is often this: I would be extremely surprised if it was accomplished within 20 years, but I would be equally astonished if it did not happen within 100 years, assuming that infrastructure, economy and science continue as they have.</p> <p>By historic, evolutionary and certainly by astronomical standards, 100 years is not even a blink of the eye. In other words, if we assume that humanity continues to thrive and strive, then we can also assume that humanity is right now on the very cusp of achieving whole brain emulation, and by extension, mind uploading.</p> <p>Just a little over 10 years ago, in 2008, the first attempted roadmap toward whole brain emulation was published by the Future of Humanity Institute at Oxford University. I was involved in that publication, which featured the collected and edited output of a group of researchers who convened at Oxford in 2007 for the first workshop on whole brain emulation.</p> <p>The first roadmap was necessarily incomplete at the time; and it focused heavily on a subset of the problems of whole brain emulation. It is time to compile the knowledge and the data for the updated version of the roadmap. To that end, on June 16<sup>th</sup> of this year, the Carboncopies Foundation launched a series of events that are aimed at presenting updated accomplishments and updated understanding to the public in preparation for the new version.</p> <p>In our first event of the series, Prof. Choe (Texas A&amp;M) gave us a peek at the scientific process for a better understanding of the phenomenon of consciousness, by devising models of neural dynamics that can predict aspects of consciousness. Prof. Song (USC) revisited patient-specific prosthetic neural model building and advances of memory decoding experiments with the neuromimetic hippocampal prosthesis. Prof. Parker (USC) reminded us of the importance to test the functional relevance of characteristics of biological neural signaling. Dr. Deca (NeurobotX) presented grid cell responses as an example where evolved coding (in this case for space) may enable superior autonomous navigation. She posed this as an example of the interplay between emulation of brain mechanisms and insights for A.I. Dr. Hayworth revisited the state of the art in brain preservation, which has reached a point where reliable long-term brain preservation appears to be both possible and practical. Hayworth also emphasized the importance of WBE proof-of-concept studies and the overall need to build consensus around the connection between fundamental neuroscience research and logical outcomes with meaningful impact in the world. Prominent neuroscientists must take responsibility for this reality.</p> <p>The panel discussion then turned to the obvious question: Where do we go from here? Creating working models from extracted data, and validating results according to improved success criteria were foremost on the list.</p> <p>The second event of the series is scheduled for September 21<sup>st</sup>. It is titled, \u201cUpdating the Roadmap to Whole Brain Emulation, Part 2: Where We Go From Here.\u201d It asks the question: Imagine it is the year 2030 and we can collect all of the brain data that we expect to be able to collect \u2013 how do you use that to do whole brain emulation?</p> <p>The event will feature interviews and panel discussions, and we will explicitly ask the participants to take that step, to look beyond the predictable next engineering step and instead at the more significant problems that still need to be solved. So that we may separate philosophy from physics, we will address this for a tiny animal first, before we ask about human mind uploading.</p> <p>In the June 16<sup>th</sup> event, we already learned that aldehyde stabilized cryopreservation may be the solution for the long-term storage of brain tissue in a manner that preserves every relevant detail of the structure of the brain\u2019s connectome. We look at that, and we say brain preservation is scientifically a solved matter. Turning it into a reliable process that can be used for human-size brains is an engineering problem that will make almost predictable strides in the coming years. We can write about those details, the milestones that are the peaks and valleys in the roadmap, but we don\u2019t need to worry much about discovering a path.</p> <p>We also learned about multi-beam and focused ion beam electron microscopy technologies that are multiplying the volume of brain tissue that can be accurately scanned in a reasonable amount of time at resolutions that show the details of the brain\u2019s connectome which our consensus assumptions about whole brain emulation deem necessary. Certainly, there are still some questions about reliably identifying what has been scanned, or about methods to label what will be scanned via chemical or molecular means for such identification. But the capacity increases, that are needed to get to the point where imaging the connectome of brain tissue is possible at the scale of a human brain, are looking more and more like engineering challenges instead of fundamental scientific questions. Again, we can write a lot about those details, but we are less worried about discovering a feasible path than we might have been 10 years ago.</p> <p>The first roadmap didn\u2019t say that much about electrophysiology or about collecting electrophysiological recordings from a very large number of sites throughout a living brain. That is a type of data collection that is crucially important to the characterization of brain mechanisms and systems. The road there still looks a little murkier, despite the efforts of the Human Brain Project, the Brain Initiative, the Allen Brain Institute, and many others. Multi-site recording is beginning to take off, but its ultimate potential, and the optimal technology path, is still a little uncertain. There may be several paths worth taking; therefore, there is some terrain the roadmap should suggest to explore.</p> <p>Notice that I haven\u2019t mentioned any models yet, any emulated brains or emulated pieces of brain. Those models are where it all has to be put together. In previous events, the Carboncopies Foundation has frequently highlighted the efforts by the Berger lab and its associates to create a neuroprosthesis for regions of the human hippocampus. We did that, specifically, to highlight this important problem of bringing the structure, the characterized functions, and the desired functional output together in one model, in one emulation.</p> <p>The hippocampal prosthesis project is an attempt to create such models, such emulations of a specific patient\u2019s brain function, and then to cast those into medical devices tailored specifically to that patient\u2019s needs. The results are preliminary though promising. The chosen system, in regions CA3 and CA1 of the hippocampus, is purposely structurally relatively simple. It means that researchers working on that prosthesis were able to focus on model building by combining well understood structure with characteristics of recorded data. That hasn\u2019t been possible in most other parts of the brain, where connectome details still need more data and more effort to reconstruct. The retina of the eye is one other relatively simple region where prosthetic modeling has been possible. So, this is where we begin to run into a multitude of scientific and applied science questions. There are many possible paths to follow and probably many studies to conduct.</p> <p>We would like the updated roadmap to describe not just the terrain historically covered, or the known engineering paths with predictions for the time from capability A to capability B. Rather, we would like the roadmap to look ahead to our goal. We would like it to include the best ideas for exploration, and so we would like to ask the pioneers to consider the unknown pieces.</p> <p>Dear Pioneer, come with us into our virtual landscape. Imagine that you find yourself at the end of the path that has been taken so far, and even a little further \u2013 as far as we can comfortably see along the path. So, please imagine that it is 2030, and we have reached the point where brains can be preserved virtually forever, without any damage to connectome relevant matter. Please also imagine that scanning of brain tissue at Electron Microscope scale has reached the point where the details of entire brains can be digitized in reasonable time and at reasonable cost. Perhaps these are Drosophila brains in 2030. That\u2019s fine. Let\u2019s also assume that labels and other identification methods allow us to automatically process the image data into 3-dimensional maps that show the locations of, the spatial dimensions of, and the connections between all of the identified scan content. Imagine therefore, that we have in 2030 (or is it 2040?) a process that can convert the preserved tissue of a brain into a reasonably reliable and accurate full connectome, synaptome, etcetera-tome of that brain.</p> <p>Let\u2019s first assume that we want to create a working whole brain emulation of a Drosophila with its 135 thousand neurons. Where would you take us next on our exploratory journey to this goal?</p> <p>Keep in mind that the maps created with the data that was acquired are not working models. They are a collection of data without processes to run. They are the image of the sea, not the sea roiling under the influence of gravitation and winds.</p> <p>Perhaps, first it would be a good exercise to know a little bit more about the goal. For our whole Drosophila-brain emulation, what are the success criteria that we use to determine if a successful emulation was built?</p> <p>Is there a systematic process that you can imagine \u2013 and which we can then discuss in detail for the updated roadmap \u2013 by which all of those brain tissue maps are converted into processes, including the constraints and means of validation that are needed to determine that the resulting processes are not just any processes, but are indeed those that generate a successful whole brain emulation of that specific Drosophila?</p> <p>What are the main difficulties you can imagine? For example. are you at all worried about justified scale separation in a complex system? Are there important alternate routes to consider that you can already see in the distance?</p> <p>That was quite the hike! Awesome.</p> <p>Now, for the next step, let\u2019s assume that we want to create a working whole brain emulation to upload your mind.</p> <p>Are there any new success criteria that need to be met? And do those raise any additional difficulties that we should discuss before we embark on that journey?</p> <p>Thank you. We\u2019ll be poring over this wonderful travel log, and then we\u2019ll be back with our next set of questions as we try to collect what we need to know for that updated roadmap. Your travels will tell us a lot about the updated state of what we might call the consensus approach to whole brain emulation:</p> <ul> <li>Several parts of the approach will have moved from scientific problems to being largely engineering problems that present a clear progress curve towards the required capabilities on a somewhat predictable timeline.</li> <li>Others will still contain basic scientific questions, even though the consensus about underlying assumptions is still strong. For example, that cognitive functions are accomplished by neurons that interact through the exchange of electrochemical signals, and that a separation of scales is possible whereby some aspects of the biological machinery behind that interaction are not in themselves crucial to the cognitive functions experienced.</li> <li>Finally, there may be some areas where our understanding has changed in important ways over the last decade, with new findings and insights that challenge specific assumptions of the consensus approach.</li> </ul>"},{"location":"Blog/Posts/HedgeOnWholeBrainEmulation/Post/","title":"A reason to hedge on whole-brain emulation for AGI","text":""},{"location":"Blog/Posts/HedgeOnWholeBrainEmulation/Post/#randal-a-koene-june-2024","title":"Randal A. Koene, June 2024","text":"<p>The following is nothing but a simple argument based on one of the significant insights explained in the Addendum to the essay \u201cI. From GPT-4 to AGI: Counting the OOMs\u201d (OOM stands for \u201corders of magnitude\u201d) in the series SITUATIONAL AWARENESS The Decade Ahead, by Leopold Aschenbrenner (2024). For context, here is a reprint of the Addendum:</p> <p>Quote</p> <p>Addendum. Racing through the OOMs: It\u2019s this decade or bust</p> <p>I used to be more skeptical of short timelines to AGI. One reason is that it seemed unreasonable to privilege this decade, concentrating so much AGI-probability-mass on it (it seemed like a classic fallacy to think \u201coh we\u2019re so special\u201d). I thought we should be uncertain about what it takes to get AGI, which should lead to a much more \u201csmeared-out\u201d probability distribution over when we might get AGI.</p> <p>However, I\u2019ve changed my mind: critically, our uncertainty over what it takes to get AGI should be over OOMs (of effective compute), rather than over years.</p> <p>We\u2019re racing through the OOMs this decade. Even at its bygone heyday, Moore\u2019s law was only 1\u20131.5 OOMs/decade. I estimate that we will do ~5 OOMs in 4 years, and over ~10 this decade overall.</p> <p> </p> <p>We\u2019ve been racing through the OOMs this decade; after the early 2030s, we will face a slow slog.</p> <p>In essence, we\u2019re in the middle of a huge scaleup reaping one-time gains this decade, and progress through the OOMs will be multiples slower  thereafter. If this scaleup doesn\u2019t get us to AGI in the next 5-10 years, it might be a long way out.</p> <ul> <li> <p>Spending scaleup: Spending a million dollars on a model used to be outrageous; by the end of the decade, we will likely have $100B or $1T clusters. Going much higher than that will be hard; that\u2019s already basically the feasible limit (both in terms of what big business can afford, and even just as a fraction of GDP). Thereafter all we have is glacial 2%/year trend real GDP growth to increase this.</p> </li> <li> <p>Hardware gains: AI hardware has been improving much more quickly than Moore\u2019s law. That\u2019s because we\u2019ve been specializing chips for AI workloads. For example, we\u2019ve gone from CPUs to GPUs; adapted chips for Transformers; and we\u2019ve gone down to much lower precision number formats, from fp64/fp32 for traditional supercomputing to fp8 on H100s. These are large gains, but by the end of the decade we\u2019ll likely have totally-specialized AI-specific chips, without much further beyond-Moore\u2019s law gains possible.</p> </li> <li> <p>Algorithmic progress: In the coming decade, AI labs will invest tens of billions in algorithmic R&amp;D, and all the smartest people in the world will be working on this; from tiny efficiencies to new paradigms, we\u2019ll be picking lots of the low-hanging fruit. We probably won\u2019t reach any sort of hard limit (though \u201cunhobblings\u201d are likely finite), but at the very least the pace of improvements should slow down, as the rapid growth (in $ and human capital investments) necessarily slows down (e.g., most of the smart STEM talent will already be working on AI). (That said, this is the most uncertain to predict, and the source of most of the uncertainty on the OOMs in the 2030s on the plot above.)</p> </li> </ul> <p>Put together, this means we are racing through many more OOMs in the next decade than we might in multiple decades thereafter. Maybe it\u2019s enough\u2014and we get AGI soon\u2014or we might be in for a long, slow slog. You and I can reasonably disagree on the median time to AGI, depending on how hard we think achieving AGI will be\u2014but given how we\u2019re racing through the OOMs right now, certainly your modal AGI year should sometime later this decade or so.</p> <p> </p> <p>Matthew Barnett has a nice related visualization of this, considering just compute and biological bounds.</p> <p>The Addendum does not spend a lot of time expounding on the \u201cor bust\u201d portion of the argument, but that part deserves equal attention.</p> <p>The principal argument of this Addendum is fairly easy to understand: If AGI / superintelligence is not achieved by the time compute clusters have reached the $100 billion to $1 trillion cost level then achieving AGI essentially through this form of scale-up is unlikely to be cost effective (compared, for example, with hiring actual researchers instead of AGI-based researchers to do research work).</p> <p>If that is the scenario that plays out then the development of AGI will depend on other factors, such as discovering and utilizing new system and algorithm insights, insights that may very well have to come from the human brain.</p> <p>Whether the scenario described in the Addendum plays out or not will be apparent within a few years. Consequently, for anyone who wishes to hedge their bets for the next decade, working on whole-brain emulation and the insights that come from that now makes a lot of sense.</p> <p>But why whole-brain emulation and not just neuroscience in general?</p> <p>In this context, think of \u2018whole-brain\u201d as pointing out the importance of understanding how algorithms utilized by different parts of the brain are used in concert to achieve things that would not be possible with a single algorithm, even if that algorithm was super-charged with compute power. Don\u2019t focus on the \u201cdeep\u201d learning architecture of just the prefrontal cortex. Don\u2019t focus on the way features are combined from simple-cells to complex-cells in visual cortex. Don\u2019t focus on the way auto-associative and hetero-associative networks are combined in entorhinal and hippocampal regions for one-shot acquisition and filtering of new episodic memory. Instead, make sure to consider the cooperation between strategies.</p> <p>And emulate actual circuitry at the level of detail obtained by high-resolution scans of specimen-specific brain tissue, in order to move away from purely correlational ways to make model hypotheses about brain function and towards causative circuit-level correspondence [see Jonas &amp; Kording, 2017] that can be validated, where a single thought process depending on specific learned patterns can be followed from beginning to end.</p>"},{"location":"Blog/Posts/IfSimulatedFireCant/Post/","title":"If Simulated Fire Can't Burn Wood, How Can a Simulation Really Think, Feel or be Conscious?","text":""},{"location":"Blog/Posts/IfSimulatedFireCant/Post/#how-a-simulation-of-a-persons-mind-can-still-think-feel-and-be-conscious","title":"How a Simulation of a Person's Mind Can Still Think, Feel, and be Conscious","text":"<p>An Opinion Response to, \"If Simulated Fire Can't Burn Wood, How Can a Simulation Really Think, Feel or be Conscious?\" by Michael Ulrich</p> <p>When discussing simulation of cognitive function, in the context of Whole Brain Emulation, there is an argument against the simulation being capable of having real cognitive traits. This argument compares a simulation of fire to a simulation of cognitive function. If the simulated fire can\u2019t do things that real fire can, like burn wood, then how could a simulation of cognitive function be capable of things that real cognitive function can do like think, feel, or be conscious?</p> <p>It is obvious that a simulation is not the real thing. If you want to have a real fire, a simulation will not satisfy that. But if you want to burn something like real fire can, a simulated fire could be made to be able to do that. Simulation does not mean \"effects in computer RAM only.\" This can be reflected with the simulated cognition situation. If what we want is real consciousness, real thinking, we can build a simulated cognition that can do that.</p> <p>Going back to the simulated fire, there are things about fire that we know in regards to how it burns something. Take another substance, like acid, that can also burn something, and use it to build the simulation. If you want to add heat to the fire simulation, also use infrared illumination.</p> <p>For simulated cognition, similar to how we know how fire burns things we need to know how cognition produces consciousness. Assuming consciousness (physically) is an electrical spike arrangement produced from the sequence of firing neurons in the brain, we can build the simulation of cognition with something else that can produce the same electrical spike arrangement such as computer transistors. Furthermore, each cognitive product, like thinking, memory, and feeling, can be simulated using the same tools.</p> <p>These cognitive products of the simulated cognition can, therefore, have real world effects using real world sensory input. For instance, they can be used to recognize cars or faces and can grant or not grant access based on that, just like a person recognizing faces. Not surprisingly, there is little debate about whether simulated perception/vision can achieve real-world recognition. The distinction between arbitrary artificial vision and simulated vision may just be that the simulated version is an artificial vision that tries to closely approximate the way in which human vision accomplishes the task.</p> <p>The misconception of comparing simulated fire to simulated consciousness, as a means to dis-affirm that simulated cognition can produce real cognitive products, comes from the misconception that making a computer simulation of cognition has the same purpose of creating a computer simulation of fire. The computer simulation of fire is meant to have only the real recognizable imagery that real fire produces. It has only this one real product that real fire produces. However, a computer simulation of cognition has everything it presumably needs to produce all real traits that real cognition can produce. This is because all real cognitive function products can be produced also by computers.</p> <p>Therefore, simulated cognition can produce real cognition products because the simulation has the same means to do so. Furthermore, comparing simulated cognition to simulated fire must be done by using the correct interpretation of simulation which is that the real causal effects from one object are duplicated in another (different) object. [Human cognition understanding is increasing. Much of the knowledge still has yet to be confirmed.]</p>"},{"location":"Blog/Posts/NeuralArchives/Post/","title":"The Neural Archives Foundation","text":""},{"location":"Blog/Posts/NeuralArchives/Post/#the-neural-archives-foundation","title":"The Neural Archives Foundation","text":""},{"location":"Blog/Posts/NeuralArchives/Post/#a-recognition-to-a-fellow-organization","title":"A Recognition to a Fellow Organization","text":"<p>For those who's interests have been captured by the exiting possibilities that the future of whole brain emulation has to offer, it may be no surprise that other organizations with related objectives have sprung to life in various places of the world. One such organization is helping the cause for brain preservation research by offering the public a cryogenic brain preservation service.</p> <p>Founded in 2005 the Neural Archives Foundation was a response to an increasing demand for brain simulation research. Philip Rhoades and James Newton-Thomas saw value in a non-profit organization that could help people have their neural tissue to be preserved in such a way that all of the brains information that defines an individual's consciousness remains intact. Having a storage of preserved minds like this would boost reason and cause for the advancement technological means to revive the brain's consciousnesses.</p> <p>Cryonics involves taking the brains of those recently deceased and preserving them in temperatures below -130 \u00b0C. The brain cells are dehydrated and compressed without losing the connections between cells necessary for brain function. When the means for achieving the revival of the preserved brains comes to fruition, the information in the brain, as designated as the individual's identity, can be uploaded and preserved onto an artificial substrate.</p> <p>This method of mind uploading from a deceased brain is referred to as the post-mortem method. This is in contrast to gradual replacement mind uploading in which the brain of a living patient is gradually embedded with artificial prosthesis by which the organic tissue and artificial substrate devices communicate and function symbiotically until the organic tissue is no longer needed to complete the entire brain's functionality.</p> <p>Patients who participate in this procedure by preserving their brains have high hopes that they will indeed wake up again.</p> <p>The Neural Archives Foundation is based in Cowra, Australia. Their associated storage facilities are also in Australia, but for security reasons there are no further details given. For donors who wish to participate, the cost for the services provided by the storage facilities is about $30,000 in Australian currency which is the rate for storing human tissue indefinitely. The property rights of the rest of the body of the donating patient are given to the next of kin.</p> <p>The Neural Archives Foundation guarantees that no experimentation will be conducted on the donor's tissue and they will guarantee the tissue will not be sold, which Australian law also upholds. They may perform an autopsy on the patient if it is in the public interest to do so.</p> <p>As a non-profit organization, the NAF is also accepting donations as a means towards their cause for promoting the preservation of human brains. Their contact information is provided below.</p> <p>Phone: +61 2 6342 2918 (Leave a message)</p> <p>Mail:</p> <pre><code>NAF\nPO Box 896\nCowra NSW 2794\nAustralia\n</code></pre> <p>Sources: http://neuralarchivesfoundation.org/ (The Neural Archives Foundation Home Page)</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/","title":"Neuromorphic Hardware Designs - A Quick Survey","text":"<p>Abolfazl Alipour</p> <p></p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#historical-backgrounds","title":"Historical Backgrounds","text":"<p>The brain is a fascinating mystery, 3 pounds of organic material that can generate consciousness, think about the origins of the cosmos, and even think about its own thinking. Making machines that can work and behave like brains is an old dream for humanity that has yet to be achieved. With the advent of computers in the 20<sup>th</sup> century, scientists started to think about the similarities and differences between brains and computers. On one hand, brains are similar to computers; they are connected to a set of sensors \u2014our sensory organs\u2014 and process electrical signals generated by those sensors to guide our behavior by sending electrical signals to our motor organs, the same way computers process information and display outputs on the screen. On the other hand, computers do not process their sensory information the way brains do. For example, as you are reading this text, each of your eyes compresses the information through one million \u201cstreaming lines\u201d in parallel and sends them to your visual cortex at the back of your brain. Once in your visual cortex, information is distributed and undergoes simultaneous processing in your brain to form concepts and meanings. This is different from conventional computers where information is queued in one/a few streams to be processed by one/a few central cores without being distributed across nodes. This distinction is one of several differences between brains and computers that help brains to be good at generating concepts, associations, logical relationships, etc. and computers to be good at multiplying two six digit numbers in a split second. Accordingly, scientists started to design chips and computer hardware based on our knowledge of how brains work and this approach is called the \u201cneuromorphic engineering\u201d [1].</p> <p>Early attempts to build neuromorphic chips date back to late \u201980s [2] but the first large-scale implementations only came in late 2000s [3]. Here, we will review major driving forces behind their development, major neuromorphic hardware designs and the latest technologies. At the end, we will discuss the implications of this field of research for whole brain emulation.</p> <p>**Driving forces behind development of neuromorphic chips: **</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#a-necessity-of-power-efficient-brain-simulators","title":"A. Necessity of power efficient brain simulators","text":"<p>A highly detailed simulation of the entire brain, down to the gene expression level,  needs processing power on the order of an exaflop (1018 operations per second) [4] which is approximately a billion average home computers running atonce and consuming the electricity of millions of households. However, best of the current supercomputers -as of November 2018- use 1 gigawatts of power to deliver the required computational power for such simulation [5] which is almost equal to output of a nuclear power plant. On the other hand, the brain only uses ~20 watts to operate [6]. Therefore, best current supercomputer uses 100 million times more power to deliver a the computational capability for detailed whole brain simulation. Accordingly, supercomputers might not be the optimal power efficient platforms for large-scale brain simulations.</p> <p>Meanwhile, other scientific fields addressed a similar problem through the development of Application Specific Integrated Circuits (ASICs). For example, Jun Makino in 2003 designed and built an application specific computer (GRAPE-6) to simulate gravitational forces between galaxies delivering the same amount of computation  (1 TFLOPs) at 1/16 the cost of a blue gene supercomputer [7].</p> <p>But what is an ASIC? To understand them, we will need to define a few terms and their differences:</p> <ol> <li>What is an IC?   IC just means integrated circuit. All different chips that we discuss in here are ICS (ASICs are ICs, FPGAs are ICs, neurmorphic chips are ICs, microprocessors are ICs.)</li> <li>What are microcontrollers/ Microprocessors? Microprocessors typically contain one or more processing cores (arithmetic unit, program decoder, memory addressing unit, etc) and they fetch instructions and data and execute those (Von Neumann style), for example, Intel\u2019s core i7 CPUs are microprocessors. Microcontrollers, however, contain a CPU plus RAM, ROM, and other peripheral parts on an IC, they are basically super small computers on an IC.</li> <li>What are ASICs, exactly? These are Application Specific ICs. They can contain compute cores (that's where the line gets fuzzy), but they often just contain a bunch of highly specific digital circuits that operate without a program (the program is baked in). Sometimes ASICs can even be analog and not digital!</li> <li>What is a FPGA? FPGAs are Field Programmable Gate Arrays. The arrays of gates are used to construct circuits, and those circuits can be reconfigured when the chip is 'flashed' and programmed 'in the field'. The need to work with a vast array of identical resources to build circuits means a little more overhead and wastage, so they are typically not quite as optimized, fast and energy efficient as microprocessors or ASICs. But they are extremely flexible and great for prototyping designs that you later bake into an ASIC (or microprocessor).</li> <li>What is a neuromorphic IC? An IC design that focuses on using a circuit layout that emphasizes a high degree of parallelism, similar to a neural net (as in software code). The design is sometimes baked in (it is an ASIC) and sometimes it is prototyped (it is an FPGA). For example, you can get the NM500 (a neuromorphic IC) as either an ASIC or as a software .zip file that you use to set up a common FPGA.</li> </ol> <p>Therefore, Application Specific Integrated Circuits (ASICs) seemed like intriguing solutions for implementation of neural simulations since they reduce power consumption and increase processing speed. They reduce power consumption because IC of an ASIC will contain circuits optimized for a specific set of functions, minimizing the number of steps (delay) and transistors involved (power) while carrying out the intended system operations. This has many advantages. We don't need to send any power to circuits that may be left in some sort of 'wait' cycle. We also don't need to 'simulate' the circuit operation you're trying to do by moving data into temporary buffers (registers), sending groups of them to an arithmetic unit in turn, storing temporary results, looking for results that were stored and that should be combined with this one (e.g. when input to neurons converges), carrying out another arithmetic process with more buffering of input data and temporary results to determine if a threshold was crossed, etc. Instead, we have independent pieces of circuitry that receive and operate on different parallel paths of input and that immediately (and actually) converge on another circuit that detects if a threshold is exceeded, etc. Thus, we don't need piles of complex machinery to build a high end CPU, memory, etc. Instead, we can dedicate the IC surface to doing a lot of simple things fast in parallel with minimal circuit designs. Ultimately, all of that means that the power-per-operation in an ASIC is much lower than in a general purpose CPU based system.</p> <p>In other words, speed will tend to go up for 2 reasons: (1) We are actually carrying out more simple operations truly in parallel (not in turns). (2) Lower power consumption means less heat per operation, which means you can afford to raise the processing speed (clock speed) without destroying the chip.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#b-an-opportunity-for-development-of-new-computer-architectures","title":"B. An opportunity for development of new computer architectures","text":"<p>Consequently, researchers started to simulate neural networks on ASICs from early 1990s (see[14-17] for examples). These chips provided something beyond just brain simulation: they also became a platform for a new - and perhaps revolutionary - computer architecture which turned into a second driving force for the development of these chips. More specifically, implementing brain-like computations at the hardware level can be a step towards creating the so called cognitive computers. These types of computers are designed to be more efficient than current Von Neumann architectures in performing brain like behaviors (both in terms of speed, power consumption, and processing capacity). Another idea behind this line of research is to use neuromorphic architectures to circumvent the Van Neumann bottleneck problem. In a Van Neumann architecture, because the memory and processor are separated, computations are limited by the communication bandwidth between the memory and the processor. A neuromorphic architecture can potentially solve this problem through massive parallelization.</p> <p>Here, we will look at the major neuromorphic hardware projects in the past two decades. We will first survey the chips that are designed mostly for research purposes and then we will look at the more commercial oriented designs.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#neuromorphic-hardware-designs","title":"Neuromorphic Hardware Designs","text":""},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#research-oriented-neuromorphic-chips","title":"Research-oriented Neuromorphic Chips","text":""},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#1-neurogrid","title":"1. Neurogrid","text":"<p>Graduate students Sam Fok (left) and Alex Neckar (right) hold the brain-inspired computational platform \"Neurogrid that had been developed under Kwabena Boahen\u2019s supervision in Stanford.</p> <p>One of the early successful neuromorphic chips that could simulate 1 million neurons with 1 billion synapses with 100,000 times less power consumption compared to a Blue Gene supercomputer. Neurogrid was a chip designed in 2006 for energy efficient and fast neural simulations [9], it had its first reported success in 2014 [19] It stores connectivity patterns into a memory table, and nodes on this chip can become single or multiple compartment neurons (a neuron with just a cell body or a neuron with dendrites). The chip can either simulate 1 million single compartment neurons or 100,000 ten compartment neurons. In other words, it can either simulate a lot of simple neurons or a few complex (multicompartmental) neurons. This chip is developed by Kwabena Boahen\u2019s team at Stanford University. Boahen\u2019s group intends to build the next version of Neurogrid called \u201cBrainstorm\u201d by the end of 2018. Brainstorm will be able to run SPAUN which is the first functioning model of the brain (accomplished with just a few million neurons). </p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#2-brainscales","title":"2. BrainScaleS","text":"<p>Brainscales was a major European project to develop a neuromorphic chip that was started in early 2011 as a successor of the FACETS project. Different from other neuromorphic chips, this chip uses wafer-scale integration.</p> <p>But what is wafer-scale integration?</p> <p>Briefly, in normal chip manufacturing process, several chips are printed on a single wafer so that if one of the chips turn out to be defective, other chips can stay usable. However, finding and separating these defective chips is costly. Using an entire wafer as a single chip circumvents these cost and of course, it is extremely challenging.</p> <p>However, wafer-scale integration in BrainScaleS is used for another reason:</p> <p>wafer-scale integration is used to enable the dense connectivity patterns that this architecture provides [30].</p> <p>On a single wafer developed by BrainScaleS project ( that has a diameter of 20 cm) there are 48 \u201creticles\u201d  (the small squares visible on the below picture) and each reticle contains 8 HICANNs (High Input Count Analog Neural Network, see picture for more detail). HICANNs are the core functional units of Brainscales. Each HICANN comprises 128,000 synapses and 512 membrane patches. Similar to Neurogrid, increasing the neuronal detail reduces the number of possible simulated neurons and vice versa. However, here, the neural detail that can be adjusted is is the number of synapses per neuron. Each Brainscales\u2019 wafer can either simulate 196,000 neurons with 256 synapses each (50 Million synapses in total) or 3000 neurons with 16,000 synapses each (~48 Million synapses) [12].</p> <p></p> <p>Each of the squares on the wafer is a reticle and each reticle contains 8 HICANNs. Each vertical column on the below picture (bottom right) is a HICANN. From [12-13].</p> <p></p> <pre><code>Neurons are implemented as analog circuits (see [20] for the general difference between analog and digital implementations) but synapses are designed as digital signals. See [this video](https://www.youtube.com/watch?v=nfqu-oe54qE) for a more detailed explanation. Another goal of this project is to start a new computing paradigm beyond the von Neumann architecture.\n</code></pre> <p>Practical Note: BrainScales support the use of PyNN for programming.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#3-spinnaker","title":"3. SpiNNaker","text":"<p>The 48-node (864-core) System that is used in SpiNNaker machines (photo courtesy of the University of Manchester).</p> <p>SpiNNaker is a neuromorphic hardware project started in 2005 with first prototype chips built in 2009. A standard SpiNNaker chip is a 10x10 cm board with 18 cores (~1,000 neurons each) and the biggest SpiNNaker machine (composed of a collection of chips) can simulate 1 billion neurons. This project is led by Steve Furber\u2019s team at the university of Manchester and it is a part of human brain project neuromorphic computing platform. In a 2012 paper, SpiNNaker group reported a successful simulation of Izhikevich neurons on spiNNakker with 100 nanojoules (nJ) per neuron per millisecond and 43 nJ per postsynaptic potential, which was the smallest quantity reported for any digital computer to the date [25]. At this rate, required power for simulation of all neurons in the brain (not synapses or postsynaptic potentials) on SpiNNakeer will be 8.6 watts (compare it to brain itself that uses 20 watts of power).</p> <p>SpiNNaker is used in different applications such as building a line follower robot, representing information through spiking activity of neurons, and also applications that are not necessarily related to neuromorphic engineering such as solving partial differential equations of heat flow. It is possible to use SpiNNaker by becoming a member of the human brain project community. Interestingly, you can use PyNN to simulate neurons in SpiNNaker. More information can be found on project\u2019s website.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#4-synapse","title":"4. SyNAPSE","text":"<p> DARPA SyNAPSE board with 16 TrueNorth chips</p> <p>SyNAPSE is a DARPA funded project with the aim of creating a neuromorphic architecture that can resemble functions of a mammalian brain with the same size and power consumption characteristics. Different companies and institutes are involved in this project but IBM\u2019s TrueNorth chip is one of the most well-known results of this project. This chip is a scalable neuromorphic chip with the end goal of building cognitive computers rather than simulating brain functions with its first prototypes revealed in 2011. Scalable means that the chips can be assembled together to form bigger chunks of neuromorphic hardware. This chip contains 4096 cores with 256 neurons each (around 1 million in total) and each neuron can have 256 synapses.</p> <p>The main goal of this project is to deliver functions and perform computations on a variety of multidimensional noisy data types. For instance, energy efficient object recognition had been shown previously [22] and audio signal processing, multisensory fusion are among the goals of this project [1]. Even though the primary goal of this project is to perform computations, this project is also at the forefront of large-scale brain simulations with a simulation of 530 billion neurons in 2012. However, this simulation was performed on \u201ca supercomputer that was simulating these neuromorphic chips\u201d rather than the actual neuromorphic chips. Besides, Markram (head of human brain project) criticized this simulation as a public relations stunt.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#commercial-neuromorphic-chips","title":"Commercial neuromorphic chips","text":"<p>Google\u2019s first Tensor Processing Unit (TPU) on a printed circuit board (left); TPUs deployed in a Google datacenter (right). From here.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#5-googles-tensor-processing-units-tpu","title":"5. Google\u2019s tensor processing units (TPU)","text":"<p>Google\u2019s tensor processing units (TPU) is an ASIC developed and owned by Google for machine learning purposes using tensorflow. TPUs use a specific architecture called systolic array where data moves in the array in a pulse like fashion. This specific architecture enables the TPUs to be efficient in matrix multiplication which is a vital part of artificial neural networks. The user can program TPUs to run convolutional, LSTM models, and large, fully connected models. Conceptually, this chip is designed based on the insight that artificial neural networks are heavily using matrix multiplication operation. Therefore, a chip that can perform efficient matrix multiplication can be efficient at running artificial neural networks. This design is more focused on computational practicality rather than biological realism needed for neural simulation. More information on the architecture can be found here. Unfortunately, these chips are not commercially available.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#6-intels-loihee-chip","title":"6. Intel\u2019s Loihee chip","text":"<p>Intel\u2019s Loihee chip is a newly developed chip that can be used for simulation of 130,000 single compartment neurons with 130 million synapses. More information here.</p> <p>There are several examples of commercial neuromorphic chips that are now on the market. These chips are popular in the smartphone industry because of their object recognition capabilities. Qualcomm, Apple, Huawei, and several other manufacturers are building neuromorphic chips that are generally called Neural Processing Units.</p> <ol> <li>Intel\u2019s Movidius chip which is a neuromorphic hardware on USB stick for $79. See this video for a demonstration of Movidius recognizing objects.</li> <li>NM500 is a neuromorphic chip with 576 neurons that can be used for pattern recognition problems such as vision, audition, etc. More information on neuromem website. Neuromem also offers a usb stick chip (similar to Movidius) called BrilliantUSB for $89 that is composed of NM500 chips.</li> </ol> <p></p> <p>Intel\u2019s Movidius chip</p> <p>NeuroShield is a shield board featuring the NM500 chip. It supports connection to Raspberry Pi, Arduino, PMOD, etc. that makes it a good option for prototyping on the edge AI devices. More information here.</p> <p></p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#fpgas","title":"FPGAs","text":"<p>FPGAs (Field-Programmable Gate Arrays) are chips with circuits that are configurable on demand by the programmer. These chips are composed of configurable logic gates that can be used to construct neuromorphic chips. Examples of such studies are Implementation of motion perception [10], image segmentation models [11], robotic locomotion [22], and several other applications [23-24]. Unfortunately, a widely used and well accepted high level programming language that can be used to configure FPGAs as neuromorphic chips is not present yet (as opposed to spiNNaker or BrainScales that can be used for neural simulation by PyNN).</p> <p>However, NeuroFlow is a new simulation platform that can be used with PyNN to configure FPGAs and run neural simulations. These simulations are 33.6 times the speed of an 8-core processor or 2.83 times the speed of GPU-based platforms on a 6-FPGA system. Meanwhile, we did not find codes of this project online.</p> <p>Additionally, Intel\u2019s FPGA boards (formerly known as Altera) provided a good platform and support for implementation of artificial neural networks and deep learning on FPGAs. Their solutions are aimed to provide practical applications of neural networks rather than neural simulation per se. Here is a demonstration of AlexNet (a deep learning architecture) on one of these FPGAs. See here for the wiki and here for the Intel\u2019s multiplatform computer vision solution called OpenVINO that can be used on their FPGA boards as well.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#neuromorphic-chips-based-on-reservoir-computing-framework","title":"Neuromorphic chips based on reservoir computing framework","text":"<p>Reservoir computing framework is another interesting approach that is being used to build neuromorphic hardware. In this framework, inputs are fed into a randomly connected neural network with fixed weights and then the repertoire of the network is read by a readout unit. The network generates many results for each input at a given time point (hence called a reservoir). The readout unit can choose which output it needs for each particular computational demand by changing its connection weights with the reservoir network nodes.</p> <p></p> <p>**The structure of an echo state network (a type of network in reservoir computing framework), from [26]. **</p> <p>These types of network are efficient in time series prediction and different designs were inspired by reservoir computing framework to build neuromorphic chips. A recent paper on this technology [27] achieved 99.9% accuracy on a time series recognition task. See this talk on one of the developed technologies and [26] for a review of the topic.</p> <p>There are other neuromorphic chip technologies that we have not covered in here such as:</p> <p>Eyeriss, MIT/DARPA</p> <p>Zeroth, Qualcomm</p> <p>Darwin, Hangzhou Dianzi U. &amp; Zhejiang U.</p> <p>Readers are encouraged to check the links for more information on each of these particular designs.</p>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#conclusion","title":"Conclusion","text":"<p>From a broader perspective, a whole brain emulation platform must meet a set of basic criteria:</p> <ol> <li>It should  be able to handle a very large number of neurons and synapses in a network.</li> <li>It should be able to emulate the spiking behavior of neurons. Similarly, it should be able to specify fair analogs of the different postsynaptic potentials, after-hyperpolarization, after-depolarization, etc.</li> <li>It should be able to achieve an average spike frequency at least on the same order as the average in biological neurons (e.g. 100hz, rarely 1000hz) to be able to run real-time emulations.</li> <li>It should be able to emulate spike timing dependent plasticity effects. Therefore, it should be capable of distinguishing smaller time differences than 1000 Hz, perhaps at the order of 10khz</li> <li>It should be a power efficient platform so that it can be used for more than one brain in the world, possibly for billions of them.</li> </ol> <p>Neuromorphic hardware technologies have the potential to pass these minimal criteria in the near future. In other words, neuromorphic hardware designs are the most promising technologies that can achieve real-time emulation of a whole brain at normal (or faster speeds) in a cost-effective and ecologically responsible way. This because these chips can bring down the power per neural and synaptic operation.</p> <p>Among all of the mentioned technologies, it seems that FPGA based solutions are one of the interesting topics to follow in the coming years because they offer a middle ground between power, flexibility, and cost. FPGAs can be sometime more powerful than ASIC neuromorphic chips. For example, FPGA designs are reported to be able to outperform Google\u2019s tensor processing units. Moreover, FPGAs are more flexible than ASICs since their reconfiguration takes hours to weeks of programing while reconfiguration of ASICs needs redesigning and manufacturing a new chip. Finally, FPGAs are considerably cheaper than custom made ASICs. However, we should note that FPGAs are still less power efficient compared to ASICs.</p> <p>Advancement of robotics and intelligent IoT (Internet of Things) devices will push the growth of this field on small scale of the spectrum while ambitious projects such as SyNAPSE will drive their development at a large scale.</p> <p>A simple comparison of some of the designs reviewed in this paper</p> platform Neurogrid SpiNNaker BrainScales SyNAPSE NM500 BrilliantUSB Google\u2019s TPU Intel\u2019s Movidius No. of single compartment Neurons/board* 1M 18K 196K 1M 576 2K 64K Not specified, 4T operations/sec No. of Synapses/board 1B arbitrary ** 50M 268M Neuron type Spiking Spiking Spiking Spiking ANN type ANN type ANN type ANN type <p>* all of these chips except intel movidius and BrilliantUSB have the capacity to be assembled together and form larger neural networks. ** a single spike can propagate through an arbitrary tree to an arbitrary number of destinations within the machine</p> <p>Table of comparison between 4 different major large-scale neuromorphic projects. From Furber [1].</p> <p></p> <p>Acknowledgement</p> <p>The author would like to thank Carboncopies research team  for their support. In particular, Dr. Randal Koene, Alicia Smallwood, Dr. Keith Wiley, and Alexander McLin for their constructive feedback and suggestions on this paper. Additionally, I must thank Allen Sulzen for enhancing the design and structure of this article.</p> <p>Notes:</p> <p>Some ideas in this blog post are taken from Kwabena Boahen\u2019s talk in UCSD, video available here.</p> <p>Some of the explanation methods in this text had been inspired by artificialbrains.com website which is a rich source of information on neuromorphic hardware designs.</p> <p>Footnotes:</p> <ol> <li>Ph.D. Program in Neuroscience &amp; Psychological and Brain Sciences, Indiana University Bloomington, IN, USA.</li> <li>S. Ramachandran, TED 2007</li> <li>Jonas et al., \u201cHuman Optic Nerve Fiber Count and Optic Disc Size.\u201d</li> <li>Here, a conventional computer is defined as a computer that is built based on a Von Neumann architecture. In short, a Von Neumann architecture uses a processing unit, a control unit, memory, external mass storage, and input/output mechanisms. For example, your phone or laptop that you are using to read this article is built based on this architecture.</li> <li>Brain-inspired multiscale computation in neuromorphic hybrid systems.</li> <li>PyNN (pronounced 'pine') is a simulator-independent language for building neuronal network models. See here for more information.</li> <li>Spiking Neural Network Architecture</li> <li>It is important to note that almost 70 percent of neurons in the brain are cerebellar neurons (69 billion) and only 17 billion neurons exist in the cerebrum while the major portion of cognitive processes are believed to be handled by cerebrum rather than cerebellum.</li> <li>A spike or an action potential is the process in which the electrical charge of a neuron\u2019s membrane sharply increases and then comes back to its resting level. Neurons use spikes to send information to each other. In a neuromorphic chip, neurons can either be modeled with the capability of generating these spikes and perform computations based on spike timing or they can be simplified as nodes that sum over inputs and send an output based on an activation function and work in a cyclic fashion. The later is directed more towards machine learning applications whereas the former is mostly used for research purposes.</li> <li>Systems of Neuromorphic Adaptive Plastic Scalable Electronics</li> </ol>"},{"location":"Blog/Posts/NeuromorphicHardwareDesigns/Post/#references","title":"References","text":"<ol> <li>Furber, Steve. \u201cLarge-Scale Neuromorphic Computing Systems.\u201d Journal of Neural Engineering 13, no. 5 (2016): 051001. https://doi.org/10.1088/1741-2560/13/5/051001.</li> <li>\u201cA Silicon Model of Early Visual Processing - ScienceDirect.\u201d Accessed December 16, 2017. http://www.sciencedirect.com/science/article/pii/089360808890024X.</li> <li>Boahen, Kwabena. \u201cNeurogrid: Emulating a Million Neurons in the Cortex.\u201d In Conf. Proc. IEEE Eng. Med. Biol. Soc, 6702, 2006.</li> <li>https://www.nature.com/news/computer-modelling-brain-in-a-box-1.10066</li> <li>https://en.wikipedia.org/wiki/Summit_(supercomputer)</li> <li>Sydney, L. A. M. B. \"On the Evolution of Language and Brain.\" Eastward Flows the Great River: Festschrift in Honor of Professor William SY. WANG on his 80<sup>th</sup> Birthday (2013): 393.</li> <li>Makino, Junichiro, et al. \"GRAPE-6: Massively-parallel special-purpose computer for astrophysical particle simulations.\" Publications of the Astronomical Society of Japan 55.6 (2003): 1163-1187.</li> <li>https://web.stanford.edu/group/brainsinsilicon/neurogrid.html</li> <li>http://ieeexplore.ieee.org/abstract/document/4030636/</li> <li>Torres-Huitzil, C\u00e9sar, Bernard Girau, and Claudio Castellanos-S\u00e1nchez. \"On-chip visual perception of motion: A bio-inspired connectionist model on FPGA.\" Neural networks 18.5 (2005): 557-565.</li> <li>Girau, Bernard, and Cesar Torres-Huitzil. \"Massively distributed digital implementation of an integrate-and-fire LEGION network for visual scene segmentation.\" Neurocomputing 70.7 (2007): 1186-1197.</li> <li>https://www.humanbrainproject.eu/en/silicon-brains/how-we-work/hardware/</li> <li>https://web.archive.org/web/20201008205005/https://www.humanbrainproject.eu/en/silicon-brains/how-we-work/hardware/</li> <li>Valle M, Caviglia DD, Bisio GM. An experimental analog VLSI neural network with on-chip back-propagation learning. Analog Integrated Circuits and Signal Processing. 1996 Apr 1;9(3):231-45.</li> <li>Eldredge, James G., and Brad L. Hutchings. \"Density enhancement of a neural network using FPGAs and run-time reconfiguration.\" FPGAs for Custom Computing Machines, 1994. Proceedings. IEEE Workshop on. IEEE, 1994.</li> <li>Ouali, J., and G. Saucier. \"Fast generation of neuro-ASICs.\" International Neural Network Conference. Springer, Dordrecht, 1990.</li> <li>Burr, James B. \"Digital neural network implementations.\" Neural networks, concepts, applications, and implementations 3 (1991): 237-285.</li> <li>Boahen, Kwabena. \"Neurogrid: emulating a million neurons in the cortex.\" Conf. Proc. IEEE Eng. Med. Biol. Soc. 2006.</li> <li>Benjamin, Ben Varkey, et al. \"Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations.\" Proceedings of the IEEE 102.5 (2014): 699-716.</li> <li>Benjamin, Ben Varkey, et al. \"Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations.\" Proceedings of the IEEE 102.5 (2014): 699-716.</li> <li>Merolla, Paul A., et al. \"A million spiking-neuron integrated circuit with a scalable communication network and interface.\" Science 345.6197 (2014): 668-673.</li> <li>Guerra-Hernandez, Erick Israel, et al. \"A FPGA-based neuromorphic locomotion system for multi-legged robots.\" IEEE Access 5 (2017): 8301-8312.</li> <li>Cassidy, Andrew, Andreas G. Andreou, and Julius Georgiou. \"Design of a one million neuron single FPGA neuromorphic system for real-time multimodal scene analysis.\" Information Sciences and Systems (CISS), 2011 45<sup>th</sup> Annual Conference on. IEEE, 2011.</li> <li>Cassidy, Andrew, et al. \"FPGA based silicon spiking neural array.\" Biomedical Circuits and Systems Conference, 2007. BIOCAS 2007. IEEE. IEEE, 2007.</li> <li>Sharp, Thomas, et al. \"Power-efficient simulation of detailed cortical microcircuits on SpiNNaker.\" Journal of neuroscience methods 210.1 (2012): 110-118.</li> <li>Kudithipudi, Dhireesha, et al. \"Design and analysis of a neuromemristive reservoir computing architecture for biosignal processing.\" Frontiers in neuroscience 9 (2016): 502.</li> <li>Dion, Guillaume, Salim Mejaouri, and Julien Sylvestre. \"Reservoir computing with a single delay-coupled non-linear mechanical oscillator.\" Journal of Applied Physics 124.15 (2018): 152132.</li> <li>Schemmel, Johannes, et al. \"A wafer-scale neuromorphic hardware system for large-scale neural modeling.\" Circuits and systems (ISCAS), proceedings of 2010 IEEE international symposium on. IEEE, 2010.1. </li> </ol>"},{"location":"Blog/Posts/Neuroprosthesis/Post/","title":"An Introduction to Neuroprosthesis and BCIs","text":""},{"location":"Blog/Posts/Neuroprosthesis/Post/#by-rowan-whitney","title":"by Rowan Whitney","text":"<p>We have all heard of Sci-Fi flicks where people get chips implanted into their brains to augment their capabilities, which may seem far off by today\u2019s standards. This trope of science fiction, however, is already presenting itself as a reality. These \u201cbrain chips\u201d, or in more scientific terms, neuroprosthetic implants or brain-computer interfaces (BCIs), are helping people with disabilities today, and in some cases, have been for decades. The future looks strong for the development of neural interfaces, so let\u2019s take a look at several examples of neuroprosthetics that currently exist and are in the process of research and development.</p> <p>We know some BCIs better as cochlear implants, retinal implants, and neurostimulators, which were devised to help with deficiencies in hearing, vision, and various mental conditions (Parkinson\u2019s, epilepsy, chronic pain, clinical depression, and more) respectively. Neurostimulation, more specifically vagus nerve stimulation, has been in use since 1997 (Amin, 2018). The first single channel cochlear implants were released in 1972 (Brown, 2003). These dates tell us that devices connecting to the nervous system (brain-computer interfaces) have been in practice for decades, the first released being the cochlear implant, which was introduced a full half-century ago.</p> <p>There are really only three functions of brain-computer interfaces: to stimulate, to record, and to block.</p> <p>Here is a more in-depth delineation: 1) stimulating devices, which provide the nervous system with stimulating voltage pulses or other feedback, such as with neurostimulation) 2) recording devices, which serve mainly as observational tools for scientists (namely electrodes, electroencephalographs (EEGs), and Functional Magnetic Resonance Imaging (FMRI) machines, which afford a view of the activity of desired regions of a subject\u2019s brain), and 3) blocking devices, which block certain stimuli or activity from occurring. (Anderson, 2008)</p> <p>These devices are not cheap, however. Starting on the \u201caffordable\u201d side, cochlear implants in the United States, at least, are usually covered by various forms of healthcare. Retinal implants are more costly, with the Argus II Artificial Retina or \u201cbionic eye\u201d reaching $150,000 USD in cost, not including the cost of surgery and rehabilitation (Duffy, 2013). What\u2019s more, these \u201csensory substitution\u201d implants are only those that are available for purchase, leaving the prices of more complex, as yet commercially unavailable devices completely open to speculation. An example of a developing neuroprosthetic system is the osseointegrated (bone-anchored) prosthetic arm devised by Max Ortiz-Catalan et al. which interfaces directly with the nervous system, meaning that users can control the limb via thought, and can directly feel stimuli applied to it. (Catalan et al., 2014) It is reasonable to think that systems advancing in that direction, upon public release, garner high demand.</p> <p>Now that we\u2019re familiar with BCIs, let\u2019s discuss their potential applications. Sensory substitution BCIs such as the implants discussed above are the first line of applications. In parallel, neurostimulators are and will continue to be used throughout the world of medicine. Next are the \u201cbionic limbs\u201d, or prosthetics in the same vein as that discussed in the article by Catalan et al., whose further development centers around providing more realistic and higher quality limb prosthetics. Further, labs have started developing systems to connect paralyzed patient\u2019s brains to external prosthetic limbs, to enable them to perform movements and receive haptic feedback. (Hochberg et al., 2014) This has the potential to assist patients suffering from \u201clocked-in\u201d syndrome, a condition where nerve damage renders the body disconnected from the mind operating it, even though the person is fully aware of their surroundings.</p> <p>Some out there might have guessed that DARPA might find its way onto this list, and rightly so.</p> <p>DARPA is widely known for attempting some\u2026 unusual research. One of their projects on the weirder side has been the Hybrid Insect Micro-Electro-Mechanical Systems (HI-MEMS) program. Simply put, this program successfully integrated BCIs into the brains of juvenile cockroaches, allowing researchers to control their movements. (Anthes, 2013) Even more DARPA-esque, a little known project from the early 2000s attempted to remotely control the movements of sharks via BCIs to act as naval reconnaissance. (Highfield, 2006) Unlimited are the possibilities.</p> <p>We are not DARPA. At the Carboncopies Foundation, BCIs serve to illustrate a part of the research and development we strive to promote. Every neuroprosthetic, from cochlear and retinal implants to bionic limbs and remote-controlled animals, has enabled us to understand more about brains, human and otherwise, and how to interface with them. The mission of the Carboncopies Foundation is to preserve, restore, and even improve your mental experience beyond the limits of biology. To accomplish this, it is essential to first understand the brain and the symphony of its workings. Neuroprosthetics is a fast developing field, and advances within it bring us one step closer to that understanding.</p> <p>Keywords: Retinal implants, cochlear implants, brain-computer interface, neurostimulator, neuroprosthetic implants</p> <p>Updated 1/21/22</p>"},{"location":"Blog/Posts/Neuroprosthesis/Post/#references","title":"References","text":"<p>Amin, U. (2018, July 02). Neurostimulation for the Treatment of Epilepsy. Retrieved January 01, 2019, from https://emedicine.medscape.com/article/1186123-overview</p> <p>Anderson, P. (2008, July 09). Implantable Device that Blocks Brain Signals Shows Promise in Obesity. Retrieved January 01, 2019, from https://www.medscape.com/viewarticle/577292</p> <p>Anthes, E. (2013, February 17). The race to create \u2018insect cyborgs\u2019. Retrieved January 20, 2019, from https://www.theguardian.com/science/2013/feb/17/race-to-create-insect-cyborgs</p> <p>Duffy, M. (2013, August 19). The Argus II Retinal Prosthesis (\u201cBionic Eye\u201d) Receives Medicare Approval. Retrieved January 01, 2019, from https://www.visionaware.org/blog/visionaware-blog/the-argus-ii-retinal-prosthesis-bionic-eye-receives-medicare-approval/12</p> <p>Herreros_alonso I, Giovannucci A, Taub AH, Hogri R, Magal A, Bamford SA, Prueckl R and Verschure PF(2014) A cerebellar neuroprosthetic system: computational architecture and in vivo experiments. Front. Bioeng. Biotechnol. 2:14. doi:10.3389/fbioe.2014.00014 http://www.sim.me.uk/neural/JournalArticles/HerrerosEtAl2014.pdf</p> <p>Hochberg, L. R., Bacher, D., Jarosiewicz, B., Masse, N. Y., Simeral, J. D., Vogel, J., Haddadin, S., Liu, J., Cash, S. S., van der Smagt, P., \u2026 Donoghue, J. P. (2012). Reach and grasp by people with tetraplegia using a neurally controlled robotic arm. Nature, 485(7398), 372-5. doi:10.1038/nature11076 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3640850/</p> <p>Mahoney, P. (2007, June 21). Wireless is getting under our skin. Retrieved January 01, 2019, from https://web.archive.org/web/20080604164839/http://machinedesign.com/ContentItem/67966/Wirelessisgettingunderourskin.aspx</p> <p>Ortiz-Catalan, M., H\u00e5kansson, B., &amp; Br\u00e5nemark, R. (2014, October 08). An osseointegrated human-machine gateway for long-term sensory feedback and motor control of artificial limbs. Retrieved January 17, 2019, from http://stm.sciencemag.org/content/6/257/257re6</p> <p>Highfield, R. (2006, March 02). Sharks are Pentagon\u2019s latest spy recruits. Retrieved January 27, 2019, from https://www.telegraph.co.uk/news/science/science-news/3345150/Sharks-are-Pentagons-latest-spy-recruits.html</p> <p>Brown, C., Geers, A., Hermann, B., Iler Kirk, K., Tomblin, B., Waltzman, S. (2003, March) ASHA Technical Report, Working Group on Cochlear Implants. Retrieved January 21, 2022, from https://www.asha.org/policy/tr2004-00041/#:~:text=The%20first%20single%20channel%20cochlear,1980s%20including%20several%20hundred%20children.</p>"},{"location":"Blog/Posts/Preconscious/Post/","title":"The Preconscious Smart Home","text":""},{"location":"Blog/Posts/Preconscious/Post/#the-preconscious-smart-home","title":"The Preconscious Smart Home","text":""},{"location":"Blog/Posts/Preconscious/Post/#keith-wiley","title":"Keith Wiley","text":"<p>\u201cComputer, open a new email.\u201d</p> <p>\u201cTo whom?\u201d</p> <p>\u201cMy sister, with the subject line, \u2018Plans for the weekend\u2019.\u201d</p> <p>\u201cWhat should the email say?\u201d</p> <p>\u201cWe\u2019ll be heading to the Shakespeare festival on Saturday. Want to join us? We\u2019ll probably also grab dinner afterwards.\u201d</p> <p>\u201cThe email has been sent.\u201d</p> <p>The spoken-word exchange shown above is possible today with a variety of technologies. Let\u2019s try again:</p> <p>\u201cCompu\u2014\u201d</p> <p>\u201cThe email has been sent.\u201d</p> <p>?! What just happened?</p> <p>With the email sent\u2014somehow\u2014you head to the kitchen, reach into the food replicator, and retrieve a mug of coffee (the replicator produced both the coffee and the mug, the latter in a manner similar to contemporary 3D printing). You never verbally requested coffee, much less did anything so archaic as pressing buttons, and the machine could not have assumed you wanted coffee since you just as often have either tea or juice. There are too many options for the replicator to have guessed, yet it got it right. You walk into your dining room and sit down, where you find that breakfast is already waiting for you. Although you enjoy a variety of breakfast options, the spread of eggs and toast lay before you is precisely what you wanted today, not cereal, which you eat just as often, not a waffle, not a scone. Your smart house got it right. You realize that you wish the coffee was a bit sweeter and then become aware of a plate of sugar cubes in your peripheral vision on the table. Was it there the whole time, or did the matter replicators built into the table rapidly emit it onto the table\u2019s surface as soon as you felt the desire for additional sugar? Which came first, your realization that you wanted sugar, or the plate of sugar itself? How can the latter be possible? You notice the ceiling light dimming automatically, and then realize it was a bit too bright a moment before\u2014in that order. As you take the first heavenly sip from the mug, you hear Rossini start to pipe through the audio system and then realize that was precisely what you wanted to listen to on this particular morning while you ate your breakfast. Did you only decide you wanted to listen to Rossini because you heard it? If so, how did the house know to play it in the first place? No, rather, the house seems to have known you slightly before you knew yourself.</p> <p>Your environment not only seems to meet your needs without verbal direction, essentially reading your mind, it seems to do so conspicuously before you are aware of your own desires. By the time you head back to your bedroom to get dressed, the outfit you intend to wear is already front and center in your closet, but you had barely given it a moment\u2019s attention before leaving the dining room. Giving yourself a final check in the mirror you realize that you wish you had a belt with a silver buckle, not brass. Turning to your closet you find such a belt hanging on the hook. You never owned one before, but now it\u2019s there. The matter replicator could not have built it fast enough in response to your preference for a silver buckle, regardless of any potential mind-reading technology, since even your futuristic metal printer requires several seconds to complete a construction. The replicator absolutely must have begun its construction a few seconds earlier, before you even realized you were distressed with the appearance of the brass buckle in the mirror.</p> <p>You can construct vast bodies of text faster than you can think of them. Gone are the ancient days of penmanship and typing. Even dictation, which steadily replaced\u2014or at least augmented\u2014keyboard typing in certain domains as the twentieth century unfolded, is now completely outdated. Rather, while staring at a blank text editor on your computer monitor, you see the words flood across the page faster than you can think of them. They don\u2019t even feel like your words because they lead instead of follow your intentions, yet the text emerging from the white background is precisely what you sat down to accomplish. Any edits or changes you conceive along the way similarly materialize on the screen faster than you can grasp control of them. The whole body of text seems to grow organically without your direction, not following your inner voice, but seemingly a moment or two ahead of your own conscious awareness. Yet while it doesn\u2019t feel like the text belongs to you, the final document is precisely what you set out to accomplish. It must be yours. Who else\u2019s could it be?</p> <p>How can any of this be possible? At every turn, not only are you able to achieve your goals without directly expressing them verbally or otherwise, but more astoundingly, your goals are met before you knew you had them. It is an impressive feat in itself that your environment can respond to your mental intents without your having to incantate them, but it is a wholly different experience that such tools are apparently a step ahead of your own conscious awareness. The whole world appears to be in a state of perpetual physical flux as futuristic matter converters constantly reshape your environment not only to your wants and needs, not even only in a seemingly mind-reading fashion, but somehow anticipating each desire slightly before you actually experience the desire. Consequently, the world always seems to be magically ready for you at every turn.</p> <p>Try to wrap your mind around how weird this experience would be. Every time you wish for some physical object you conveniently find it sitting on your desk by the time you realize you need it. You see your matter converters in a state of constant activity tossing out (and recycling) objects faster than you can ask for them, and always emitting something you only just realized you were about to want at the very moment it appears before you. This happens ceaselessly throughout the day. The whole world simply conforms to your desire.</p> <p>Research suggesting that our choices and decisions are already made significantly in advance of our conscious awareness of those choices goes back as early as the 1980s. Benjamin Libet\u2019s experiments are widely regarded as the initial foray into the discovery that neurological indications of a decision precede the subject\u2019s conscious awareness of their own decision by hundreds of milliseconds. Modern variants of the experiment, using fMRI, have pushed the window of time during which brain scans can anticipate a subject\u2019s decision to as long as ten seconds in some cases. In Libet\u2019s experiment, subjects freely choose the exact time at which to take some action, such as lifting a finger, yet the event can be predicted in advance by observing the EEG of the subject. Other experiments, such as those by Roger Koenig-Robert and Joel Pearson, consist of choosing between two images to focus on. Again, brain scans, this time fMRI, can anticipate the choice. Yet another experiment, by John-Dylan Haynes, has the subject choose between pressing a button with their left or right hand. And again, the choice can be anticipated far in advance.</p> <p>When the implications of these experiments are considered, the discussion generally wanders into the morass of free will, attempting to determine if we still have free will in light of such experiments, or alternatively if our conscious intention (our volition) doesn\u2019t seem to be the determinant of our choices and actions. I have no interest in pursuing the implications for free will here. If you are otherwise curious about my take on free will, please read my book.</p> <p>This article merely explores the end result of such research in terms of practical applications. Other attempts to speculate on the value of such discoveries are, frankly, rather mundane, considering the possibility of more accurate lie detectors and such. Is that really the best we can come up with? As illustrated above, in a slightly more distant future, a confluence of technologies may enable some remarkable technologies. It will require unintrusive, efficient, reliable brain scanners, preferably wearable or implantable. Nothing about the story described above would work with a gargantuan fMRI machine. Scanners of the requisite sort are far off indeed. For the text construction example, practically no other technology will be necessary, but it is no small feat to extend the rudimentary experiments above to a version that can read your inner voice as a stream of text from a brain scan, much less do so far ahead of your otherwise prosaic dictation capabilities, which are already feasible today for the mere cost of a microphone. Furthermore, we honestly don\u2019t know which particular mental events offer which possible lead-times of anticipatory neural activity. While binary forced choice experiments may offer lead times of several seconds, perhaps text generation only leads by a much smaller window, but maybe that will be sufficient for a rich user experience anyway. We don\u2019t know these things yet. Moving on, the physical examples above will require steady advances in 3D printing, and in the culinary examples, may require at the least a capable kitchen robot, and in a more extended imagining, a biomatter printer or rapid chemistry machine of some sort that we needn\u2019t delve into here. In the extreme, something like utility fog as described by John Storrs Hall may be used, from which nanobots coalesce from the very air around us to construct objects on a whim (and just as easily dissolve those objects the moment we no longer need them). Doubtlessly, each of these technologies presents serious challenges, and the scenario described above will not be possible in the near future. But there is good reason to expect some of the possibilities described above to emerge in some fashion in our coming future.</p>"},{"location":"Blog/Posts/Restoration/Post/","title":"Restoration of Function After Brain Damage Using a Neural Prosthesis","text":""},{"location":"Blog/Posts/Restoration/Post/#restoration-of-function-after-brain-damage-using-a-neural-prosthesis","title":"Restoration of Function After Brain Damage Using a Neural Prosthesis","text":""},{"location":"Blog/Posts/Restoration/Post/#a-summary-of-the-proof-of-concept-testing-for-repairing-neural-pathways-using-prostheses-by-guggenmos-azin-barbay-mahnken-dunham-mohensi-and-nudo","title":"A summary of the proof-of-concept testing for repairing neural pathways using prostheses by Guggenmos, Azin, Barbay, Mahnken, Dunham, Mohensi, and Nudo","text":"<p>Most often neural prosthesis are associated with giving people superhuman like abilities such as controlling machines by thought or adding the seemingly infinite information of the internet to your memory. It's important to remember that neural prosthesis have a more immediate purpose to serve in the near future by helping those who suffer from brain damage.</p> <p>Repairing the functionality of a damaged human brain using neural prosthesis is still several years away, yet the technological capabilities have already been proven to exist and the field of research in neural prosthesis is growing.</p> <p>A collaboration effort was made with the Departments of Molecular and Integrative Physiology and Biostatistics and the Landon Center on Aging at the Kansas University Medical Center, and the Department of Electrical Engineering and Computer Science at Case Western Reserve University. They have conducted experiments testing the hypothesis that brain injury recovery can be aided by using neural prostheses to bridge communication pathways between distant locations in the cerebral cortices of rat test subjects.</p> <p>Rats with damaged cerebral cortexes, in the primary motor region, were given the experimental microelectrode prosthesis. The rat's brain damage disrupted the communication between the motor and somatosensory areas causing impaired reaching and grasping abilities. The prosthesis delivered spike triggering electrical stimulation to their somatosensory cortex over a period of two weeks. Noticeable improvements in grasping and reaching developed by the first week and, by the second week, reaching and grasping capabilities were indistinguishable to how the rats were observed before brain damage.</p> <p>This experiment has shown evidence that the communication pathways between the two locations in the rat's cerebral cortex was treated by the stimulation of the microelectrode neural prosthesis. Therefore, this experiment also provides evidence for the capability to treat neural pathway communication inhibitions in human brains by the facilitation of neural prosthesis.</p> <p>This prosthesis is classified as a closed-loop neuroprosthetic microdevice. The importance of this prosthesis has all to do with spike stimulation in the brain. A spike is the observable electrostatic operation in the brain when neurons send signals among each other. When a communication pathway between locations in the brain or groups of neurons is inhibited by damage to the brain tissue it is impossible for electrostatic signals to be transferred between those groups of neurons to allow neural activity to function normally. The prosthesis is an artificial communication pathway to replace the damaged tissue. Being a closed-loop means that electrostatic signals can be sent and received between groups of neurons as they would be naturally, without damage to the pathway.</p> <p>For a prosthesis to be efficient enough to be implanted into a human patient, it must be capable of much greater precision and reliability than the experimental prosthesis used in this test; however, the first human brain prosthesis for repairing damaged neural pathways will still operate using the same functionality of spike stimulation.</p> <p>For complete details please see the article which is posted on the site for Proceedings of the National Academy of Sciences of the United States of America:</p> <p>Restoration of Function After Brain Damage Using a Neural Prosthesis</p>"},{"location":"Blog/Posts/ShouldYouBeScared/Post/","title":"Why Whole Brain Emulation isn't a threat to humanity","text":""},{"location":"Blog/Posts/ShouldYouBeScared/Post/#why-whole-brain-emulation-isnt-a-threat-to-humanity","title":"Why Whole Brain Emulation isn't a threat to humanity","text":"<p>Article Written by Jason Wong, June 2024</p> <p>Terminator\u2019s SKYNET was first initially seen by the public on October 26, 1984. It has been roughly 40 years since then and we still do not have sentient artificial intelligence. This has not stopped a large anti-AI public sentiment from rising, however we at Carboncopies believe that it is only a matter of time before we are able to unlock a controllable and safe, fully digitized consciousness. We are attempting to recreate consciousness by creating a one to one mapping of an already existing person\u2019s brain. So, with all that being said, is there anything to be feared? Should you worry about giant metal robots attempting to eradicate all life on earth?</p> <p>The short answer is no.</p> <p>With almost a 100% certainty, a whole brain emulation will not be taking over the world or destroying it. Let me explain:  </p>"},{"location":"Blog/Posts/ShouldYouBeScared/Post/#factor-1-if-a-person-has-unlimited-time-whats-stopping-them-from-doing-whatever-they-want","title":"Factor 1: \u201cIf a person has unlimited time, what\u2019s stopping them from doing whatever they want?\u201d","text":"<p>With almost a 100% certainty, a whole brain emulation will not be taking over the world or destroying it. Let me explain:  </p> <p>As mentioned before, we are attempting to recreate a human brain. What that means is that the digitized human brain will be mapped with the exact same amount of brain tissue, neurotransmitters, and synapses as roughly you and I. What that means is that even if someone who was digitized wanted to do bad things, things would still take that said long time. In the time that the person would take to do bad things, there would already be either an established justice system or people-ran justice system (like in the American wild west) to prevent these actors from doing wrong. </p> <p>They are also limited by the fact motivation is fickle. It's hard to believe that even if someone had an eternity to plot something, they would be able to stay motivated to do so for that long. </p>"},{"location":"Blog/Posts/ShouldYouBeScared/Post/#factor-2-couldnt-a-bad-person-duplicate-themselves-and-become-exponentially-smarter","title":"Factor 2: \u201cCouldn\u2019t a bad person duplicate themselves and become exponentially smarter?\u201d","text":"<p>If the person was able to duplicate themselves, they wouldn\u2019t suddenly become smarter or more dangerous to humanity. Imagine if you had to work with a hundred clones of yourself. You still wouldn\u2019t necessarily be able to suddenly understand nuclear physics, or calculus right away. Even if one version of myself was able to, it\u2019s not likely every clone of myself would understand it. Another thing to consider is that the brain is an unbelievably powerful machine. If a person wanted to simulate millions of clones of themselves, it would cost a pretty penny to power and maintain the machines used to keep each clone alive and store gathered data.</p>"},{"location":"Blog/Posts/ShouldYouBeScared/Post/#factor-3-what-would-happen-if-a-bad-person-boosted-their-digital-brain-processing-speed-by-x-amount-does-that-change-anything","title":"Factor 3: \u201cWhat would happen if a bad person boosted their digital brain processing speed by X amount. Does that change anything?\u201d","text":"<p>We currently do not understand how amplifying the digital brain would affect a digitized person\u2019s mind, however if you recall what was said above, it is believed that one would just get bored of the task and want to do more enjoyable things. For example It\u2019s very difficult to stay mad at someone for more than a few hours or days, imagine how much anger it would take for a person to go through hundreds if not thousands of years of existence with the sole purpose of destroying humanity. Humans generally are not like that; we typically like going to the beach, eating pumpkin pie, or going snowboarding, not hurting others. However if a truly evil person was dead-set on causing destruction, they would light up like a beacon on the map because of their extraordinary power consumption and suspicious acquisition of computing hardware unless they were based in the few super data centers around the world which are constantly monitored. </p>"},{"location":"Blog/Posts/ShouldYouBeScared/Post/#conclusion","title":"Conclusion","text":"<p>We at Carboncopies do not believe that there is any threat of large scale violence coming from a Whole Brain Emulation. There are many limiting factors on possible bad actors. The entire emulation process in its early stages will be open-source and very tightly watched over by the smartest people in the field. There is nothing to fear as long as we remain intelligent about how we create this and vigilant after we create it. </p> <p>Quote</p> <p>The oldest and strongest emotion of mankind is fear, and the oldest and strongest kind of fear is fear of the unknown. - H.P. Lovecraft </p>"},{"location":"Blog/Posts/Threats/Post/","title":"The Greatest Long-Term Threats Facing Humanity","text":""},{"location":"Blog/Posts/Threats/Post/#the-greatest-long-term-threats-facing-humanity","title":"The Greatest Long-Term Threats Facing Humanity","text":""},{"location":"Blog/Posts/Threats/Post/#blog-entry-by-michael-ulrich-a-review-of-the-perspective-article-by-dr-anders-sandberg","title":"Blog Entry by Michael Ulrich: A review of the Perspective Article by Dr. Anders Sandberg","text":"<p>It is no surprise that many of us are interested in mind uploading because of the idea of gaining immortality. Even if we don't want to admit it, the desire to keep experiencing the world long after our original bodies can sustain our mind is a reasonable purpose for dedicating a life of research to achieving Whole Brain Emulation. Aside from individual life-extension, humanity itself must face challenges to survive long into the distant future. Even if we get to the point where we become machines, humanity surviving indefinitely will always have it's challenges. In his article about the future challenges that humanity must face to survive, Dr. Anders Sandberg explores 6 main stages of the future's greatest threats to the continuation of humanity as well as some hopeful solutions to counter those threats.</p>"},{"location":"Blog/Posts/Threats/Post/#our-imminent-demise","title":"Our Imminent Demise","text":"<p>The first great challenge that humanity must overcome is the ability to survive longer than the typical mammalian species. Aside from risks caused by humanity such as nuclear war or bio-engineered plagues, there is the fact that the earth is constantly going through climate cycles. Ice ages occur on Earth in intervals due to the alterations in which the Earth's axis tilts over millions of years. Other natural disasters that have happened in Earth\u2019s history are still likely to happen again such as meteor impacts, volcanic eruptions, or ecological disruptions. To survive the first great threat, humanity must evolve into something unlike it's current mammalian state. Becoming machines and merging with AI through Whole Brain Emulation is an obvious solution.</p> <p>The second great threat will be when the biosphere of the Earth can no longer function. In about one billion years the sun's brightness intensity will cause the Earth to become too hot to support life naturally. The increasing heat will cause a runaway greenhouse effect with carbon dioxide releasing and killing plant life. More water will evaporate from the oceans making the atmosphere hotter. It would be a monumental engineering task to alter the effects of the biosphere such as a giant solar shade. It would make much more sense to sustain human life in space and leave our home planet. Sustaining human life in space-faring vessels has been proven to be practical for several months; and artificial gravity will expand that time. We have one billion years to make sure we can do that when this second great threat arrives. Again, merging with machines will make this much easier. The ability for the mind to survive hostile environments in a machine vessel is a great advantage for Whole Brain Emulation. Long-term space travel will be made eventual will the realization of Whole Brain Emulation.</p>"},{"location":"Blog/Posts/Threats/Post/#what-risks-do-we-face-if-we-survive","title":"What Risks Do We Face If We Survive?","text":"<p>The third great threat will be surviving the end of the sun's main sequence lifetime. Anyone who has studied astronomy knows very well that the sun will not be there forever to support the earth regardless of how well the ecosystem has been maintained. Humanity will have to move off our home world at some point and the sun becoming a red giant is our final deadline. The sun's lifetime is determined by the elements it has to burn. In about 5 billion years from now, the sun will run out of hydrogen and start burning helium. This is when it will expand far past the edge of the solar system as a red giant completely swallowing the earth. When this point comes, we will have to find a new solar system. Spacecraft that can support human life for multiple millennia will be needed for this journey.</p>"},{"location":"Blog/Posts/Threats/Post/#the-end-of-the-universe","title":"The End of the Universe","text":"<p>The fourth great threat is expected to come in about 100 trillion years when all stars in the universe die and fade. It has been observed that star formation has already hit its peak and has begun to decline. As the stars go through their life cycles they will all eventually die and will no longer be sources of energy. This means that humanity will have to find alternative energy sources to starlight. Some solutions proposed in the article include fusion using brown dwarfs and gas giants or black hole radiation. Without isotopes produced by star formation, fission power will ultimately no longer be available. It is possible that humanity will need to evolve to a point where we no longer need enormous amounts of energy and can survive in sub-zero temperatures.</p>"},{"location":"Blog/Posts/Threats/Post/#when-stars-collide","title":"When Stars Collide","text":"<p>The fifth great threat is more of a larger aspect of the fourth threat. As galaxies spin and collide with each other they will all eventually cease spinning. The problem with this is keeping the surviving stars and planets in those galaxies from collapsing into the galaxy center's black holes. If all those stars and planets are consumed by the black holes we lose our resources. The article proposes that altering the movements of the spinning stars could be achieved with something like radiation reflectors as used on the Voyager spacecraft. While feats of engineering this extravagant seem impossible in this era, it might be a part of everyday life for our evolved states at this point.</p> <p>The sixth great threat to the survival of humanity is something even Whole Brain Emulation can't solve by itself. It is the end of matter. While the theory has not been proven, some theories argue that protons in atoms are not eternally stable. If protons eventually decay, in trillions of years, the only things left in the universe will be radiation and black holes. As of now, there is no solution to this problem.</p>"},{"location":"Blog/Posts/Threats/Post/#what-does-whole-brain-emulation-solve","title":"What Does Whole Brain Emulation Solve?","text":"<p>While achieving Whole Brain Emulation will get us much further ahead in the game of survival, we still need to find better means of evolving to higher and higher forms. It will be a constant effort throughout time for humanity to keep its presence on the universal stage. Those alive today are on the cusp of transcending our animal lives and merging with machines. While improbable, it is not impossible that someone alive today may have the chance to face all 6 great threats in their life.</p> <p>Getting to a point where humanity can just relax for eternity and never worry about death may never come. However, facing an eternal challenge to defy death might just be what makes living forever all the more worthwhile.</p> <p>For further information please see Dr. Sandberg's full article posted on BBC.com: The Greatest Long-Term Threats Facing Humanity</p>"},{"location":"Blog/Posts/UploadBeMe/Post/","title":"Would an Upload Be Me, or Just a Copy; Who is the Real Me?","text":""},{"location":"Blog/Posts/UploadBeMe/Post/#would-an-upload-be-me-or-just-a-copy-who-is-the-real-me","title":"Would an Upload Be Me, or Just a Copy; Who is the Real Me?","text":"<p>An Opinion Response by Michael Ulrich</p> <p>For this question, the answer considers the constraints and definition of personal identity.</p> <p>Consider the implications, every copy has, at some point, the same mental information that is unique to your brain\u2019s origination. At the instant a copy is set into existence, it takes on a worldly experience of its own that is different from the other copies up to the point of identity branching. By this they are different, but they have the same point of branching from one form of mental information.</p> <p>If personal identity has no bias against copies, so long as they have the same mental information at the point of branching from the originating mind, then all copies can be considered \u201cyou.\u201d</p> <p>This does not hold up if there are additional continuity constraints required for every copy to be considered the same \u201cyou.\u201d For example, if spatial continuity is a considered necessary continuity, then information must also have some form of definitive spatial volume that cannot be hindered. If an originating brain is scanned of information and the information is then used to construct an emulation of the originating brain the emulated brain would lack a continuity of spatial volume in comparison to the original brain from before to after the procedure.</p> <p>There are issues with claiming that any \u201ccopy\u201d of an individual has any priority of personal identity over any other copy. Branching identity is a multiplication of the information. To argue that there is any priority of one copy over another is to require an additional condition for continuity than just the individual\u2019s brain information.</p> <p>In the hypothetical event, in that you\u2019re experiencing your life as a member of a group of copies of your mental information, to ask, \u201cWho is married to your wife?\u201d would require some additional definitive attributes than the information requirement for personal identity. It could be something like, the identity with complete spatial continuity is the individual who is married. It could also be that all copies are equally married to the spouse. Consider an additional factor, if both spouses are copied multiple times, which copies are married to each other. It seems that because the conditions for marriage have never had to deal with the aspect of cloning, this could be open for newly created marriage definition constraints for sometime in the future.</p> <p>This can also be said for things like inheritance laws. It could be something like, each clone that is created gets an even percentage of the property that belongs to the individual at the instant of identity branching. Of course, in this hypothetical case, the more copies that are made, the less property will be inherited per clone.</p> <p>This kind of projection thinking, of a future where multiple copies exist, can also be tied back into the anxieties and considerations that make personal identity survival such a controversial issue to attach additional continuity constraints to that are not just about the mental information.</p> <p>Consider this hypothetical situation story: You are given an opportunity to have your brain emulated. The procedure has gotten so advanced, that your brain can be scanned of all it\u2019s information while you are still alive and there is no health risk. You are fully aware of the arguments against personal identity being anything more than just information preservation, so you don\u2019t have any worries about whether or not the entity with an emulated brain is going to be you, and you're excited that this could be your big chance to fulfill your dreams of living forever! You undergo the procedure and the next day your fellow identity is standing next to you. You see your \u201ctwin\u201d in a robotic body with a silicon based brain-like substrate while your perspective (for the remainder of this story) is from your original biological body. It is truly a marvel for you to behold that technology and science has come this far! For the next few weeks your robotic \u201ctwin\u201d is having a space adventure, but without you because his/her body is able to survive the necessary harsh conditions that your biological body cannot. You\u2019re starting to feel a little left out, but you keep on telling yourself to be happy because this doppelganger is still just \u201cyou.\u201d The years pass and the robotic \u201ctwin\u201d has added new upgrades to his/her artificial body that allow him/her to have all of the valued experiences of a normal human body, but with none of the weaknesses or vulnerabilities. You, however, in your original body, have become frail and weak with old age. At this point, you know that your biological body will soon quit and die. You\u2019re starting to feel like this doppelganger of your mental information, scanned from your biological brain from years ago, doesn\u2019t really seem like it\u2019s you who\u2019s getting to fulfill your dream of living forever. It\u2019s more like you\u2019ve been given the bad end of a deal that your robotic \u201ctwin\u201d won out completely.</p> <p>If personal identity preservation is only based on the preservation of the information, then you, in the story, should be completely indifferent as to which entity gets what in life after the procedure, because it would hold up logically that \u201cyou\u201d are also the robotic version. However, it can be difficult to mentally project yourself as experiencing the life of the robotic \u201ctwin\u201d instead of the biological you, because the biological you had complete continuity from before and after the procedure, whereas the robotic \u201ctwin\u201d only had the continuity of information.</p> <p>Unfortunately, there has yet to be a logical argument against the \u201ccopies\u201d of you being all equally the preserved identity of you. However, this ever persistent need for some kind of additional condition for continuity (other than just information) between the identity from before the procedure and after the procedure, in order to have the original personal identity preserved and survive, should not necessarily be dismissed as merely irrelevant obsolete prejudices, just because there is no irrefutable justification as of yet.</p> <p>One possible path to take for a more clear understanding of personal identity preservation, as technology and neuroscience progresses, is a complete understanding of connectomics and how connectomics can explain the first-person experiences in a completely non-metaphysical way.</p>"},{"location":"Blog/Posts/WBEHowCouldItAffectUs/Post/","title":"How Could Whole Brain Emulation Affect Us?","text":"<p>Imagine this: you\u2019re truly free, unbound from the restrictions of the past. This world can become anything you want it to be. You can change the environment instantly, obtain a multitude of skills, and witness countless decades of existence. You could even fly through space if you\u2019d like. Whole brain emulation (WBE) offers many possibilities, including transcendence from the physical world and the transformation of the human condition. It could affect us in different ways, ranging from the impacts of technological advancement to a potential shift in motivations and desires for survival.</p> <p>Technological singularity is a concept proposed by Vernor Vinge that describes an acceleration of progress in technology culminating in the emergence of \u201cgreater-than-human intelligence\u201d (1). The accomplishment of whole brain emulation would mark a drastic and innovative achievement which would likely coincide with other advancements, such as the development of conscious artificial intelligence. In this scenario, predictive algorithms and neural networks would be greatly improved. They might be utilized more often in society, incorporated into our everyday lives. In some ways, technology might become more human, just as humans might become further integrated into technology. If beings with artificial intelligence were designed to recognize emotions, they would not be the cruel, nightmarish robots seen in science fiction movies; with the emulation of the right neural functions, robots could become fully empathetic. In this sense, robots would pose the same threat that human nature poses, as they would possess the same cognitive abilities. There could be virtually no difference between a robot that distinguishes objects based on prediction and a human that interprets the world based on predictive coding. The emergence of artificial superintelligence would likely be met by equally augmented humans, or emulations possessing heightened abilities.</p> <p>The main objective of whole brain emulation is to transcend fundamental limitations. Consequently, WBE could affect humanity by allowing for the unprecedented crossing of boundaries. We could improve the reliability and speed of cognition, lengthen our attention spans, and overcome the burden of fatigue. We would no longer need to heal from physical injuries. In the absence of a biological body, there would be no risk of developing an infectious virus or an illness such as cancer. An emulated individual could achieve immortality through backup copies (2). Because of the possibility of prolonged life, a cultural knowledge of art, history, and language could be preserved for future generations. Additionally, a dangerous feat such as space travel could be accomplished if an emulation served as the pilot through a remote connection or machine body.</p> <p>Whole brain emulation could further the field of neuroscience by improving an understanding of the brain. With a multitude of connectomes and functional emulations, neuroscientists would have new tools to witness or simulate neural firings. As a connectome aims to capture the entirety of an individual\u2019s synaptic connections, the resulting data would be superior to images produced by neuroimaging technologies widely used in the present day. There are many ways of obtaining this data in-vivo rather than through destructive methods (3), (4). In addition to broadening neuroscientific knowledge, WBE and its related technologies could be used for therapeutic applications, leading to many clinical benefits. Researchers are currently using connectomics data to study anxiety and depression (5), biomarkers of illness (6), Alzheimer\u2019s disease (7), and numerous other conditions. Upon the advent of WBE, it would not only be possible to study brain diseases in more detail, but accurate and effective treatments could be developed. After observing the origin or mechanisms of dysfunction, scientists could potentially find new ways to modulate brain regions. In emulations, neurons could be directly altered, allowing for individualized treatments. People at risk of Alzheimer\u2019s disease or other neurodegenerative illnesses could choose to have their brains emulated before the onset of dementia.</p> <p>Despite these prospective benefits, WBE also opens up the possibility of negative consequences. Malware and ransomware could become more dangerous than ever by tampering with the neural substrates of emulations. Computer viruses and software bugs could replace biological viruses and bacteria. When thoughts, emotions, and memories are converted into code, this leaves such sensitive data vulnerable to hacking or corruption. In the absence of workers\u2019 rights for emulated beings, corporations could take advantage of the ability to work for long hours without physical limitations. Hypothetically, emulations could be manually \u201creprogrammed\u201d, which presents ethical dilemmas. In the case that an individual consents to a treatment for an illness, this could be useful, but what if the neural connections are altered without an emulation\u2019s knowledge and for a malevolent purpose? The potential exists for diminishing agency over one\u2019s consciousness and autonomy. To remedy these issues, precautions could be taken such as the installation of antivirus programs. Emulations could be granted protections over individual autonomy just as humans in many countries are granted rights by law. Additionally, it would be possible to create backup copies in the case of irreparable damage.</p> <p>It is unknown what effects prolonged life might have on individuals. In the case they grow tired of existence, there may or may not be an \u201coff\u201d button that would delete emulation data. On the other hand, WBE could serve to alleviate death anxiety by providing an indefinite lifespan on a substrate immune to physiological decay7. Certainly, threats such as malware would still pose risks to survival without sufficient backup, but an emulation would not need to worry about inevitable demise. The fear of death, born of an evolutionary drive for survival, has led to an age-long desire for eternal life; whole brain emulation offers the alluring promise of near-immortality. In this, it is similar to the conception of an afterlife, and may appeal to those who wish to ease their existential dread (8). </p> <p>Emulations could experience reality in different ways, depending on whether they are based on digital or physical substrates. In order to become functioning individuals, they must be able to interact with the world (9). They must also have access to sensory input, which could come from various sources. To be an isolated \u201cbrain in a vat\u201d without sufficient stimuli would be an exceedingly frustrating experience; consequently, an emulation would likely be connected to either a virtual avatar or a robotic body. Emulations with virtual avatars would be immersed in digital environments. In these environments, pressure and heat maps could translate back to action potentials, allowing emulations to experience touch. Similarly, virtual bodies would accept motor nerve signals and convert them into movement. Research on the use of virtual reality avatars shows that the sense of body ownership can be transferred, supporting the notion that emulations can be embodied (10). They would be able to feel the proprioceptive sensations of avatars. This would be mediated by neuroplasticity, the capacity of the brain to adapt and shape itself. Emulated neural function would retain the malleability of biological brains, as plasticity is the foundational principle of neural networks and neuromorphic devices that learn based on association. Those in robotic bodies would live in the world that we currently know, and could access sensory input through neuroprosthetic feedback. There are devices already in existence that facilitate tactile (11), visual (12), and auditory input (13).</p> <p>The introduction of emulations to the wider social landscape could have varying outcomes, the best of which would be harmonious interaction between biological and emulated humans (16). There could also be backlash from anti-technology groups afraid of progress toward the future. The human instinct for advancement is similarly contradicted by the human fear of change. Technological developments have long been met with reluctance; once whole brain emulation is achieved, there could certainly be opposition. There is a current hesitance among some individuals to accept the technology of whole brain emulation, as they doubt its feasibility (17), (18), (19).</p> <p>Emulated beings might experience shifts in goals and drives for survival. Initially, emulations would retain all of the motivations, biases, fears, and desires of humans. It would first be necessary to replicate human behavior and function before making changes. However, after the success of WBE is ensured, emulations might find themselves possessing brains unadapted for digital or computational substrates. They would no longer need to consume food in order to survive, and could be exposed to many situations previously deemed dangerous. As a consequence, they might evolve to adopt new motivations and biases, either through deliberate modification or automatic learning. Emulations would most likely focus on avoiding the deletion or corruption of data to ensure survival.</p> <p>Whole brain emulation could have a diverse range of effects once it is achieved. Artificial intelligence might become more advanced and possibly more human-like; we might be able to transcend physical boundaries in a way never seen before; the field of neuroscience could be entirely transformed. Emulations could face survival risks (albeit different than those we currently face), but also might live for a prolonged period of time. The technology could shape future societies, providing risks and benefits for biological individuals as well as those who choose to become emulated.</p>"},{"location":"Blog/Posts/WBEHowCouldItAffectUs/Post/#bibliography","title":"Bibliography","text":"<ol> <li>Cutrone, A., &amp; Micera, S. (2019). Implantable neural interfaces and wearable tactile systems for bidirectional neuroprosthetics systems. Advanced healthcare materials, 8(24), 1801345.</li> <li>Eth, D., Foust, J. C., &amp; Whale, B. (2013). The prospects of whole brain emulation within the next half-century. Journal of Artificial General Intelligence, 4(3), 130.</li> <li>Ghezzi, D. (2015). Retinal prostheses: progress toward the next generation implants. Frontiers in neuroscience, 9, 290.</li> <li>Humphries, M. (2021, May 5). We can't upload you, sorry. Medium. Retrieved February 21, 2022, from https://onezero.medium.com/we-cant-upload-you-sorry-5c3c85f47766. </li> <li>Kaiser, M. (2013). The potential of the human connectome as a biomarker of brain disease. Frontiers in human neuroscience, 7, 484.</li> <li>Koene, R. A. (2012). Experimental research in whole brain emulation: the need for innovative in vivo measurement techniques. International Journal of Machine Consciousness, 4(01), 35-65.</li> <li>Linssen, C. A. P., &amp; Lemmens, P. C. (2016). Embodiment in whole-brain emulation and its implications for death anxiety.</li> <li>Naples, J. G., &amp; Ruckenstein, M. J. (2020). Cochlear implant. Otolaryngologic Clinics of North America, 53(1), 87-102.</li> <li>O'Gieblyn, M. (2017). Ghost in the cloud. n+1. Retrieved January 22, 2022, from https://www.nplusonemag.com/issue-28/essays/ghost-in-the-cloud/. </li> <li>Sandberg, A., &amp; Armstrong, S. (2012). Indefinite survival through backup copies. Future of Humanity </li> <li>Institute Technical Report, Future of Humanity Institute, University of Oxford, http://www.fhi.ox.ac.uk/indefinitesurvivalbackup.pdf (accessed 5 March 2013).</li> <li>Slater, M., Spanlang, B., Sanchez-Vives, M. V., &amp; Blanke, O. (2010). First person experience of body transfer in virtual reality. PloS one, 5(5), e10564.</li> <li>Tozzi, L., Staveland, B., Holt-Gosselin, B., Chesnut, M., Chang, S. E., Choi, D., ... &amp; Williams, L. M. (2020). The human connectome project for disordered emotional states: Protocol and rationale for a research domain criteria study of brain connectivity in young adult anxiety and depression. Neuroimage, 214, 116715.</li> <li>Vinge, V. (1993, March). Technological singularity. In VISION-21 Symposium sponsored by NASA Lewis Research Center and the Ohio Aerospace Institute (pp. 30-31).</li> <li>Why our minds can't really be uploaded to computers. Mind Matters News. (2020, April 22). Retrieved February 21, 2022, from https://mindmatters.ai/2020/04/why-our-minds-cant-really-be-uploaded-to-computers/. </li> <li>Yu, M., Sporns, O., &amp; Saykin, A. J. (2021). The human connectome in Alzheimer disease\u2014relationship to biomarkers and genetics. Nature Reviews Neurology, 17(9), 545-563.</li> <li>Zenki, P. T. (2020, December 6). No, your mind can't be uploaded to a computer. A Quiet Normal Life. Retrieved February 21, 2022, from https://www.quietnormal.com/mind-upload/.</li> </ol>"},{"location":"Blog/Posts/WhatIsWholeBrainEmulation/Post/","title":"What is Whole Brain Emulation","text":"<p>As humans, limitations are inherent to our existence. Our perceptions are narrow and our attention is constrained; we struggle with illness and injury. These hindrances often seem insurmountable, but we still strive to push the boundaries to their breaking points. Can you imagine what it would be like to live a life untethered, free from the physical constraints of a body? In the future, a technology called whole brain emulation (WBE) could make it possible to have unprecedented experiences such as seeing centuries of existence, developing heightened abilities of prediction, perceiving the world through new senses, or recalling details with the precision of a computer (1). An individual could potentially live indefinitely (2). WBE is the process of creating a replica of the brain so that it can operate in a digital form. Instead of acting as a model, this replica would function in an identical manner to the brain in the biological substrate (3). A simulation operates as an imitation of a structure, existing solely for observation, while an emulation reproduces behavior. </p> <p>We have always been concerned with evolving as a species. We are full of ambition, anxious to go further and achieve more than the humans of the past. We have transformed ourselves and the whole world by building cities, connecting communities, and inventing technologies that were once inconceivable. Whole brain emulation may enable us to transcend boundaries in a way never seen before. By becoming substrate-independent, or autonomous from our physical bodies, we could overcome fundamental limitations that include constrained attention, unreliable memory, illness, fatigue, and the human lifespan.</p> <p>WBE depends on a functionalist understanding of the mind, which says that the operations of the brain produce a cohesive, conscious human. The mind can be reproduced as long as neuronal function is emulated. Since the brain is constantly changing itself at the molecular level (4), the mind can be considered a dynamic process that does not necessarily arise from the specific physical matter of neurons. Consequently, it can be emulated in a non-biological substrate.</p> <p>The first steps of WBE are scanning and modeling. Before we can emulate the individual details of a brain, it is necessary to build a connectome \u2014 a complete map of neural connections. This establishes a baseline model and helps us properly understand the relationships and functions of neurons. To facilitate modeling on an individual scale, the brain must be scanned. One essential technology of connectomics is electron microscopy, which utilizes radiation from electrons to obtain high-resolution images (5). By using the technology to photograph thin slices of tissue, researchers have mapped the connectome of the fruit fly Drosophila (6) and reconstructed a region of the human hippocampus in a computer model (7). As an alternative to imaging, large-scale dynamic recording could build a map of neural function. This is already possible in C. elegans (8). Recently, fluorescence microscopy has allowed for the mapping of an entire primate brain at a detailed, micrometer resolution (9); such a feat took only 100 hours. Although a macaque brain is less complex than a human brain, this opens the encouraging possibility of a future human connectome.</p> <p>After an accurate simulation, the process of translation will convert a neural model to a working emulation, combining structure and function. The product could potentially resemble existing neural networks that possess the human-like ability to predict and learn based on input. Through digital software, equations could mimic action potentials (10). However, emulations would incorporate all the mechanisms and organic flexibility of biological organisms rather than being constrained to the comparative simplicity of current-day artificial intelligence (11). While the computers of today cannot use common sense, understand emotion, conceptualize identities, or reason through logical arguments, an emulated being would have all these capabilities. One technological development that may be a precursor to WBE is neural prosthesis, comprising devices that replace missing or deficient function, such as cochlear implants that transduce sound. Visual prosthetics restore sight (12), motor prosthetics enable conscious control of movement (13), and tactile prosthetics allow amputees to perceive touch and pain (14). Researchers have developed a hippocampal prosthetic that enables the formation of long-term memories (15). These devices show that it is possible for technology to successfully emulate the workings of biological neurons.</p> <p>There are two procedural methods for WBE that are currently being discussed: gradual replacement and scan-and-copy. Gradual replacement would slowly install technological devices in place of neurons or neural circuits, whereas scan-and-copy would image the brain in order to emulate it in a digital substrate. The former is an inherently destructive process, but the latter may preserve the original brain depending on future advances in technology. The method of destructive scan-and-copy would likely come before gradual replacement as well as non-destructive scan-and-copy. There is a misconception that gradual replacement is superior to scan-and-copy, as it might better ensure personal survival through utilizing the same body; however, the two procedures are not so different from each other. Both would result in a transfer of functional activity. As the original brain is destroyed through gradual replacement, biological neurons yield their function to devices and can no longer operate. The same would be true for a destructive method of scan-and-copy, regardless of the distance traveled. The preservation of identity and survival are equally likely in both gradual replacement and scan-and-copy scenarios (16).</p> <p>Moving away from the technological possibilities, WBE presents several philosophical questions. Would an emulated brain develop a personality or identity, and would it match that of the biological brain? Would our minds be transferred or would we stay in our bodies? How can a machine develop consciousness? What is consciousness, and how can identity be defined? As far as we know, neither identity nor consciousness is magical; instead, they are tangible and arise from brain activity (17). The concept of the self can be traced to a series of regions included in the default mode network, which is active upon rest and associated with mind-wandering (18). As described in the attention schema theory, consciousness is subjective awareness that is constructed in a model of attention similar to the body schema (19). In other words, the brain can focus on certain signals while dimming others; when this is built into a representation, consciousness emerges. Based on this theory, consciousness is able to be emulated like any other neural function, as are identity and personality. </p> <p>The transfer of consciousness is a tricky idea. Most likely, there will be two entities with awareness (assuming the original brain is not destroyed), but there is no consensus on whether a procedure of WBE would result in personal survival. Addressing this concern, psychological branching identity says that continuity of consciousness will occur in the uploaded brain as well as the original brain (20). Both minds would have an equal claim to the original identity. A similar phenomenon occurs in split-brain patients, where the severing of the corpus callosum results in two conscious states (21). Each hemisphere is independently alert, but each is psychologically continuous. This is also comparable to the two cells created upon the division of a single-celled organism. Therefore, an emulation would not be a copy, but an individual with continuity of consciousness and identity. </p> <p>Despite these potential answers, a discussion of mind uploading is still quite speculative. There is much uncertainty on the path forward. Instead of becoming discouraged, we should use our questions as motivation to spur the development of whole brain emulation.</p>"},{"location":"Blog/Posts/WhatIsWholeBrainEmulation/Post/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Berger, T. W., Song, D., Chan, R. H., Marmarelis, V. Z., LaCoss, J., Wills, J., ... &amp; Granacki, J. J. (2012). A hippocampal cognitive prosthesis: multi-input, multi-output nonlinear modeling and VLSI implementation. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 20(2), 198-211.</p> </li> <li> <p>Cerullo, M. A. (2015). Uploading and branching identity. Minds and Machines, 25(1)</p> </li> <li> <p>Davey, C. G., Pujol, J., &amp; Harrison, B. J. (2016). Mapping the self in the brain's default mode network. Neuroimage, 132, 390-397.</p> </li> <li> <p>Gazzaniga, M. S. (1967). The split brain in man. Scientific American, 217(2), 24-29.</p> </li> <li> <p>Graziano, M. S., &amp; Webb, T. W. (2015). The attention schema theory: a mechanistic account of subjective awareness. Frontiers in psychology, 6, 500.</p> </li> <li> <p>Gulyaeva, N. V. (2017). Molecular mechanisms of neuroplasticity: an expanding universe. Biochemistry (Moscow), 82(3), 237-242.</p> </li> <li> <p>Koch, C., &amp; Tononi, G. (2008). Can machines be conscious?. Ieee Spectrum, 45(6), 55-59.</p> </li> <li> <p>Koene, R. A. (2012). Fundamentals of whole brain emulation: State, transition and update representations. International Journal of Machine Consciousness, 4(01), 5-21.</p> </li> <li> <p>Maghami, M. H., Sodagar, A. M., Lashay, A., Riazi-Esfahani, H., &amp; Riazi-Esfahani, M. (2014). Visual prostheses: the enabling technology to give sight to the blind. Journal of ophthalmic &amp; vision research, 9(4), 494.</p> </li> <li> <p>Montero-Crespo, M., Dominguez-Alvaro, M., Rondon-Carrillo, P., Alonso-Nanclares, L., DeFelipe, J., &amp; Blazquez-Llorca, L. (2020). Three-dimensional synaptic organization of the human hippocampal CA1 field. Elife, 9, e57013. </p> </li> <li> <p>Okahara, Y., Takano, K., Nagao, M., Kondo, K., Iwadate, Y., Birbaumer, N., &amp; Kansaku, K. (2018). Long-term use of a neural prosthesis in progressive paralysis. Scientific reports, 8(1), 1-8.</p> </li> <li> <p>Osborn, L. E., Dragomir, A., Betthauser, J. L., Hunt, C. L., Nguyen, H. H., Kaliki, R. R., &amp; Thakor, N. V. (2018). Prosthesis with neuromorphic multilayered e-dermis perceives touch and pain. Science robotics, 3(19).</p> </li> <li> <p>Randi, F., &amp; Leifer, A. M. (2020). Measuring and modeling whole-brain neural dynamics in Caenorhabditis elegans. Current Opinion in Neurobiology, 65, 167-175.</p> </li> <li> <p>Sandberg, A., &amp; Armstrong, S. (2012). Indefinite survival through backup copies. Future of Humanity Institute Technical Report, Future of Humanity Institute, University of Oxford, http://www.fhi.ox.ac. uk/indefinitesurvivalbackup.pdf.</p> </li> <li> <p>Scheffer, L. K., Xu, C. S., Januszewski, M., Lu, Z., Takemura, S. Y., Hayworth, K. J., ... &amp; Plaza, S. M. (2020). A connectome and analysis of the adult Drosophila central brain. Elife, 9, e57443.</p> </li> <li> <p>Serruya, M. D. (2017). Connecting the brain to itself through an emulation. Frontiers in neuroscience, 11, 373.</p> </li> <li> <p>TEDx Talks. (2012, Sep 4). Machines in minds to reverse engineer the machine that is mind: Randal A. Koene at TEDxTallinn [Video]. YouTube. https://www.youtube.com/watch?v=IM_k_c6Uj0A. </p> </li> <li> <p>What is Electron Microscopy? University of Massachusetts Medical School. (n.d.). https://www.umassmed.edu/cemf/whatisem/.</p> </li> <li> <p>Wiley, K. B., &amp; Koene, R. A. (2015). The fallacy of favoring gradual replacement mind uploading over scan-and-copy. arXiv preprint arXiv:1504.06320.</p> </li> <li> <p>Xu, F., Shen, Y., Ding, L., Yang, C. Y., Tan, H., Wang, H., ... &amp; Bi, G. Q. (2021). High-throughput mapping of a whole rhesus monkey brain at micrometer resolution. Nature Biotechnology, 1-8.</p> </li> </ol>"},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/","title":"What will the first Substrate Independent Mind Look Like?","text":""},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#what-will-the-first-substrate-independent-mind-look-like","title":"What Will the First Substrate Independent Mind Look Like?","text":""},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#a-theoretical-projection-article-by-michael-ulrich","title":"A Theoretical Projection Article by Michael Ulrich","text":"<p>Whole Brain Emulation continues to gain traction in research and development. Whether it be in the advancements in neural prostheses, more precise connectomic mapping, or strictly in artificial intelligence; more effort is being focused on  engineering research instead of solely philosophical debates. If this trend continues, there will be a point where the first facility is established to conduct official testing of human brain emulation. After that, the first successful emulation will be made marking the day where human evolution takes another giant leap forward. It is easy, and exciting, to let one\u2019s mind imagine all the possibilities for whole brain emulation advancements and what that could mean for divergent evolutionary paths. However, it helps one\u2019s realistic perspective and guides one's foresight to have a sensible projection of what a substrate independent mind will be on a physical level in regards to aspects such as material, size, limitations, and it\u2019s responsibility to sustain the mind of it\u2019s emulated human host. This article will theorize what the first substrate-independent mind might physically look like and what its limitations will be.</p>"},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#the-road-to-emulation-is-a-gradual-incline-with-many-stages-and-milestones","title":"The road to emulation is a gradual incline with many stages and milestones.","text":"<p>Undeniably, the first case of a successful emulated human mind will have a huge impact on the world and make its mark in our history books. It will also likely be far less sudden and unexpected than we might tend to imagine. Building an emulation is best done in stages. For example, treating each section of the brain as separate emulation projects would be easier to focus on than tackling the entire brain at once. There will be successful emulations of sections of the brain before they can operate as one complete operating substrate. Even emulating a handful of neurons at biophysical precision is a daunting task and every group of neurons in the brain have their own unique operations. Furthermore, emulating animal brains will come before a human emulation. Progress will be marked by emulations of animal brains with increasing cognitive complexity. This is why subjects such as the fruit fly drosophila and the nematode worm Caenorhabditis elegans are prime initial emulation subjects. It will also be a massive cooperation effort. Teams from all over the world are already working on various research and development projects that ultimately help get us to whole brain emulation.  The more cooperation, the better. Progress toward the first successful human emulation will be very gradual. Therefore, when the day comes to witness the first successful human emulation it will be more like a sigh of relief for all the hard work rather than some grander surprise.</p>"},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#so-what-does-this-first-successful-emulation-look-like-physically","title":"So, what does this first successful emulation look like physically?","text":"<p>Some things to consider are the similarities to a modern day computer and what that includes. The default consensus is that the structure of the substrate is built with similar features of a modern day computer. Now, this might seem redundant to note as it is obvious to anyone familiar with the concept of mind uploading, but it really is important to keep this in mind: that a new type of computer is really all that it is. Nothing about the substrate, to enable the emulated mind, should be any concept too foreign to wrap one's head around. So, given that the information of a person's mind is huge (big data) the substrate may have a large size compared to that of modern day computers. There are other possible outcomes of what computing capabilities will be like in the future by the time that whole brain emulation is realized. The size of the computer required to store all the data necessary for an emulated brain may be very small. It is hard to predict what computer sizes will be like based on how much information they can hold. It could also likely need a huge power source depending on how the methods for power consumption has advanced for computing. It will likely be made of circuits housed in silicon surrounded by wires, power supplies, cooling devices, and encased in a well-sealed metal containment. Imagine the size of the first computers in the 1970s. It may be realistic to project that the first successful emulation substrate could be the size of several rooms when considering that if the substrate were built today, it would need this much space. In the facility in which this substrate will be, it will likely be monitored and maintained around the clock by scientists and engineers. The facility would have a security team, well regulated temperature and humidity controls for the environment, be a high level cleanroom, and likely be located in an area with a high concentration of engineering organizations (like Silicon Valley).</p>"},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#how-can-we-know-when-a-test-is-successful","title":"How can we know when a test is successful?","text":"<p>There is also the question of how we test the success of an emulated mind. Imagine how the scenario will be when the first successful whole brain emulation is observed. The immediate imagined scenario that plays in my head is this: The donated patient's brain is fully scanned, the room-sized substrate has been built, the lead scientist presses the button to download the code that constructs the patient's mind simulation program in the hardware of the substrate; once the download is complete, the scientist says to the mind, \"Mr. Smith, can you hear me?\" A few seconds later, there is text written on the scientist's screen that says, \"Yes.\" This may be far from what will take place when the first successful emulation is observed, but it tries to remain within a reasonable and somewhat likely portrayal of how the event will unfold.</p> <p>It is not unreasonable to project that the emulated mind will have to provide the observers with feedback that communicates a level of cognition similar to the levels of cognition of the host patient prior to the scanning of the original organic brain. Assuming that the patient's original mind now operates within the substrate, that patient would likely need to willingly give feedback to the observing scientists to provide as much data as possible that this is indeed a successful emulation. The task of recognizing some level of distinguishable personality will be limited by the capabilities of the substrate. This may be limited by the ability to recognize the unique personality of a patient by the physical features of their original body (such as facial expressions, mannerisms, and tone of voice), given that their mind now resides in a room-size box-shape computer. As a proposition, maybe a voice producing device with code capable of replicating voice patterns unique to an individual may provide a means for the scientists to observe some level of recognizable personality that is unique to that of the emulated patient. There is also the possibility that the lifespan of the first emulated mind will be very short, perhaps even only a few seconds. This could be an accepted risk for patients volunteering to undergo the first emulation procedure with the understanding that this procedure is also testing many aspects of sustainability. It would still be a monumental accomplishment in whole brain emulation, even if the patient\u2019s emulation was sustained for only a short time.</p>"},{"location":"Blog/Posts/WhatWillFirstSIMLookLike/Post/#from-projection-to-construction","title":"From projection to construction","text":"<p>A successful first emulation will likely be done with a substrate that is crude, experimental, expensive, highly monitored, fragile, and assembled with computer components that are familiar to what is manufactured today. It will also likely have a large spatial volume and high power consumption (assuming that computing capabilities at the time when whole brain emulation is realized is similar to that of today). While a completed successful first emulation on a substrate independent mind is a theory based on reason, it serves as a blueprint to fill in the gaps. While research and development is absolutely essential for real progress toward a working emulation, theory and philosophy provide goals and milestones to aim to reach. Keeping in mind that the first successful emulation will not be surprising, epic, or pandemonium-inducing, can help encourage those working to realize the first successful emulation without anxiety or hesitation. As with every scientific breakthrough in human history, whole brain emulation will just happen, and it will be normal.</p>"},{"location":"CarbonGPT/","title":"Index","text":""},{"location":"CarbonGPT/#_1","title":"Index","text":""},{"location":"CarbonGPT/#_2","title":"Index","text":""},{"location":"CarbonGPT/#carbongpt-ask-the-llm-service-undergoing-maintainance","title":"CarbonGPT - Ask the LLM! Service undergoing maintainance","text":""},{"location":"Contact/","title":"Contact Us","text":"<p>In addition to general inquiries, please send all speaking and media requests for Dr. Koene via the contact email.</p> <p>We'd love to hear from you. Please use the information below to get in touch.</p>"},{"location":"Contact/#general-inquiries","title":"General Inquiries","text":"<p>For general questions, speaking engagements, and media requests, please reach out to us via email or phone.</p> <ul> <li> Email: contact@carboncopies.org</li> <li> Phone: +1 (415) 484-0528</li> </ul>"},{"location":"Contact/#mailing-address","title":"Mailing Address","text":"<p> Carboncopies Foundation  2108 N ST STE 6380  Sacramento, CA 95816  USA</p>"},{"location":"Contact/#connect-with-us","title":"Connect With Us","text":"<ul> <li>Join Our Community: Connect with our team, volunteers, and other supporters. Learn more about joining.</li> <li>Follow Us on Social Media:<ul> <li> GitLab</li> <li> Facebook</li> <li> Twitter</li> <li> LinkedIn</li> <li> YouTube</li> <li> Discord</li> </ul> </li> </ul>"},{"location":"Donate/","title":"Donate","text":"<p>Your contribution directly supports our mission to advance the science of whole brain emulation. Donations are primarily used to fund our research efforts, including the acquisition of necessary hardware and software, and to support our educational outreach programs. All donations are tax-deductible.</p> <p>Carboncopies is a U.S. IRS approved 501(c)(3) non-profit organization. As such, donations to Carboncopies are tax deductible in the United States. Please use the Donate button to make a philanthropic contribution.</p> <p>Or donate via Paypal or Crypto.</p> <p>Paypal Crypto</p> <p>Please contact us about other methods or if you have any questions.</p>"},{"location":"Donate/#faqs","title":"FAQs","text":"<p>What do we spend donations on?</p> Date Item Price Note 2024-06-25 Server RAM/CPU Upgrades $857.14 Your donations enabled us to upgrade the RAM and CPUs in our two servers, accelerating development of the Brain Emulation Challenge. Are there any individual benefits for donors?  Asides from being tax-deductible, currently we utilize 100% of donations towards progressing development of Whole Brain Emulation.    Are donations to CarbonCopies Foundation tax deductible?  Carboncopies is a U.S. IRS approved 501\\(c)(3) non-profit organization. As such, donations to Carboncopies are tax deductible in the United States. EIN: 81-4083638"},{"location":"Events/","title":"Events","text":""},{"location":"Events/#neuroethics-of-whole-brain-emulation-panel-discussion-june-30-2024","title":"Neuroethics of Whole Brain Emulation Panel Discussion, June 30, 2024","text":""},{"location":"Events/#carboncopies-foundation-workshop-june-2021","title":"Carboncopies Foundation Workshop, June 2021","text":""},{"location":"Events/#c-elegans","title":"C-ELEGANS","text":""},{"location":"Events/#the-first-emulation","title":"The First Emulation?","text":"<p>The nematode C. Elegans is a primary subject for neural connectome mapping and experimentation because of its connectome features.</p> <p>It is a good way to study methods to scan and model. This is because it is a simple organism with a tiny connectome of 302 neurons always connected in the same way.</p> <p>In this workshop we will discuss the implications of C. Elegans research including the current C. Elegans modeling challenges, current connectomic mapping and modeling advances, and counter arguments against C. Elegans being an effective precursor to human connectome research.</p>"},{"location":"Events/#carboncopies-foundation-fall-2020-workshop-december-20-2020","title":"Carboncopies Foundation Fall 2020 Workshop, December 20, 2020","text":""},{"location":"Events/#updating-the-roadmap-to-whole-brain-emulation-part-6-neural-modeling","title":"Updating the Roadmap to Whole Brain Emulation Part 6: NEURAL MODELING","text":""},{"location":"Events/#patient-specific-selection-fitting-and-validation","title":"Patient Specific Selection, Fitting and Validation","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-winter-2020-workshop-march-15-2020","title":"Carboncopies Foundation Winter 2020 Workshop, March 15, 2020","text":""},{"location":"Events/#updating-the-roadmap-to-whole-brain-emulation-part-4-successful-mind-uploading-what-is-personal-identity-and-how-can-it-survive-mind-uploading","title":"Updating the Roadmap to Whole Brain Emulation Part 4: SUCCESSFUL MIND UPLOADING What is Personal Identity and How Can It Survive Mind Uploading","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-fall-2019-workshop-december-14-2019","title":"Carboncopies Foundation Fall 2019 Workshop, December 14, 2019","text":""},{"location":"Events/#updating-the-roadmap-to-whole-brain-emulation-part-3-consciousness","title":"Updating the Roadmap to Whole Brain Emulation Part 3: Consciousness","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-summer-2019-workshop-september-21-2019","title":"Carboncopies Foundation Summer 2019 Workshop, September 21, 2019","text":""},{"location":"Events/#updating-the-roadmap-to-whole-brain-emulation-part-2-where-we-go-from-here","title":"Updating the Roadmap to Whole Brain Emulation Part 2: Where We Go From Here","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-spring-2019-workshop-june-1-2019","title":"Carboncopies Foundation Spring 2019 Workshop, June 1, 2019","text":""},{"location":"Events/#updating-the-roadmap-to-whole-brain-emulation-part-1","title":"Updating the Roadmap to Whole Brain Emulation Part 1:","text":""},{"location":"Events/#review-of-the-oxford-roadmap-on-whole-brain-emulation","title":"Review of the Oxford Roadmap on Whole Brain Emulation","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-winter-2019-workshop-march-16-2019","title":"Carboncopies Foundation Winter 2019 Workshop, March 16, 2019","text":""},{"location":"Events/#ai-safety-and-whole-brain-emulation","title":"AI safety and Whole Brain Emulation","text":"<p>This event was hosted online and the archived event page can be found here. A transcript of this event is also available.</p>"},{"location":"Events/#carboncopies-foundation-summer-2018-workshop-september-15-2018","title":"Carboncopies Foundation Summer 2018 Workshop, September 15, 2018","text":""},{"location":"Events/#metaphysics-and-ethics-of-whole-brain-emulation","title":"Metaphysics and Ethics of Whole Brain Emulation","text":"<p>This event was hosted online and the archived event page can be found here.</p>"},{"location":"Events/#carboncopies-foundation-spring-2018-workshop-april-29-2018","title":"Carboncopies Foundation Spring 2018 Workshop, April 29, 2018","text":""},{"location":"Events/#from-brain-preservation-to-reconstruction","title":"From Brain Preservation to Reconstruction","text":"<p>This was a hybrid San Francisco Bay Area + Online workshop.</p> <p>The archived workshop page with links to summary and videos is here.</p>"},{"location":"Events/#carboncopies-foundation-2018-winter-workshop-jan-28-2018","title":"Carboncopies Foundation 2018 Winter Workshop, Jan 28, 2018","text":""},{"location":"Events/#transcending-biology-reverse-engineering-the-brain","title":"Transcending Biology: Reverse engineering the brain","text":"<p>This was a hybrid San Francisco Bay Area + Online workshop.</p> <p>The archived workshop page with links to summary and videos is here.</p>"},{"location":"Events/Calendar/","title":"Calendar","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Events/JournalClub/","title":"JournalClub","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Events/Livestream/","title":"Livestream Event","text":"<p>Our upcoming experts panel event on the Neuroethics of Whole Brain Emulation is on Sunday, June 30, 2024 at 10 am PDT (1 pm EDT, 19:00 CET).</p> <p>To participate in the event live, please join the Google Meet session at http://meet.google.com/apd-juyw-fby</p> <p>Audience participation is possible during Q&amp;A intervals after each topic.</p> <p>Visit our Ethics site at https://sites.google.com/carboncopies.org/ethics for more information.</p> <p>For more information about past events, please visit our event page page.</p> <p>Please stay informed by joining us on Facebook, Twitter, and more, see our contact page.</p>"},{"location":"Events/JournalClubs/","title":"Journal Clubs","text":"<ul> <li> <p>Memory Decoding</p> <p> Read more about the Memory Decoding journal club</p> </li> <li> <p>Consciousness &amp; Subjective Experience</p> <p> Read more about the Consciousness &amp; Subjective Experience journal club</p> </li> </ul>"},{"location":"Events/JournalClubs/ConsciousnessAndSubjectiveExperience/","title":"Consciousness and Subjective Experience journal club","text":"<p>This is a collaborative biweekly engagement involving primarily members of the Carboncopies Foundation and of the Brain Preservation Foundation. We are primarily discussing papers and books that cumulatively give us a good understanding of the state of the field, and that ultimately enable us to connect experimental and reductionist approaches to theories of consciousness and its neural correlates with approaches that begin with the structure of subjective phenomenology. We include specific attention to all aspects of what Chalmers has dubbed the \"hard problem\" of consciousness.</p> <p>Ultimately, we aim for insights gained to coalesce into what we may consider a satisfying and defensible model of consciousness and subjective experience that aligns with and informs foundational core assumptions with regards to whole brain emulation.</p> <p>Furthermore, insights into the requirements for subjective experience, being able to distinguish types of intelligent processing that have conscious subjective experiences from those that probably cannot, implications for the needs of well-being versus the risks of suffering, and attribution of personhood will inform work in our WBE Ethics Framework project.</p> <p>The journal club meets biweekly. If you are interested in joining, please message us at contact@carboncopies.org.</p> <p>Materials studied so far:</p> <ul> <li>Being No One: The Self-Model Theory of Subjectivity, Thomas Metzinger, MIT Press, 2004</li> <li>Falsification and consciousness, Johannes Kleiner and Erik Hoel, Neuroscience of Consciousness, 2021</li> <li>Facing Up to the Problem of Consciosuness, David J. Chalmers, In The Character of Consciousness, Oxford University Press, 2010</li> <li>Consciousness and the Fallacy of Misplaced Objectivity, Francesco Ellia, Jeremiah Hendren, Matteo Grasso, Csaba Kozma, Garrett Mindt, Jonathan P. Lang, Andrew M. Haun, Larissa Albantakis, Melanie Boly, Giulio Tononi, Neuroscience of Consciousness, 2021</li> <li>What Subjectivity Is Not, Joseph Neisser, In The Science of Subjectivity, 2015</li> </ul>"},{"location":"Events/JournalClubs/MemoryDecoding/","title":"Memory Decoding Journal Club","text":"<p>The Memory Decoding journal club is a coproduction in a partnership between the Carboncopies Foundation and the Brain Preservation Foundation's Aspirational Neuroscience Prize.</p> <p>For more information about the Memory Decoding Challenge go to aspirationalneuroscience.org.</p> <p>This journal club takes place biweekly on Tuesdays at 3 pm PDT (6 pm EDT, 00:00 CET).</p> <p>You can participate directly by joining the online session.</p> <p>Register to receive automatic updates.</p> <p>Watch recordings of previous Memory Decoding Journal Club presentations on the Aspirational Neuroscience YouTube channel.</p> <ul> <li> <p>Aspirational Neuroscience</p> <p></p> </li> <li> <p>Carboncopies Foundation</p> <p></p> </li> </ul>"},{"location":"Events/JournalClubs/MemoryDecoding/2024-09-29/","title":"Connectome-constrained networks predict neural activity across the fly visual system","text":"<p>Or watch the recording on the Carboncopies Foundation Media Server.</p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal Koene September 29, 2024</p> <p>Paper: Connectome-constrained networks predict neural activity across the fly visual system Janne K. Lappalainen, Fabian D. Tschopp, Sridhama Prakhya, Mason McGill, Aljoscha Nern, Kazunori Shinomiya, Shin-ya Takemura, Eyal Gruntman, Jakob H. Macke &amp; Srinivas C. Turaga Nature 634, 1132\u20131140 (2024). https://doi.org/10.1038/s41586-024-07939-3 </p>"},{"location":"Events/JournalClubs/MemoryDecoding/2024-09-29/#abstract","title":"Abstract","text":"<p>We can now measure the connectivity of every neuron in a neural circuit, but we cannot measure other biological details, including the dynamical characteristics of each neuron. The degree to which measurements of connectivity alone can inform the understanding of neural computation is an open question. Here we show that with experimental measurements of only the connectivity of a biological neural network, we can predict the neural activity underlying a specified neural computation. We constructed a model neural network with the experimentally determined connectivity for 64 cell types in the motion pathways of the fruit fly optic lobe1 but with unknown parameters for the single-neuron and single-synapse properties. We then optimized the values of these unknown parameters using techniques from deep learning11, to allow the model network to detect visual motion12. Our mechanistic model makes detailed, experimentally testable predictions for each neuron in the connectome. We found that model predictions agreed with experimental measurements of neural activity across 26 studies. Our work demonstrates a strategy for generating detailed hypotheses about the mechanisms of neural circuit function from connectivity measurements. We show that this strategy is more likely to be successful when neurons are sparsely connected\u2014a universally observed feature of biological neural networks across species and brain regions.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2024-12-29/","title":"A Drosophila computational brain model reveals sensorimotor processing","text":"<p>Or watch the recording on the Carboncopies Foundation Media Server.</p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Archit Kalra December 29, 2024</p> <p>Paper: A Drosophila computational brain model reveals sensorimotor processing Philip K. Shiu, Gabriella R. Sterne, Nico Spiller, Romain Franconville, Andrea Sandoval, Joie Zhou, Neha Simha, Chan Hyuk Kang, Seongbong Yu, Jinseop S. Kim, Sven Dorkenwald, Arie Matsliah, Philipp Schlegel, Szi-chieh Yu, Claire E. McKellar, Amy Sterling, Marta Costa, Katharina Eichler, Alexander Shakeel Bates, Nils Eckstein, Jan Funke, Gregory S. X. E. Jefferis, Mala Murthy, Salil S. Bidaye, Stefanie Hampel, Andrew M. Seeds &amp; Kristin Scott Nature 634, 210\u2013219 (2024). https://doi.org/10.1038/s41586-024-07763-9</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2024-12-29/#abstract","title":"Abstract","text":"<p>The recent assembly of the adult Drosophila melanogaster central brain connectome, containing more than 125,000 neurons and 50 million synaptic connections, provides a template for examining sensory processing throughout the brain. Here we create a leaky integrate-and-fire computational model of the entire Drosophila brain, on the basis of neural connectivity and neurotransmitter identity, to study circuit properties of feeding and grooming behaviours. We show that activation of sugar-sensing or water-sensing gustatory neurons in the computational model accurately predicts neurons that respond to tastes and are required for feeding initiation. In addition, using the model to activate neurons in the feeding region of the Drosophila brain predicts those that elicit motor neuron firing \u2014 a testable hypothesis that we validate by optogenetic activation and behavioural studies. Activating different classes of gustatory neurons in the model makes accurate predictions of how several taste modalities interact, providing circuit-level insight into aversive and appetitive taste processing. Additionally, we applied this model to mechanosensory circuits and found that computational activation of mechanosensory neurons predicts activation of a small set of neurons comprising the antennal grooming circuit, and accurately describes the circuit response upon activation of different mechanosensory subtypes. Our results demonstrate that modelling brain circuits using only synapse-level connectivity and predicted neurotransmitter identity generates experimentally testable hypotheses and can describe complete sensorimotor transformations.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-03-11/","title":"Dynamic and selective engrams emerge with memory consolidation","text":"<p>Or watch the recording on the Carboncopies Foundation Media Server.</p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Ariel Zeleznikow-Johnston March 11, 2025</p> <p>Paper: Dynamic and selective engrams emerge with memory consolidation Douglas Feitosa Tom\u00e9, Ying Zhang, Tomomi Aida, Olivia Mosto, Yifeng Lu, Mandy Chen, Sadra Sadeh, Dheeraj S. Roy &amp; Claudia Clopath Nature Neuroscience 27, 561\u2013572 (2024). https://doi.org/10.1038/s41593-023-01551-w</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-03-11/#abstract","title":"Abstract","text":"<p>Episodic memories are encoded by experience-activated neuronal ensembles that remain necessary and sufficient for recall. However, the temporal evolution of memory engrams after initial encoding is unclear. In this study, we employed computational and experimental approaches to examine how the neural composition and selectivity of engrams change with memory consolidation. Our spiking neural network model yielded testable predictions: memories transition from unselective to selective as neurons drop out of and drop into engrams; inhibitory activity during recall is essential for memory selectivity; and inhibitory synaptic plasticity during memory consolidation is critical for engrams to become selective. Using activity-dependent labeling, longitudinal calcium imaging and a combination of optogenetic and chemogenetic manipulations in mouse dentate gyrus, we conducted contextual fear conditioning experiments that supported our model\u2019s predictions. Our results reveal that memory engrams are dynamic and that changes in engram composition mediated by inhibitory plasticity are crucial for the emergence of memory selectivity.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-04-08/","title":"Reconstructing a new hippocampal engram for systems reconsolidation and remote memory updating","text":"<p>Or watch the recording on the Carboncopies Foundation Media Server.</p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal A. Koene April 8, 2025</p> <p>Paper: Reconstructing a new hippocampal engram for systems reconsolidation and remote memory updating Bo Lei, Bilin Kang, Yuejun Hao, Haoyu Yang, Zihan Zhong, Zihan Zhai, Yi Zhong Neuron 113(3), 471-485 (2025). https://doi.org/10.1016/j.neuron.2024.11.010</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-04-08/#abstract","title":"Abstract","text":"<p>Recalling systems-consolidated neocortex-dependent remote memories re-engages the hippocampus in a process called systems reconsolidation. However, underlying mechanisms, particularly for the origin of the reinstated hippocampal memory engram, remain elusive. By developing a triple-event labeling tool and employing two-photon imaging, we trace hippocampal engram ensembles from memory acquisition to systems reconsolidation and find that remote recall recruits a new engram ensemble in the hippocampus for subsequent memory retrieval. Consistently, recruiting new engrams is supported by adult hippocampal neurogenesis-mediated silencing of original engrams. This new engram ensemble receives currently experienced contextual information, incorporates new information into the remote memory, and supports remote memory updating. Such a reconstructed hippocampal memory is then integrated with the valence of remote memory via medial prefrontal cortex projection-mediated activity coordination between the hippocampus and amygdala. Thus, the reconstruction of new memory engrams underlies systems reconsolidation, which explains how remote memories are updated with new information.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-04-22/","title":"Fear learning induces synaptic potentiation between engram neurons in the rat lateral amygdala","text":"<p>Or watch the recording on the Carboncopies Foundation Media Server.</p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Kenneth Hayworth April 22, 2025</p> <p>Paper: Fear learning induces synaptic potentiation between engram neurons in the rat lateral amygdala Marios Abatis, Rodrigo Perin, Ruifang Niu, Erwin van den Burg, Chloe Hegoburu, Ryang Kim, Michiko Okamura, Haruhiko Bito, Henry Markram &amp; Ron Stoop Nature Neuroscience 27, 1309\u20131317 (2024). https://doi.org/10.1038/s41593-024-01676-6</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-04-22/#abstract","title":"Abstract","text":"<p>The lateral amygdala (LA) encodes fear memories by potentiating sensory inputs associated with threats and, in the process, recruits 10\u201330% of its neurons per fear memory engram. However, how the local network within the LA processes this information and whether it also plays a role in storing it are still largely unknown. Here, using ex vivo 12-patch-clamp and in vivo 32-electrode electrophysiological recordings in the LA of fear-conditioned rats, in combination with activity-dependent fluorescent and optogenetic tagging and recall, we identified a sparsely connected network between principal LA neurons that is organized in clusters. Fear conditioning specifically causes potentiation of synaptic connections between learning-recruited neurons. These findings of synaptic plasticity in an autoassociative excitatory network of the LA may suggest a basic principle through which a small number of pyramidal neurons could encode a large number of memories.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-05-06/","title":"Motor learning selectively strengthens cortical and striatal synapses of motor engram neurons","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Ariel Zeleznikow-Johnston May 6, 2025</p> <p>Paper: Motor learning selectively strengthens cortical and striatal synapses of motor engram neurons Fuu-Jiun Hwang, Richard H. Roth, Yu-Wei Wu, Yue Sun, Destany K. Kwon, Yu Liu, Jun B. Ding Neuron 110, 2790\u20132801 (2022). https://doi.org/10.1016/j.neuron.2022.06.006</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-05-06/#abstract","title":"Abstract","text":"<p>Learning and consolidation of new motor skills require plasticity in the motor cortex and striatum, two key motor regions of the brain. However, how neurons undergo synaptic changes and become recruited during motor learning to form a memory engram remains unknown. Here, we train mice on a motor learning task and use a genetic approach to identify and manipulate behavior-relevant neurons selectively in the primary motor cortex (M1). We find that the degree of M1 engram neuron reactivation correlates with motor performance. We further demonstrate that learning-induced dendritic spine reorganization specifically occurs in these M1 engram neurons. In addition, we find that motor learning leads to an increase in the strength of M1 engram neuron outputs onto striatal spiny projection neurons (SPNs) and that these synapses form clusters along SPN dendrites. These results identify a highly specific synaptic plasticity during the formation of long-lasting motor memory traces in the corticostriatal circuit.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-05-20/","title":"Synaptic architecture of a memory engram in the mouse hippocampus","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal A. Koene May 20, 2025</p> <p>Paper: Synaptic architecture of a memory engram in the mouse hippocampus Marco Uytiepo, Yongchuan Zhu, Eric Bushong, Katherine Chou, Filip Souza Polli, Elise Zhao, Keun-Young Kim, Danielle Luu, Lyanne Chang, Dong Yang, Tsz Ching Ma, Mingi Kim, Yuting Zhang, Grant Walton, Tom Quach, Matthias Haberl, Luca Patapoutian, Arya Shahbazi, Yuxuan Zhang, Elizabeth Beutter, Weiheng Zhang, Brian Dong, Aureliano Khoury, Alton Gu, Elle McCue, Lisa Stowers, Mark Ellisman, and Anton Maximov Science 387, eado8316 (2025). https://doi.org/10.1126/science.ado8316</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-05-20/#abstract","title":"Abstract","text":"<p>Memory engrams are formed through experience-dependent plasticity of neural circuits, but their detailed architectures remain unresolved. Using three-dimensional electron microscopy, we performed nanoscale reconstructions of the hippocampal CA3-CA1 pathway after chemogenetic labeling of cellular ensembles recruited during associative learning. Neurons with a remote history of activity coinciding with memory acquisition showed no strong preference for wiring with each other. Instead, their connectomes expanded through multisynaptic boutons independently of the coactivation state of postsynaptic partners. The rewiring of ensembles representing an initial engram was accompanied by input-specific, spatially restricted upscaling of individual synapses, as well as remodeling of mitochondria, smooth endoplasmic reticulum, and interactions with astrocytes. Our findings elucidate the physical hallmarks of long-term memory and offer a structural basis for the cellular flexibility of information coding.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-06-03/","title":"Structure and function of the hippocampal CA3 module","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Kenneth Hayworth June 3, 2025</p> <p>Paper: Structure and function of the hippocampal CA3 module Rosanna P. Sammons, Mourat Vezir, Laura Moreno-Velasquez, Gaspar Cano, Marta Orlando, Meike Sievers, Eleonora Grasso, Verjinia D. Metodieva, Richard Kempter, Helene Schmidt, and Dietmar Schmitz Proc. Natl. Acad. Sci. U.S.A. 121 (6) e2312281120, (2024). https://doi.org/10.1073/pnas.2312281120</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-06-03/#abstract","title":"Abstract","text":"<p>The hippocampal formation is crucial for learning and memory, with submodule CA3 thought to be the substrate of pattern completion. However, the underlying synaptic and computational mechanisms of this network are not well understood. Here, we perform circuit reconstruction of a CA3 module using three dimensional (3D) electron microscopy data and combine this with functional connectivity recordings and computational simulations to determine possible CA3 network mechanisms. Direct measurements of connectivity schemes with both physiological measurements and structural 3D EM revealed a high connectivity rate, multi-fold higher than previously assumed. Mathematical modelling indicated that such CA3 networks can robustly generate pattern completion and replay memory sequences. In conclusion, our data demonstrate that the connectivity scheme of the hippocampal submodule is well suited for efficient memory storage and retrieval.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-06-17/","title":"Neocortical synaptic engrams for remote contextual memories","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal A. Koene June 17, 2025</p> <p>Paper: Neocortical synaptic engrams for remote contextual memories Ji-Hye Lee, Woong Bin Kim, Eui Ho Park and Jun-Hyeong Ch Nature Neuroscience 26, 259\u2013273 (2023). https://doi.org/10.1038/s41593-022-01223-1</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-06-17/#abstract","title":"Abstract","text":"<p>While initial encoding of contextual memories involves the strengthening of hippocampal circuits, these memories progressively mature to stabilized forms in neocortex and become less hippocampus dependent. Although it has been proposed that long-term storage of contextual memories may involve enduring synaptic changes in neocortical circuits, synaptic substrates of remote contextual memories have been elusive. Here we demonstrate that the consolidation of remote contextual fear memories in mice correlated with progressive strengthening of excitatory connections between prefrontal cortical (PFC) engram neurons active during learning and reactivated during remote memory recall, whereas the extinction of remote memories weakened those synapses. This synapse-specific plasticity was CREB-dependent and required sustained hippocampal signals, which the retrosplenial cortex could convey to PFC. Moreover, PFC engram neurons were strongly connected to other PFC neurons recruited during remote memory recall. Our study suggests that progressive and synapse-specific strengthening of PFC circuits can contribute to long-term storage of contextual memories.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-07-01/","title":"Systems consolidation reorganizes hippocampal engram circuitry","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Ariel Zeleznikow-Johnston July 1, 2025</p> <p>Paper: Systems consolidation reorganizes hippocampal engram circuitry Sangyoon Y. Ko, Yiming Rong, Adam I. Ramsaran, Xiaoyu Chen, Asim J. Rashid, Andrew J. Mocle, Jagroop Dhaliwal, Ankit Awasthi, Axel Guskjolen, Sheena A. Josselyn &amp; Paul W. Frankland Nature (2025). https://doi.org/10.1038/s41586-025-08993-1</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-07-01/#abstract","title":"Abstract","text":"<p>Episodic memories\u2014high-fidelity memories for events that depend initially on the hippocampus\u2014do not maintain their precision in perpetuity. One benefit of this time-dependent loss of precision is the emergence of event-linked gist memories that may be used to guide future behaviour in new but related situations (that is, generalization)1,2,3. Models of systems consolidation propose that memory reorganization accompanies this loss of memory precision1,4; however, the locus of this reorganization is unclear. Here we report that time-dependent reorganization of hippocampal engram circuitry is sufficient to explain shifts in memory precision associated with systems consolidation. Using engram labelling tools in mice, we demonstrate that the passage of time rewires hippocampal engram circuits, enabling hippocampal engram neurons to be promiscuously active and guide behaviour in related situations that do not match the original training conditions. Reorganization depends on hippocampal neurogenesis; eliminating hippocampal neurogenesis prevents reorganization and maintains precise, event memories. Conversely, promoting hippocampal neurogenesis accelerates memory reorganization and the emergence of event-linked gist memories in the hippocampus. Our results indicate that systems consolidation models require updating to account for within-hippocampus reorganization that leads to qualitative shifts in memory precision.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-07-15/","title":"Binary and analog variation of synapses between cortical pyramidal neurons","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Kenneth Hayworth July 15, 2025</p> <p>Paper: Binary and analog variation of synapses between cortical pyramidal neurons Sven Dorkenwald, Nicholas L Turner, Thomas Macrina, Kisuk Lee, Ran Lu, Jingpeng Wu, Agnes L Bodor, Adam A Bleckert ,Derrick Brittain, Nico Kemnitz, William M Silversmith ,Dodam Ih, Jonathan Zung, Aleksandar Zlateski, Ignacio Tartavull, Szi-Chieh Yu, Sergiy Popovych ,William Wong, Manuel Castro, Chris S Jordan, Alyssa M Wilson, Emmanouil Froudarakis ,JoAnn Buchanan, Marc M Takeno, Russel Torres, Gayathri Mahalingam, Forrest Collman ,Casey M Schneider-Mizell, Daniel J Bumbarger, Yang LiLynne Becker, Shelby Suckow, Jacob Reimer, Andreas S Tolias, Nuno Macarico da Costa, R Clay Reid, H Sebastian Seung eLife 11: e76120 (2022). https://doi.org/10.7554/eLife.76120</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-07-15/#abstract","title":"Abstract","text":"<p>Learning from experience depends at least in part on changes in neuronal connections. We present the largest map of connectivity to date between cortical neurons of a defined type (layer \u2154 [L\u2154] pyramidal cells in mouse primary visual cortex), which was enabled by automated analysis of serial section electron microscopy images with improved handling of image defects (250 \u00d7 140 \u00d7 90 \u03bcm3 volume). We used the map to identify constraints on the learning algorithms employed by the cortex. Previous cortical studies modeled a continuum of synapse sizes by a log-normal distribution. A continuum is consistent with most neural network models of learning, in which synaptic strength is a continuously graded analog variable. Here, we show that synapse size, when restricted to synapses between L\u2154 pyramidal cells, is well modeled by the sum of a binary variable and an analog variable drawn from a log-normal distribution. Two synapses sharing the same presynaptic and postsynaptic cells are known to be correlated in size. We show that the binary variables of the two synapses are highly correlated, while the analog variables are not. Binary variation could be the outcome of a Hebbian or other synaptic plasticity rule depending on activity signals that are relatively uniform across neuronal arbors, while analog variation may be dominated by other influences such as spontaneous dynamical fluctuations. We discuss the implications for the longstanding hypothesis that activity-dependent plasticity switches synapses between bistable states.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-07-29/","title":"Nominations for the 2025 Memory Decoding Prize - Discussion","text":"<p>     On July 29, 2025 - @ 3 pm PDT (6 pm EDT, 00:00 CET)     Click Here to join the session     carboncopies.org/aspirational-neuroscience   </p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Hosted by Dr. Kenneth Hayworth, Dr. Randal A. Koene and Ariel Zeleznikow-Johnston July 29, 2025</p> <p>Join the discussion! We will be discussing the fit and merit of candidate papers to be nominated for the 2025 Memory Decoding Prize in Aspirational Neuroscience. Prizes will be announced and presented at the Aspirational Neuroscience satellite event to the Annual Meeting of the Society for Neuroscience (Nov. 2025). During this discussion it will still be possible to nominate additional papers for Memory Decoding prizes. Papers will be evaluated for their fit to the challenge to \"decode a non-trivial memory from static brain data\" and for their impact and contribution to the field.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-08-12/","title":"The dendritic engram","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal A. Koene August 12, 2025</p> <p>Paper: The dendritic engram George Kastellakis, Simone Tasciotti, Ioanna Pandi, Panayiota Poirazi Frontiers in Behavioral Neuroscience (2023). https://doi.org/10.3389/fnbeh.2023.1212139</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-08-12/#abstract","title":"Abstract","text":"<p>Accumulating evidence from a wide range of studies, including behavioral, cellular, molecular and computational findings, support a key role of dendrites in the encoding and recall of new memories. Dendrites can integrate synaptic inputs in non-linear ways, provide the substrate for local protein synthesis and facilitate the orchestration of signaling pathways that regulate local synaptic plasticity. These capabilities allow them to act as a second layer of computation within the neuron and serve as the fundamental unit of plasticity. As such, dendrites are integral parts of the memory engram, namely the physical representation of memories in the brain and are increasingly studied during learning tasks. Here, we review experimental and computational studies that support a novel, dendritic view of the memory engram that is centered on non-linear dendritic branches as elementary memory units. We highlight the potential implications of dendritic engrams for the learning and memory field and discuss future research directions.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-08-26/","title":"Behavioral time scale synaptic plasticity underlies CA1 place fields","text":"<p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Kenneth Hayworth August 26, 2025</p> <p>Paper: Behavioral time scale synaptic plasticity underlies CA1 place fields Katie C. Bittner, Aaron D. Milstein, Christine Grienberger, Sandro Romani, and Jeffrey C. Magee Science, Vol 357, Issue 6355, pp. 1033-1036 (2017). https://doi.org/10.1126/science.aan3846</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-08-26/#a-different-form-of-synaptic-plasticity","title":"A different form of synaptic plasticity","text":"<p>How do synaptic or other neuronal changes support learning? This subject has been dominated by Hebb's postulate of synaptic change. Although there is strong experimental support for Hebbian plasticity in a number of preparations, alternative ideas have also been developed over the years. Bittner et al. provide in vivo, in vitro, and modeling data to support the view that non-Hebbian plasticity may underlie the formation of hippocampal place fields (see the Perspective by Krupic). Instead of multiple pairings, a single strong Ca2+ plateau potential in neuronal dendrites paired with spatial inputs may be sufficient to produce place cells.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-08-26/#abstract","title":"Abstract","text":"<p>Learning is primarily mediated by activity-dependent modifications of synaptic strength within neuronal circuits. We discovered that place fields in hippocampal area CA1 are produced by a synaptic potentiation notably different from Hebbian plasticity. Place fields could be produced in vivo in a single trial by potentiation of input that arrived seconds before and after complex spiking. The potentiated synaptic input was not initially coincident with action potentials or depolarization. This rule, named behavioral time scale synaptic plasticity, abruptly modifies inputs that were neither causal nor close in time to postsynaptic activation. In slices, five pairings of subthreshold presynaptic activity and calcium (Ca2+) plateau potentials produced a large potentiation with an asymmetric seconds-long time course. This plasticity efficiently stores entire behavioral sequences within synaptic weights to produce predictive place cell activity.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-09-09/","title":"Memory engram synapse 3D molecular architecture by cryoET","text":"<p>     On September 9, 2025 - @ 3 pm PDT (6 pm EDT, 00:00 CET)     Click Here to join the session     carboncopies.org/aspirational-neuroscience   </p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Randal A. Koene September 9, 2025</p> <p>Paper: Memory engram synapse 3D molecular architecture visualized by cryoCLEM-guided cryoET Charlie Lovatt, Thomas J. O\u2019Sullivan, Clara Ortega-de San Luis, Tom\u00e1s J. Ryan, Ren\u00e9 A. W. Frank bioRxiv 2025.01.09.632151. https://doi.org/10.1101/2025.01.09.632151</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-09-09/#abstract","title":"Abstract","text":"<p>Memory is incorporated into the brain as physicochemical changes to engram cells. These are neuronal populations that form complex neuroanatomical circuits, are modified by experiences to store information, and allow for memory recall. At the molecular level, learning modifies synaptic communication to rewire engram circuits, a mechanism known as synaptic plasticity. However, despite its functional role on memory formation, the 3D molecular architecture of synapses within engram circuits is unknown. Here, we demonstrate the use of engram labelling technology and cryogenic correlated light and electron microscopy (cryoCLEM)-guided cryogenic electron tomography (cryoET) to visualize the in-tissue 3D molecular architecture of engram synapses of a contextual fear memory within the CA1 region of the mouse hippocampus. Engram cells exhibited structural diversity of macromolecular constituents and organelles in both pre- and postsynaptic compartments and within the synaptic cleft, including in clusters of membrane proteins, synaptic vesicle occupancy, and F-actin copy number. This \u2018engram to tomogram\u2019 approach, harnessing in vivo functional neuroscience and structural biology, provides a methodological framework for testing fundamental molecular plasticity mechanisms within engram circuits during memory encoding, storage and recall.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-09-23/","title":"Distinct synaptic plasticity rules across dendritic compartments","text":"<p>     On September 23, 2025 - @ 3 pm PDT (6 pm EDT, 00:00 CET)     Click Here to join the session     carboncopies.org/aspirational-neuroscience   </p> <p>The Memory Decoding Challenge: Decode a non-trivial memory from a static map of synaptic connectivity. A journal club by Aspirational Neuroscience &amp; the Carboncopies Foundation.  </p> <p>Presented by Dr. Kenneth Hayworth September 23, 2025</p> <p>Paper: Distinct synaptic plasticity rules operate across dendritic compartments in vivo during learning William J. Wright, Nathan G. Hedrick, and Takaki Komiyama Science, Vol 388, Issue 6744, pp. 322-328 (2025). https://doi.org/10.1126/science.ads4706</p>"},{"location":"Events/JournalClubs/MemoryDecoding/2025-09-23/#abstract","title":"Abstract","text":"<p>Synaptic plasticity underlies learning by modifying specific synaptic inputs to reshape neural activity and behavior. However, the rules governing which synapses will undergo different forms of plasticity in vivo during learning and whether these rules are uniform within individual neurons remain unclear. Using in vivo longitudinal imaging with single-synapse resolution in the mouse motor cortex during motor learning, we found that apical and basal dendrites of layer \u2154 (L\u2154) pyramidal neurons showed distinct activity-dependent synaptic plasticity rules. The strengthening of apical and of basal synapses is predicted by local coactivity with nearby synapses and activity coincident with postsynaptic action potentials, respectively. Blocking postsynaptic spiking diminished basal synaptic potentiation without affecting apical plasticity. Thus, individual neurons use multiple activity-dependent plasticity rules in a compartment-specific manner in vivo during learning.</p> <p>Register for updates about the Memory Decoding journal club and Aspirational Neuroscience Prize.</p>"},{"location":"Events/Workshops/Topic/AISafety/","title":"AI Safety","text":""},{"location":"Events/Workshops/Topic/AISafety/#carboncopies-workshop-whole-brain-emulation-and-ai-safety","title":"Carboncopies Workshop: Whole Brain Emulation and AI Safety","text":"<p>A written summary of the event by Dr. Keith Wiley is available at this link. The entire workshop is available on our Youtube channel. There you can find:</p> <ul> <li>The raw recording of the livestream (5+ hours) at this link.</li> <li>The playlist containing original (high resolution, clear audio) recorded interviews at this link.</li> <li>A transcript of the full workshop can be found at this link.</li> </ul> <p>The workshop included audience participation</p> <ul> <li>Audience members were able to ask questions in writing by typing them into the chat of the Youtube livestream. A staff member was monitoring the chat.</li> <li>Audience members were able to interact directly with our expert guests by calling in via web or phone. (URL and phone number removed as the event has concluded.) A staff member was moderating the call-in bridge. When a question was selected, the caller\u2019s microphone was activated to interact directly with our guests.</li> </ul> <p>Many thanks to all who RSVPed! </p> <p>On 2019-03-16, Carboncopies will host a Workshop on the topic of Whole Brain Emulation and AI Safety with the following main questions:</p> <p>BCI: If you create a high bandwidth communication pathway between the brain of a biological human and advanced AI, how does that affect AI Safety?</p> <p>Neuralink and others aim to create such BCI/BMI, and hope to improve the prospects for AI Safety.  What is a high bandwidth interface (e.g. compared with rate of speech, or imagery, or percentage of neurons)? What is the predicted effect of such a connection on the human, what is the predicted effect on the AI, and why?</p> <p>In the popular press, neural interfaces (BCI/BMI) are sometimes conflated with neural prosthesis. The human brain has approximately 83 billion neurons, and each neuron communicates at a typical maximum rate of about 100 spikes per second (a few can generate 1000 spikes per second). Human thought is based on processes such as pattern matching, emphasis (e.g. by up/down regulation), regularity (Hebbian learning). Machine thought is based on program execution, arithmetic, logic, or artificial (typically not spiking) neural networks.</p> <p>WBETAKEOFF: If whole brain emulation is accomplished, and implemented on a suitable processing platform, will a whole brain emulation be able to rapidly self-improve in a manner akin to a supposed AI take-off scenario?</p> <p>How would a human brain emulation be able to follow an engineered or predictable self-improvement curve? How would this compare with the notion of self-improving AI with a utility function or reinforcement learning?</p> <p>An argument that is occasionally made to urge caution in the development of whole brain emulation is that WBE might itself become a problematic runaway AI, but the supposed scenario is not clarified.</p> <p>AIACCEL: While carrying out research to accomplish whole brain emulation, what are the activities or types of insights that could risk accelerating advancements towards runaway self-improving AI?</p> <p>In what way are these activities or types of insight different from those that may be generated in mainstream and general neuroscience?</p> <p>Concern about acceleration of the risky AI improvement curve is sometimes mentioned as a possible reason for caution in the development of whole brain emulation, but the way in which that could happen is not clear. There are several specific features of AI development that are typically implicated in the possible runaway self-improvement scenarios, such as reinforcement learning, utility function following, (more?). Which of these might benefit from neuroscience or WBE research, and why?</p> <p>MERGE: What does a human-machine merger through whole brain emulation look like, and can it improve AI Safety?</p> <p>How may a substrate-independent human mind be linked or integrated with AI? What might this do to the human mind, and what might it do to the AI? How could that affect AI Safety, and why?</p> <p>A human-machine merger is sometimes proposed as a solution to avoid a competitive race between humanity and AI. The scenarios envisioned can benefit from clarification.</p> <pre><code>TIME    AGENDA ITEM\n11:00 AM    Welcome &amp; Brief Overview of Workshop\n11:05 AM    Randal Koene speaks\n11:30 AM    Jaan Tallinn interview\n12:15 PM    Tallinn Q&amp;A\n12:30 PM    Panel discussion\n1:00 PM     Panel Q&amp;A\n1:25 PM     Anders Sandberg interview\n2:30 PM     Anders Sandberg Q&amp;A + panel discussion\n3:00 PM     Ben Goertzel recorded talk\n3:30 PM     Q&amp;A + panel discussion\n</code></pre>"},{"location":"Events/Workshops/Topic/AISafety/Summary/","title":"Whole Brain Emulation &amp; AI Safety","text":""},{"location":"Events/Workshops/Topic/AISafety/Summary/#summary-of-the-march-2019-carboncopies-workshop-on-whole-brain-emulation","title":"Summary of the March 2019 Carboncopies workshop on whole brain emulation","text":"<p>Keith Wiley, 4/15/2019</p> <p>On March 16<sup>th</sup>, 2019, the Carboncopies Foundation hosted its first workshop of 2019, entitled Whole Brain Emulation &amp; AI Safety. The opening presentation was made by Randal Koene, founder and chairman of Carboncopies, followed by interviews between Dr. Koene and three leading researchers in the areas of whole brain emulation and AI safety. These researchers were Jaan Tallinn, cofounder of Skype and cofounder of the Center for the Study of Existential Risk and the Future of Life Institute, Anders Sandberg of the Future of Humanity Institute at Oxford University, and Ben Goertzel, chief scientist at Hanson Robotics, chairman of the OpenCog Foundation, and chairman of the AGI Conference series. In addition, there were two panel sessions during the conference, which consisted partly of discussion about the presentations and partly of questions from viewers. The panelists included Koene, Sandberg from the presentations, as well as Carboncopies board members Mallory Tackett, Abolfazl Alipour and Keith Wiley, author of A Taxonomy and Metaphysics of Mind-Uploading.</p> <p>Randal Koene gave the opening remarks, presenting what has become known as the \u201cFOOM\u201d scenario, in which AI suddenly surpasses a threshold of capability from which it rapidly accelerates beyond comprehension and control. In the context of Carboncopies, namely whole brain emulation (WBE), Koene introduced what was perhaps the primary question of the workshop, that of whether WBE represents an alleviation of AI safety concerns by enabling humanity to keep pace with advancing AI\u2019s cognitive and computational abilities, or alternatively whether WBE represents an exacerbating factor in the risk, such as might occur if a solitary bad actor, emulated and uploaded, were to become a hegemonic god, of sorts. Koene presented another way in which WBE might have detrimental effects: neurological and WBE research might reveal the crucial insights into the nature of intelligence that enable super-intelligent AI and a subsequent harmful fast takeoff scenario that might otherwise have never been achieved. Koene raised the question of how brain computer interfaces (BCI) might affect either the brain or the computer in question. What effects will such interfacing have on the respective systems? Are such effects even predictable?</p> <p>Koene then interviewed Jaan Tallinn, who has taken the matter of AI safety quite seriously through his founding and involvement with various AI safety organizations. Tallinn foresees a wider diversity of future scenarios than are generally acknowledged. Tallinn emphasizes increasing optionality, the number of choices available to us, which is almost always better and more desirable than less optionality. He emphasized that the more powerful decision makers in our society are notoriously focused on short term risks and goals, to our global detriment. He questioned the practicality of using WBE for the purpose of keeping up with AI, offering the analogy that little could have been done to assist horses in maintaining competitiveness with cars. Koene asked whether WBE might itself represent the takeoff scenario under concern, as opposed to AGI. Tallinn responded that there might be an uncanny valley of highly capable WBEs that aren\u2019t quite human. What if sacrificing part of a WBE\u2019s humanity actually bestows some other advantage? In this way, WBE advancement might trigger a takeoff in ways that AGI would not. Tallinn concluded with an appeal to more coordination and cooperation in research to make progress on these issues.</p> <p>Anders Sandberg expressed a concern that writings such as Nick Bostrom\u2019s on the subject of existential risk might slow down AI research. Of course, that is precisely what some people prescribe on these matters. Sandberg made the interesting observation that while it might be possible to demonstrate that developing AGI is more favorable than not doing so, it does not necessarily follow that we can demonstrate that developing safe AGI is easier than developing a dangerous variant. If possible, he emphasized that we should move the AI safety risk to earlier points in time. To state the contrary, he described how the worst scenario would be one in which AI works reasonably well right up until some turning point at which it suddenly becomes dangerous in a way that is no longer avoidable. Facing such dangers earlier, if possible, enables us to contend with them while the AI is in an earlier and more manageable state. Koene and Sandberg discussed the question of whether WBE represents an alleviation or an exacerbation of AI risk. Would the neuroscience of WBE research propel AI research more quickly? They concluded that WBE won\u2019t necessarily reveal such advances. Its findings and developments may not assist AI research very much. One can see how this conclusion might play out. While neuroscience may reveal the connectionist algorithms underlying intelligence, and in so doing accelerate AI research, WBE need not necessarily depend on furthering our understanding of neural algorithms, so much as on developing the low level processes of neuronal function and replication. At best, it is unclear whether WBE developments will play a significant role in AI research.</p> <p>The final presentation was by Ben Goertzel. Goertzel is more immediately concerned with narrow AI than AGI. Current AI applications focus on arguably the worst conceivable goals: selling, spying, and killing, as Goertzel put it. If AGI ultimately evolves from our contemporary narrow AI systems, it may be come out quite badly on the basis of its amoral (or immoral) antecedents. Goertzel asked how democratic as opposed to centralized and elitist our control of AI should be. Would we be safer with a small band of wise and tempered sages overseeing the world\u2019s various AIs, or should we prefer the collective wisdom of the masses? We currently operate more like the first approach but without having selected for the wisdom and sagacity just mentioned. Rather, the tiny cohort in charge of the world\u2019s AIs simply is the corporate and military leaders who happen to grab the reins. Consequently, Goertzel advocated for the more democratic approach in which collective human morality governs the direction of AI. Personally, I have my doubts about that approach. Winston Churchill\u2019s famous quote leaps to mind, concerning whether the average voter really has the necessary information to make guiding decisions. But an even more dire argument against the wisdom of crowds is the observation that human crowds easily devolve into mobs, from which arise not wisdom, fairness, and liberty, but nationalism, fascism, and discrimination. Would the world\u2019s demographic minorities really be pleased if the world\u2019s AI were subject to the majority decisions of a few (or one) dominant world demographics? (See Alexander Hamilton\u2019s warnings to Thomas Jefferson about the tyranny of the majority.) It is not obvious to me that the outcome here is anything short of disaster. Koene presented his primary question again, does WBE represent a worsening or salvaging lever with respect to AI risk? Goertzel feels that WBE is a terrible way to develop self-improving AI. Engineered AI should be a better approach to the end goal. Koene asked what we should be doing to maximize the likelihood of a favorable outcome, and Goertzel concluded his presentation with the excellent call for increasing resource spending on globally beneficial technologies, to focus on compassion in our AI designs, to move the bulk of our AI research spending away from marketing and weaponry and toward medicine, education, genomic research, agriculture, science, poetry, art, and philosophy.</p> <p>There were two panel sessions during the workshop as well. These fielded questions from the live online audience and involved discussion between board members of Carboncopies, Sandberg, and the audience members themselves. I encourage readers to seek out the videos and transcripts of the workshop to delve into this additional material. The new Carboncopies workshop series is now over a year old and has included several workshops, with many more to come. The day when whole brain emulation becomes possible draws nearer with each passing year, as do the serious issues of safety with regard to narrow AI, AGI, and WBE. Although the risks are real, so are the benefits. With continued involvement from researchers, communities, and the public, we will revel and prosper as we traverse the greatest transition in humanity\u2019s history.</p> <p>The Carboncopies Foundation\u2019s next workshop is currently scheduled for June 1, 2019, with the topic \u201cReview of the 2008 Oxford Roadmap on Whole Brain Emulation\u201d.</p> <p>The workshop\u2019s archived URL is https://carboncopies.org/Events/Workshops/Year-Month/2019-March and includes links to the videos. The same URLs are offered below in chronological order:</p> <ul> <li>Full Livestream Recording of the Carboncopies Spring 2019 Workshop: Whole Brain Emulation and AI Safety \u2014 https://youtu.be/n_tRfWDyIVg</li> <li>Jaan Tallinn interview by Randal Koene \u2014 https://youtu.be/m31dUFiCCFo</li> <li>Carboncopies March 2019 Workshop Panel Discussion I \u2014 https://youtu.be/1Bx_q18Jt2c</li> <li>Anders Sandberg interview by Randal Koene \u2014 https://youtu.be/H9tk4lpuL2E</li> <li>Carboncopies March 2019 Workshop Panel Discussion II \u2014 https://youtu.be/yDISmkFwNUw</li> <li>Ben Goertzel interview by Randal Koene (part 1) \u2014 https://youtu.be/Xwhq-47Qu5k</li> <li>Ben Goertzel interview by Randal Koene (part 2) \u2014 https://youtu.be/-VpEtxy3AeU</li> <li>Carboncopies March 2019 Workshop Panel Discussion III \u2014 https://youtu.be/XyDIqycBxIY</li> </ul>"},{"location":"Events/Workshops/Topic/AISafety/Transcript/","title":"Winter Workshop 2019: Whole Brain Emulation &amp; AI Safety","text":""},{"location":"Events/Workshops/Topic/AISafety/Transcript/#livestream-transcript","title":"Livestream Transcript","text":"<p>Randal Koene:</p> <p>Can you hear me?</p> <p>Allen Sulzen:</p> <p>I can hear you Randal.</p> <p>Randal Koene:</p> <p>I think I've got my volume down really low.</p> <p>Allen Sulzen:</p> <p>Randal, I can hear you just fine.</p> <p>Randal Koene:</p> <p>Oh wait, I see what's wrong here. Okay. I can hear you too. It's quiet because I've got the wrong headphones plugged in.</p> <p>Allen Sulzen:</p> <p>No problem. We have about 84 subscribers on YouTube and we are live in the way that any of them would know, and could. So, we're just pre-announcement live.</p> <p>Randal Koene:</p> <p>Have you... So, the YouTube links...</p> <p>Allen Sulzen:</p> <p>I haven't updated the links yet.</p> <p>Randal Koene:</p> <p>It should be on the live-stream active page, right? Or, the active live-stream. That's where you put it, and then all you have to do is switch the redirect when you're ready to go?</p> <p>Allen Sulzen:</p> <p>Yup. Getting that going now.</p> <p>Allen Sulzen:</p> <p>I'll put the music back on for a little bit.</p> <p>Randal Koene:</p> <p>Oh yeah, did you still want to put a link on the front page as well, or is that already there?</p> <p>Allen Sulzen:</p> <p>It says call.carboncopies.org. Do you see it?</p> <p>Randal Koene:</p> <p>Right on the front page of Carboncopies?</p> <p>Allen Sulzen:</p> <p>Oh, sorry, Yeah. I'll put it on the homepage. I thought you meant on the first slide.</p> <p>Randal Koene:</p> <p>No, no. Yeah.</p> <p>Allen Sulzen:</p> <p>Oh, I'll put that on there as well.</p> <p>Randal Koene:</p> <p>Awesome. Okay.</p> <p>Allen Sulzen:</p> <p>Grabbing 'er now.</p> <p>Randal Koene:</p> <p>And how's the Uberconference thing starting up. Is that there?</p> <p>Allen Sulzen:</p> <p>It's working really well and it started great.</p> <p>Randal Koene:</p> <p>Perfect.</p> <p>Randal Koene:</p> <p>Hi Mallory.</p> <p>Randal Koene:</p> <p>Mallory, if you can hear me, can you say something? So, I know your stuff works.</p> <p>Randal Koene:</p> <p>Not hearing you yet. Still not hearing you.</p> <p>Allen Sulzen:</p> <p>Mallory, we can hear Randal, but not you.</p> <p>Randal Koene:</p> <p>Nothing yet.</p> <p>Randal Koene:</p> <p>If you haven't done it already, you can click the settings thing in hangouts and tell it specifically which audio to use; which microphone to use.</p> <p>Allen Sulzen:</p> <p>True.</p> <p>Randal Koene:</p> <p>Not hearing you yet.</p> <p>Allen Sulzen:</p> <p>We did just test this.</p> <p>Randal Koene:</p> <p>Yeah. That's why it's good to get this started, like 20 minutes before.</p> <p>Allen Sulzen:</p> <p>I see Sarah is online.</p> <p>Randal Koene:</p> <p>Mhm, that's great.</p> <p>Randal Koene:</p> <p>Yeah, we're still not hearing you Mallory. If need be, when the time comes, I can start it up and then hand it over to you as soon as you figure out your microphone.</p> <p>Randal Koene:</p> <p>Allen?</p> <p>Allen Sulzen:</p> <p>Yes?</p> <p>Randal Koene:</p> <p>When it's 11, either you or I should say something that we're still figuring out a last minute technical glitch or something like that, rather than, waiting around.</p> <p>Allen Sulzen:</p> <p>That sounds fine.</p> <p>Allen Sulzen:</p> <p>I can do that. I'm just setting the redirects right now to go to the right spot.</p> <p>Randal Koene:</p> <p>I'm going to use this moment to test what it looks like if I'm sharing my slides, because I haven't really tested that yet.</p> <p>Allen Sulzen:</p> <p>Mallory, nothing... not coming through. You might try turning the computer off and on again? I don't know... Just making ideas here.</p> <p>Randal Koene:</p> <p>Can you stop sharing slides for a second, Allen, so I can share mine for just a moment?</p> <p>Allen Sulzen:</p> <p>Yes, actually, you just have share your screen.</p> <p>Randal Koene:</p> <p>So, I wanted to pick a specific window rather than... Okay, this window, share, and now what does it look like? Okay, it looks like that. What if I do...</p> <p>Allen Sulzen:</p> <p>You'd want to do full screen.</p> <p>Randal Koene:</p> <p>Yeah... I'm going to try to see what happens if I say present. Okay, there you go.</p> <p>Allen Sulzen:</p> <p>I'm seeing it looking like an Android-size window.</p> <p>Randal Koene:</p> <p>Oh you are? Okay. I might have to change the size of the window. Here we go.</p> <p>Randal Koene:</p> <p>Let's see what happens now. Is it still looking like an Android-size window?</p> <p>Allen Sulzen:</p> <p>Nope. Now it looks full screen. I think you can present, and then in the bottom of present, you click... It should hover over a little thing and you can click the button that makes it a browser-size window. Oh, it looks like it's not really showing up for you.</p> <p>Randal Koene:</p> <p>This thing here?</p> <p>Allen Sulzen:</p> <p>Mallory, I saw you just jump back on, and we can't hear you, still.</p> <p>Randal Koene:</p> <p>Sorry, Allen does this look about right? Or is this still...</p> <p>Allen Sulzen:</p> <p>That looks the right size now, but I do see the top of your browser.</p> <p>Randal Koene:</p> <p>So, you see the top of the browser. Oh, okay. Let's see.</p> <p>Allen Sulzen:</p> <p>Oh also, hold your... well no, that looks alright.</p> <p>Randal Koene:</p> <p>How does one do that? How about if it's like this? Does that work? Or is it the wrong size again?</p> <p>Allen Sulzen:</p> <p>That's the android size.</p> <p>Randal Koene:</p> <p>Ah, rats... Okay, so then maybe the best for me, given the weird way my window's working, I'll just keep it...</p> <p>Allen Sulzen:</p> <p>It looks like we have about six live viewers. So, I just wanted to, real quick... Hi, my name's Allen. We're, still testing out a few things. So, anyone who's viewing this, we're about to get ready with our Spring Workshop for the Carboncopies Foundation, and this has all been made possible by volunteers. So, we're all really grateful to anyone who's contributed to making this workshop possible. This workshop is going to feature a few different speakers, including Ben Goertzel, Anders Sandberg, and Jaan Tallinn. So, we're going to get started here in just a few moments. There may be just some background music for a while, and we're just trying to get one more of our speakers on if we can.</p> <p>Randal Koene:</p> <p>Ok, you can put your slides back up.</p> <p>Mallory Tackett:</p> <p>Can you guys hear me now?</p> <p>Randal Koene:</p> <p>Yeah, there you are.</p> <p>Mallory Tackett:</p> <p>Okay, great! Restarting the computer actually worked.</p> <p>Randal Koene:</p> <p>And Allen... Yeah, okay. There we go. Perfect. So it looks like we're about ready to go.</p> <p>Mallory Tackett:</p> <p>Yeah, how many viewers do we have and when should we start?</p> <p>Allen Sulzen:</p> <p>10, and whenever you want.</p> <p>Mallory Tackett:</p> <p>All right, I guess we'll go ahead and start. Like Allen said, welcome to the Carboncopies Foundation 2019 Spring Workshop. I'm Mallory Tackett, the president of Carboncopies, and I'll be moderating this event today. Our topic is whole brain emulation and AI safety. The agenda for today... We'll be starting with our chairman, Randall Koene, who will deliver a few remarks about the topic. At 11:30 AM (Pacific Time) we will show an interview with Skype co-founder and AI safety supporter Jaan Tallinn that was prepared for this event. Following that interview, I will introduce our panel and start the discussion of any issues that were raised. This is the first opportunity for any audience members to ask questions. At 1:30 PM (Pacific Time), we will have the interview, or we will show the interview, with existential risk expert and computational neuroscientist Dr. Anders Sandberg. Dr. Sandberg will then join us from Oxford to answer audience questions. Then, at 3:00 PM (Pacific time), leading AI and AGI researcher Doctor Ben Goertzel will present his remarks. This will be followed by our concluding panel discussion. There are two ways for audience members to participate. You can write questions directly in the live stream chat. This live stream chat is monitored by a volunteer who will alert me to any questions that I can then ask the panel. You can also call in and join the discussion at call.carboncopies.org or call the phone number (415) 455-3017. This is also moderated...</p> <p>Randal Koene:</p> <p>Mallory, hang on for a second. Jesse is just telling us that while he can hear you on Hangouts, he can not hear you on the live stream.</p> <p>Mallory Tackett:</p> <p>Oh.</p> <p>Randal Koene:</p> <p>I don't think that's necessarily your problem, because you're coming through on the Hangouts. So, Allen should be making sure that you're audible on the live stream.</p> <p>Mallory Tackett:</p> <p>I believe I'm on.</p> <p>Allen Sulzen:</p> <p>I also believe she's audible on the live stream.</p> <p>Mallory Tackett:</p> <p>Yeah, in Google Hangouts, I believe I'm audible. So...</p> <p>Allen Sulzen:</p> <p>Can anyone just verify that they hear...</p> <p>Mallory Tackett:</p> <p>Anyone in the live stream that wants to verify that they can hear me?</p> <p>Allen Sulzen:</p> <p>We have 13 viewers testing if the Carboncopies are seeing this. We have a guy named Luke... Help us out here.</p> <p>Allen Sulzen:</p> <p>Hi Luke. This is Allen from...</p> <p>Allen Sulzen:</p> <p>Luke, from the live stream, has confirmed, and so has Claire. Multiple people are confirming that they can all hear us. So, it's just...</p> <p>Mallory Tackett:</p> <p>Ok great.</p> <p>Randal Koene:</p> <p>Jesse, I don't know what's up with your situation there, but others can hear it. Okay. Sorry, Mallory, for that interruption. It looks like we actually are live, then. Perfect.</p> <p>Mallory Tackett:</p> <p>All right. I'll just repeat how audience members can join in, since we might've had some new people that joined. You can ask your questions just in the live stream chat directly, or you can call in at call.carboncopies.org or call the phone number: (415)-455-3017. This is also moderated by a volunteer, and it's going to be very similar to calling into a radio. When your question is chosen, you will be able to ask it to the panel directly and speak with the respondent. This second option is still new, so please be patient with any technical difficulties that we have. When the workshop is done, we would appreciate audience members to complete our survey at survey.carboncopies.org. Our thanks to our donors, our volunteers, and all the experts that participated in this workshop. With that, it's time for introductory remarks by Dr. Randal Koene. You may know Dr. Koene as our chairman and founder of Carboncopies. He's also a neuroscientist with a background in physics and artificial intelligence. He has spent the last 20 years working in neural engineering labs and companies. While doing that, he has also been studying and bringing awareness to the technical challenges for whole brain emulation and mind uploading. If you'd like to know more about his background, his writing, talks, or anything else, you can find that information at RandalKoene.com. Welcome, Dr. Koene.</p> <p>Randal Koene:</p> <p>Hi, and thanks for the introduction. I'm going to take one second here just to pop up a few slides. I'm making sure that works out correctly. So, I'm going to pick that window and hopefully I'll do it right. We're sharing the window. I'm going to make it present. Does this look correct, does this look like Android to anyone? Does it look...</p> <p>Allen Sulzen:</p> <p>Android.</p> <p>Randal Koene:</p> <p>Android, thank you. Okay, so I'll do it the other way around then. I just need to...</p> <p>Allen Sulzen:</p> <p>That looks better.</p> <p>Randal Koene:</p> <p>Yeah, Okay. Well, it's better, I don't know if I can get it to be much better than that. I suppose this is slightly better. The problem is that my monitor is actually flipped the other way around and it doesn't seem that Hangouts can deal with that. All right. However that may be, let's get into it. So, thanks everyone for joining, and thank you for that introduction, Mallory. As you probably all know... Let me just get back to the first slide here too, so that's all making sense. At the Carboncopies Foundation, we primarily focus on the technical challenges to whole brain emulation. Occasionally, we also explain why we think that mind uploading through whole brain emulation is an important part of the long-term future for humanity; and we could get into that, but I'm going to try not to do that until maybe in the panel somewhere. We haven't previously dedicated events to artificial intelligence, even though artificial brains are of course a special category of AI. There are already so many who dedicate their time and present the issues around AI. Some people, for instance, let's say companies like Deep Mind, or Open AI, laboratories like MIT's artificial intelligence laboratory and specialized organizations that have been around for quite a while, such as The Machine Intelligence Research Institute, MIRI, Open Cog, which is headed by Ben Gertz Hill and The Future of Life Institute and many, many others. Of course, everyone at Carboncopies is also very interested in artificial intelligence and an artificial general intelligence. And just to be a bit specific, by artificial general intelligence, we usually mean a kind of artificial intelligence that isn't focused on a narrow problem, but that's focused on being able to handle any kind of problem; coming up with solutions for any variety of problems, sort of like people do.</p> <p>Randal Koene:</p> <p>Now, personally, of course, I've traveled in circles where AI and AI risk or primary interests for quite awhile. As I just mentioned, MIRI is out there in Berkeley and in the whole bay area, there are a lot of people who care about this problem. So, many of my friends are, are dedicating their time to it. And then, it's clear that, of course, there are areas where these domains, whole brain emulation and AI, have to interact. If they're both part of our future, they interact in some way. And it's important to consider what the outcomes are going to be. So, when we talk about safety concerns in AI, typically what we're talking about is, what happens if artificial intelligence gets to a point where the programs can write themselves, where every artificial intelligence algorithm can come up with the next better algorithm; or can somehow improve itself along a utility function. And then, there's the idea that if this happens fast enough, it could happen so quickly that we don't know what's going on and we can't control that in any sense, this sort of \"foom,\" this big explosion of artificial intelligence, the singularity. Now, whole brain emulation is an artificial brain, in a sense. So, in what sense is that a type of AGI we might ask? It's certainly a kind of intelligence and if it's in an artificial brain, you might say it's an artificial intelligence. Even if the sort of mind that it's creating isn't that artificial, it's something based directly on human brains. How general is it? Well, humanity, of course, was evolved to fit into the niche, the evolutionary niche, that happens to be present right now and 2 million years ago; but still, were pretty general in the sense that we keep tackling new problems using this same brain that we've got and than the tools that we build.</p> <p>Randal Koene:</p> <p>So, we're a part of this big ecosystem of intelligence, as we might say. And you could even just look at that whole ecosystem and wonder, where's that going to go? How do all the pieces interact? What can we expect? And when the ecosystem moves in a certain direction, what happens to those intelligence? The ones that are the human intelligence, as originally, what happens to them? Where do we fit in? So, we have to wonder, as all these bits and pieces are interacting, does that increase or decrease what we're calling the risk, possible risk, from AI?</p> <p>Randal Koene:</p> <p>Now, those interactions and outcomes haven't received a lot of attention so far. There are just a few examples of academic writing on it, and what we're going to try to do is we're going to try to focus on it a bit more now. In fact, that's what we do with all of our workshops. We keep on trying to highlight different aspects, different pieces of a puzzle that is... Oh, it says that my slides are not full screen. Sorry. Yeah, I know they're not completely full screen. When I do that, then we get the Android version, because my screen is flipped vertically. So, I'm afraid this is probably the best that we can do right now. Maybe, in future I'll run it on a separate laptop, or something, when I do this.</p> <p>Randal Koene:</p> <p>Anyway, what we're trying to do, is we're trying to highlight different parts of this puzzle, and there are a lot of parts when we talk about whole brain emulation and the whole ecosystem it's in. If you look at what we've done so far in our workshops, right? Since one piece that we filled in is when we did the Transcending Biology: Reverse Engineering the Brain Workshop, we were really looking at the roadmap to whole brain emulation and an update on the status of all the technical bits, what was possible now, and what may be possible soon, and which technologies are going there. Then, we did a workshop called From Brain Preservation to Reconstruction, and in that workshop we were looking, specifically, at where are things going in terms of being able to preserve a brain, then be able to slice our section it in some way, image it, and from there, get to something that is a functional model and what sort of problems are you going to run into?</p> <p>Randal Koene:</p> <p>We were trying to highlight those problems in a bit more detail. Then we've done a workshop on the metaphysics and ethics of whole brain emulation which was very different from what we typically do, because we've been focusing on the technology so much. And now we're trying to address AI safety and whole brain emulation, and I think there are going to be a lot more pieces of this puzzle as we go along. Now, the topic that, that we're looking at today, I hope it's, also, going to become an official part of our road mapping effort and we're going to advocate that it's going to be included in what I'm calling, for now, the version 2.0 workshop, or conference about whole brain emulation, at Oxford University, which I hope is going to happen this year. There's no definitive plan yet, but a lot of indicators are that this may happen this year. Speaking of that, when that workshop does happen, to update, let's say, the white paper that came out in 2007, I hope that we bring in a whole set of new people and different angles, because a lot of the things that we would talk about now, they just weren't around back then. For example, now we have Anthony Zaidor who appeared at our transcending by biology workshop, who developed the molecular bar coding approach to mapping a connectome, the Boyden team, including Adam Marblestone. By the way, Adam Marblestone is now at Deep Mind,, developed expansion microscopy and wrote a set of seminal papers about fundamental neuro-technology. None of those were present at the first workshop. We've had professor Scheffer come in who tried to explain how his team has started to attempt to reconstruct functional, drosophila circuits from structure scans as presented in our From Brain Preservation workshop.</p> <p>Randal Koene:</p> <p>And then of course, the Burger and Song labs that have been working full tilt on cognitive neural prosthesis, which is really the closest example we have of partial brain emulation. Those were not on the radar back in 2007 and that's really just the tip of the iceberg. The white paper that came out of the first workshop focused on how much compute power a whole brain emulation would need and how a preserve brain could be sliced and scanned the big problems of wholesale functional data acquisition and of how to convert brain data and to working brain models, those were hardly addressed, nor were subdomain topics like AI safety, models of consciousness, or societal and ethical issues.</p> <p>Randal Koene:</p> <p>Okay. So, at this point, much of what's been said about AI Safety and whole brain emulation sounds more like hand waving speculation, then careful study. There's been a mention in Bostrom's book Super Intelligence. Some introductory studies that Carl Schulman has done, not too much of that has been published yet. Informal communications that we've had with people from the FHI, the FLI, or MIRI. And there was one paper that came out in 2017 that was interesting by Daniel Eth on AGI and neural probes, which connects fairly closely to AGI and whole brain emulation. And then, of course, a few Sci-fi situations like the version that was depicted in transcendence where, you could say, they included both whole brain emulation and the danger of runaway AI in one movie. Perhaps that was a bit much to squeeze in there, but it was an attempt to do that, right?</p> <p>Randal Koene:</p> <p>Now, the people we've invited to this workshop have expertise that comes from several directions. Jann Talliin has a background in AI safety and existential risk, he's been busy in that for quite awhile. Dr Ben Goertzel has of course been working for years on the development of AGI and he's had a hand in many other sort of tangential parts of that as well. Dr. Anders Sandberg has done a lot of work in existential risk and he was also, of course, involved with whole brain emulation, specifically with that first workshop in Oxford where we tried to pull together some of the people at the time who had a lot of interest in the topic. And then, of course, those of us who are on the panel from the Carboncopies Foundation, we've all been involved in some sense, or another, in whole brain emulation development, even if it's mostly from the technical side.</p> <p>Randal Koene:</p> <p>Now, some people that we wish were here aren't here this time, like Carl Schulman, Nick Bostrom, people from open AI or deep mind, and more. But, the first workshop can only be so big, and there's going to be plenty to digest in this first iteration of the topic. So, see now, when we talk about... Oh, I want to get to the next slide here. When we talk about the kinds of interactions that can happen between artificial intelligence or artificial intelligence safety and whole brain emulation, one of the problems is that you get into interactions between different domains and different technological developments, and those are always really complicated and hard to predict. If you look at examples of attempting to predict these things, then often people have to choose something very constrained. Take, for instance, our friend Robin Hanson's book, The age of M, where he tries to predict from an economic perspective as an economist, what would happen if you had a wholesale whole brain emulation available and basically infinite compute power.</p> <p>Randal Koene:</p> <p>But, he leaves out some things. For instance, he does not include artificial intelligence, that is not whole brain emulation, directly in that. So, a lot of the things that in his economic model are done by copying brains. They could be done by using a different type of AI, something more narrow, perhaps. So, then that changes a lot about this society he's depicting. And you can imagine that the society that he's depicting there could easily transform itself quite quickly into something very different, perhaps, to something that does include a lot of AI. So, the problem here is that as you explore angles, different angles of the question and questions, you keep discovering that you have to clarify those questions more and dig deeper and uncover more of them. And you're going to notice this in the interviews that I did with Jaan Tallinn and Anders Sandberg.</p> <p>Randal Koene:</p> <p>Every insight uncovers many more deep questions, but you've got to start somewhere. So, I've decided to seed the conversation by asking everyone a series of questions that are based on statements, assumptions, or intuitions that I've run into. I'm going to try to take you through these very briefly before we move on to the next section of this workshop. Just so that we're all on the same page, in taking you through this, I just want to mention that, typically, when I talk to people who are coming from an AI safety background about whole brain emulation, and whether they think that this is something that should receive extra funding, or should be pushed hard that there should be work done on it, I get two different kinds of responses. Some people will see work on whole brain emulation as being something that decreases the risk of runaway AI, and there are a few of these examples that I'll mention in just a moment. And others, they seem to come at it with an intuition that whole brain emulation research is more likely to increase the danger of runaway AI. And again, there are some examples of the sort of thinking that goes into that, but as I mentioned already, most of that seems fairly hand wavy, at this moment, and it really does deserve more precise attention.</p> <p>Randal Koene:</p> <p>So, let me just get started on the first one here. Oh, I think I may have skipped one. The first one is, well, BCI for AI safety, brain computer interfaces. In recent years there've been a few, especially some very well known entrepreneurs who've started companies like Neuralink, who've claimed that work on brain computer interfaces on high bandwidth interfaces between the brain and a machine are a route to improve AI Safety by causing something like a symbiosis between humanity and AI. But, you have to dig in a bit deeper to try to understand whether that's really true or in what way that would happen, and that will be discussed more later on; but here I'm just going to mention a few of the big questions there. So, for instance, what is a high-bandwidth interface? What does it mean when we say high bandwidth BCI</p> <p>Randal Koene:</p> <p>What are we comparing that with? Are we comparing it with the rate that we can type or speak, imagery? Does it mean that you target a certain percentage of all of the neurons at the same time and stimulate them? What does it really mean? And if you can make a connection like that between a biological brain and a machine, what's the predicted effect of a connection like that? And what's the effect on the human? How does the human experience change? How much does the human become a part of that AI ecosystem? And what's the effect on the AI? How does connecting with this human brain implement something you might call a level of control or a level of supervision, in some sense, or anything like that? When people talk about neural interfaces, sometimes in the popular press, they're conflated with neuro-prosthesis, but they're not. They're not a neuro-prosthesis.</p> <p>Randal Koene:</p> <p>There, just the connection between a brain and a machine. Now, the human brain has about 83 billion neurons and each of those neurons communicates at a typical maximum rate of about a hundred spikes per second. Some of them can go up to a thousand spikes per second, but not much more than that, which is a much bigger interval than, say, the nanoseconds and microseconds that computers work at. Also, human thought is based on processes like pattern matching or giving an emphasis to certain patterns by up or down regulating the neurons in that area or on regularity, which is heavy in learning, things that fire together, wire together. And machine thought is typically based on the execution of programs, on arithmetic, on logic, and on sometimes artificial neural networks.</p> <p>Randal Koene:</p> <p>I just want to mention that I'm not currently looking at my email. I see that there are some emails coming in. If anyone's trying to actually reach me, I can't see it; a message on my phone, if there's something wrong with me coming through or whatever, please ping me there. So, if you create a high bandwidth communication pathway between the brain of a biological human and an advanced AI, how does that affect AI Safety? That's a very legitimate question that's not that easy to answer. Now, the other argument that is often made, is to urge caution in the development of whole brain emulation, because, perhaps, whole branding emulation, itself, could be a risk to humanity. Maybe because, itself, could become a runaway AI. But the scenario there isn't often clarified very well. How, for instance, would a human brain be able to follow an engineered or predictable self improvement curve? How would this compare with the notion of self improving AI that follows a utility function and uses reinforcement learning as its primary method of improvement? If a whole brain emulation is accomplished and implemented on a suitable processing platform, will a whole brain emulation be able to rapidly self improve in a manner that's akin to this supposed AI take off scenario? Is there a way for whole brain emulation to do that rapidly? Is there something like a whole brain emulation \"foom?\" That too, deserves more detailed thought then whatever our intuitions may be saying.</p> <p>Randal Koene:</p> <p>Now, toggling back to looking at this as a potential risk in a different way, concern about the acceleration of risky AI improvement, or the curve that AI improvement may take; that's another possible reason for being cautious about the development of whole brain emulation. But again, the way that it could happen isn't entirely clear. The way this is presented is usually that the development of whole brain emulation may lead to insights that will then make the development of AI happen faster; just like the basic insight of how neurons work that led to neural networks and deep learning, and this is still something that's used in AI. But you know, how much of that is really happening today? How much insight are we getting? And also, how does this really differ from the insights that are gained from general neuroscience research that's happening today? Is there something specific about doing research on whole brain emulation that would accelerate AI development in a way that general neuroscience research doesn't. We need to at least have some examples of that.</p> <p>Randal Koene:</p> <p>Now finally, the last question that I wanted to present at this point is, well, sometimes people will say the best way to achieve AI safety is if we ourselves can develop at the same rate as AI if we're completely merged with it, If there's no distinction between human and machine, if we somehow bring those two together, thereby getting rid of a competitive race between humanity and artificial intelligence.</p> <p>Randal Koene:</p> <p>Now again, that needs to be clarified a bit more, because we don't really know what it means to say we're linking an uploaded mind with an AI. As we just mentioned, they work in slightly different ways. What does it mean to link the kind of pattern matching that we do with the sort of algorithms that are happening in an AI? How does that change the way that the human brain thinks? How does that change the way that the AI thinks? How do they control each other? How does this whole ecosystem move forward? And then there's the question, well, even if you do this, if you merge the two and they're moving forward together, this merged ecosystem of intelligence, does that really solve the original problem of AI Safety, or is it just taking away that one problem of the competition between humanity and AI or that one aspect, because the self improving AI, which could be say something that is reinforcement learning and following a utility function, that might still be a problem in itself. Even if you've got these other merged AI and human brain uploads there, you could still have a separate class of AI agents that are a problem. So, it could be that those two things are tangential or maybe even orthogonal, in a sense. So again, that's something that deserves more time. Now, obviously we can't answer all those questions here, but we can make a start at being more precise and it's stating those questions clearly, and that's what I hope I've managed to do here. Now, I'm going to stop sharing my slides. I'm going to hand it back to Mallory here. Thank you, very much.</p> <p>Mallory Tackett:</p> <p>All right, thank you Randal. There's going to be plenty of time for followup questions during our panel discussion, but again, you can put those followup questions on the live stream or call in at the numbers. Now, we're going to be going to the interview with Jaan Tallinn. He is the co founder of Skype and he's been a longtime AI safety supporter. So, we'll go ahead and show that.</p> <p>Allen Sulzen:</p> <p>Hey Mallory, it looks like, last minute, mine was working in our tests, but it's not. Would you be able to stream it?</p> <p>Mallory Tackett:</p> <p>It looks like we're having some technical difficulties. I am going to go ahead and just play the interview on my computer and I will stream it for you guys.</p> <p>Allen Sulzen:</p> <p>Thanks, Mallory.</p> <p>Mallory Tackett:</p> <p>Just need to change my speaker output.</p> <p>Mallory Tackett:</p> <p>There we go. We're sharing.</p> <p>Randal Koene:</p> <p>I'll just introduce you first, and introduce the topic. We can always crop out anything in the beginning that doesn't belong.</p> <p>Randal Koene:</p> <p>Our esteemed guest for this event is Jaan Tallinn, an accomplished and well known entrepreneur, investor, and theoretical physicist from Estonia who co-founded the peer to peer video-calling service Skype among other ventures. He's since been a leading voice on the frontiers of AI safety and effective altruism and has co-founded The Center for the Study of Existential Risk and The Future of Life Institute. Welcome Jaan. Thanks for agreeing to give us your time today despite your very busy travel schedule. As you may know, at the Carboncopies Foundation, we usually focus on the technical challenges for whole brain emulation. Occasionally we explain why we think mind uploading through whole brain emulation is an important step for the adaptability of an intelligent species, but everyone at the Carboncopies Foundation is also very interested artificial intelligence and artificial general intelligence. Since, however, there are already so many labs and companies like Deep Mind, groups like the Machine Intelligence Research Institute and others dedicated to AI, we often don't address it in our workshops. We decided that the interaction between those two domains should be addressed explicitly. The possible interactions are sometimes alluded to, from what I've heard and read so far, there's a lot more vague hand waving, I would say, than careful study. So, we wanted to try to move that along a little bit, starting with this workshop on whole brain emulation and AI safety. So, if you don't mind, I'd love to ask you a few questions about your thoughts on AI, and from there, maybe we can gently tip-toe into questions of where AI and whole brain emulation meet. Is that okay?</p> <p>Jaan Tallin:</p> <p>Sounds alright.</p> <p>Randal Koene:</p> <p>So, you've got a long history of being concerned about, or supporting serious study of, existential risk and, in particular, AI risk and AI safety. Would you mind telling us a little bit about how your thoughts on that topic have evolved over time and where you stand on that today?</p> <p>Jaan Tallin:</p> <p>Yeah, I think my thoughts have gotten more and more uncertain, in some sense, as I\u2019ve been exposed to more and more considerations, and more research has actually come out on achievements and progress that AI has made.</p> <p>Randal Koene:</p> <p>When you say that you're more uncertain, do you mean you\u2019re more concerned, or just that your not entirely sure of what the problem is?</p> <p>Jaan Tallin:</p> <p>Yeah, I see a wider spectrum of possible scenarios now. Before I got involved, before I read [ ... ] and stuff, I just didn't think that was an issue at all. I was a programmer and I wasn't afraid of programs. But then, [ ... ] pointed out that, like, wait a minute, if you can create a program, that is able to create programs, that's able to create programs, and that happens to be smarter with each step, we might have a serious problem. Then I got focused on this scenario, and I do still think that we have no guarantee against that certain program: that runaway AI. However, recently, I think the Open Field project introduced a concept of transformative AI: instead of talking about recursive improving AI, or narrow and general AI, which in some sense is actually specific: we should, actually, just focus on the aspect of AI that is important for us. It can be very transformative. Even if it's narrow, or if it's recursive certain programs, its for some reason does not exceed some threshold than what we improve, but still, it's going to be transformative. So, that is, in that sense, my... I see a wider spectrum of transformative situations on transformative scenarios for AI which is, in that sense I'm more uncertain.</p> <p>Randal Koene:</p> <p>Yeah yeah. So, we could go in all kinds of directions with this, and I don't want to spend too much time on it, just because we have these other topics that are really the focus of the workshop that's going to happen. I am kind of curious, because you mention, getting real advantages for the species, for all of us, out of narrow AI out of certain directions. Narrow AI, itself, also could pose concerns, right? I mean, we've seen some issues with Narrow AI even in recent times, like the way that the stock market crash could happen, or other things like that. Right?</p> <p>Jaan Tallin:</p> <p>The Facebook scandals, they have to do something with AI? I'm not sure how much though, but still.</p> <p>Randal Koene:</p> <p>Yeah, indeed. Okay, yeah, but it's not as concerning as, say, the issue of AI agents, to you, probably?</p> <p>Jaan Tallin:</p> <p>Not that current of things, but perhaps in a few generations from now, we might have some thing that is just super-manipulative, or super-addictive. Why not go that direction, because of a certain program? Say, like that kind of a scenario are still a part of my palate.</p> <p>Randal Koene:</p> <p>Okay. Well, if you don't mind, I'd love to know what your idea is, of say, a worst-case scenario vs. a best-case scenario of how we move forward with AI.</p> <p>Jaan Tallin:</p> <p>Yeah, I get that question quite a bit. I usually don't have a very specific answer, because I think that whenever I start thinking about very specific scenarios, you're almost guaranteed to shoot yourself in the foot, because each detail, basically, will make the scenario less likely. So, I think it's more valuable to think about narrow properties of traits that really positive scenarios and really negative scenarios have in common. So, for example, I think almost all existential risk scenarios coming from AI, synthetic bio, from new quality, that nuclear is going to unlikely going to be existential catastrophe. One trait that I think they have in common, is that they are going to look like catastrophes to humans. So, it's an interesting point that the first piece of existential resource of humanity is by the Manhattan Project scientists. Where, what is the probability of igniting the atmosphere once they do the first nuclear detonation? For the rest of the plant, it would have looked like one big catastrophe with no air to breathe. So, I think that's one likely common trait in, not all, but in many existential scenarios. Like there is a hoop of scenarios one of the traits that I can think of that they have in common is that there's an increase rather than decrease in optionality so like one thing that technological progress has given us is increasing optionality. Like I do have an option to easily visit other countries. These types that hundred years ago very few people have. At least not that in that quantity. Whereas in future, if things go well we might have options to travel to other places or options to upload ourselves or not upload ourselves that's also an important position to keep. That's another common trait I think that is positive and that's another common trait that unifies a set of futures, and specifically a set of positive futures.</p> <p>Randal Koene:</p> <p>I can totally the point that you're making. I also see optionality as being one of the most important things for us. It's sort of a something that for some reason as human beings we care about that sort of thing.</p> <p>Jaan Tallin:</p> <p>I think that's more general than human I think that's agents in general that have references over the world states like all other things being equal they would prefer more options and less options because of the uncertainty that they have. I think it's a meta mind, if you have the references but you don't know what the correct actions are to take right now, then it would be valuable to have all more options because in the future you will have more information about what options are actually there. So that's a general agent.</p> <p>Randal Koene:</p> <p>You can get into some interesting sort of philosophical directions there because when you think about having as many options as possible then of course that includes things like options to do things that we currently simply can't do because maybe we can't even think that way so something like a neural prosthesis or mind uploading would be necessary even to just be able to do those things like let's say for example be aware of and react to things that are happening at very short time intervals like microsecond intervals it's a world that we currently can't live in right and so optionality might include changing who we are in a sense. It gets interesting because some people would say if we change ourselves a lot and we're not really who we are anymore as humans right now because we've changed a lot then perhaps that's very similar to a scenario where say a worst case scenario that was mentioned where suddenly the environment no longer supports humans as we are. There are areas where that might look very similar.</p> <p>Jaan Tallin:</p> <p>I think it's important to be more precise about what do we mean by optional and how do you measure the increase in optionality. You can certainly have an increase in optionality that one person or one group of people like Manhattan Project scientists have to detonate potential like earth bending device that's an additional option for them. But I might result in everyone else losing all of their options by becoming extinct so in that sense like a more general version is that like we should really measure some kind of aggregate optionality that humans and more general sentient agents</p> <p>Randal Koene:</p> <p>And even that was very very difficult to measure because you might then argue that you should be measuring the aggregate over all possible future descendants of humans as opposed to just the people who are here because let's say that something takes optionality away from ninety percent of the people but then the ten percent of the people who have more optionality that creates a much greater future with more optionality for many more people than the alternative.</p> <p>Jaan Tallin:</p> <p>We'll go into either popular population ethics and infinite ethics even. It's like active research topic and it looks like we need to solve it sooner rather than later.</p> <p>Randal Koene:</p> <p>I'm saddened by the fact that we can't talk about every topic at length because these are super interesting things and I've always wanted to dive deeper into this like how do you decide what's good?</p> <p>Jaan Tallin:</p> <p>Don't you find it almost suspicious that there's a very strong overlap between super interesting topics and super important topics, it's not always but it should be like that.</p> <p>Randal Koene:</p> <p>Yeah that could point to something as well. It's true. Yeah okay well I guess maybe we'll have to have another workshop someday on what is good or how do you decide good. But that seems that falls more into say the domain of effective altruism or something like that.</p> <p>Jaan Tallin:</p> <p>You can always kind of like make progress by going up on the level of meta. So like you say like like ah it seems really hard to decide like what is good then you go like up one level meta, okay so what kind of things should I do now that would give me more optionality to decide in the future what is good. Like, for example, at the recent conference in Puerto Rico the Future Pipe Institute organized that there was like someone who was making a really good case that it's brobably going to be really likely that this massive value in having like this contemplating period during which we basically are not like as humanity think about what's going to happen next trillions of years as opposed to like just like rushing along with the first thing that comes to mind. Because it's like just we have like good reason to think about that we're going to be better at making great value to different periods. Then we would be basically losing from not acting companies in this first period. That's not a meta point.</p> <p>Randal Koene:</p> <p>Yeah I think that's probably true. It's unfortunate that when you look at the decision makers across the world very often that's exactly not what happens it's more the opposite that the next supporter is what matters the most.</p> <p>Jaan Tallin:</p> <p>That's also like an opportunity because you see why this is happening, you see the game theoretic underpinnings of these situations. And once you can realize that, you can take a step back and think about how do you solve those. What's going on coordination problems.</p> <p>Randal Koene:</p> <p>Okay. Well having created this context and putting it in a setting like this. Maybe this is a good moment to dive into the whole brain emulation aspect of it. So just kind of introducing here where this is coming from. When discussed in the context of AI safety I get different reactions to the notion of whole brain emulation. Sometimes people will be seeing it as a potential benefit, something good that will help us not have as much AI risk because humans will be able to keep up better, we will be better integrated with changing world of technology. But sometimes I get the exact opposite reaction which is, well, whole brain emulation seems like something that adds another unknown. It adds something else that could accelerate the development of artificial general intelligence or an agent AI. And that it could be its own risk, in some sense as well. Which kind of relates to what we were talking about before. About which changes on optionality are good and bad and sort of figuring out what the difference is there. So I was wondering if we can get into a few specific questions there because there are some main avenues of thought or critiques that come up from time to time.</p> <p>Randal Koene:</p> <p>So the first one that I wanted to ask about is this idea that making a connection between the human brain and a computer. So brain computer interfaces, that is somehow a very important step towards uplifting us to a point where we are more integrated with machines and where the gap is is made smaller between human minds and artificial intelligence and the differences in our capabilities that somehow this is going to create a symbiosis as one well-known entrepreneur has said with artificial intelligence. Have you thought about BCI? And I'm not just keeping it separate from neural prosthesis or mind uploading for a moment, but just BCI as a tool for that.</p> <p>Jaan Tallin:</p> <p>I guess my clip answer would be that, like Robbie Hanson's comment about this, he said that trying to make humans competitive with computers by developing brain machine interfaces is like trying to make horses competitive with cars by developing stronger ropes and so I wouldn't rule out that there is something there, but the bandwidth argument that might just start being utterly unconvincing because if you think about it if you were kind of like partnered up with someone who runs 1 billion times slower than you do. Then that beta is basically a person who can say one word per decade. And it's just going to be a burden. Is it's okay to be useful. You already know what the word going to be. That's the answer to bandwidth. That's a claim but there might be some more interesting arguments that I haven't heard but like... It's possible that I just haven't paid attention to some more serious thinkers in that space. I can cirtaintly learn more things about the brain with higher bandwidth. And then that could be useful in brain uploading for example. Or useful for alignment purpose.s</p> <p>Randal Koene:</p> <p>I see brain computer interfaces as an essential component for data acquisition, for learning about the brain in order to be able to model brains to be able to make neural prosthesis and that sort of thing. So as a part as a technology, heading in that direction, absolutely of course it's very important. But yeah I agree with you that in itself that's not really solving a problem of this gap between the two. We don't have to get into that much deeper sense we're both on the same side with this one. I would like to hear someday from the people who do advocate that as being the most essential thing to do for AI safety. I'd like to understand where they're coming from or how they imagine this should work.</p> <p>Jaan Tallin:</p> <p>If there would be like some serious careful thinkers, that would be super interesting to talk.</p> <p>Randal Koene:</p> <p>So the next critique or argument that I often get is that if you if you work hard on building neural prosthesis and then from neural prosthesis or partial brain uploads you end up getting two whole brain emulation or some kind of artificial brain like that, this is in itself of course a type of artificial intelligence or artificial general intelligence if you like although other people would call it natural intelligence emulated. And that it would be fairly easy to make it superhuman just by say increasing the speed or something like that or making sure that the memory is never fading something like that. So then that there could also be some sort of takeoff scenario, either a slow one or a fast one. Now I'm not exactly sure how self-improvement works with a human brain. I'm sure there is a method. And it may be a bit more patchy and a bit more complicated than with something that has one specific algorithm that is following. But before we even get into that do you see ways in which whole brain emulation itself could be an existential risk to humanity?</p> <p>Jaan Tallin:</p> <p>Oh sure, the way I look... I have talked much about it. So in that sense my thoughts are not super careful here. As I out source my opinions I should be more careful and honest in this in this topic. And he believes brain uploads are net positive so in that sense I'm working on priors that come from him. But I do think that there's this almost uncanny valley before we get to brain uploads. We will get to something that is potentially capable but not really human yet. So we might have like a potentially very capable nonhuman agents on this planet which is like almost isomorphic. So that is like one scenario definitely that might be problematic. Another scenario is basically when it turns out that there's some kind of a competitive situation or something. Where you get some advantage in some competitive access by sacrificing a piece of humanity, pieces of values. Which means that like we have like some race to the bottom. That would also be another extension of disaster potentials. Getting fake humans might be problematic or ending up in some weird place. But but also if you get things right, then that might be really awesome because we might just buy more time when it comes to solving problems.</p> <p>Randal Koene:</p> <p>Yeah but it's clearly so complicated because there are so many different details about how the research evolves and how you get from the very first bits you're doing. Say you're just making Ted burgers hippocampal prosthesis or something like that. Or you're trying to emulate the brain of a Drosophila and what happens if you start building agents based on these two Drosophila brains. There's so many different paths as you said that makes it a really complicated question of how do you make sure that you end up with a net positive of that. Versus you end up going down some path that has risks associated with it. But of course that's also true for any technology development. You know every time we develop some new technology there are many different possible outcomes and products and things that could have net negatives and net positives as well. It's just too hard to... So there definitely are some ways in which it could be an existential risk. But it's not that clear. I was kind of curious about this case of saying how could people using a neural prosthesis become an existential risk to to all of us or something like that. But again that sounds like a it sounds like a great sci-fi scenario.</p> <p>Jaan Tallin:</p> <p>Yeah like these weird cyborgs with metallic voices.</p> <p>Randal Koene:</p> <p>I have to think if this is again vain optionality versus staying the same. You mentioned competition. But what if that competition itself is something that has ultimately a long-term net positive or something like that. You have a species that is a little different that humans...</p> <p>Jaan Tallin:</p> <p>Technological competition seems to have given us a lot of tools that are clearly useful.</p> <p>Randal Koene:</p> <p>We're actually making pretty good progress through these questions. Even though I thought could take forever. Let's get into the next time the next critique then or the next argument. The next argument I've heard that cautions against a strong push for neuro technology and whole brain emulation is that work in those areas may accelerate advancements towards runaway self-improving AI. And well does it concern you and how do you see this different say working on whole brain emulation versus just to wait neurosciences currently investigating the brain?</p> <p>Jaan Tallin:</p> <p>Intuitively it doesn't sound to dangerous to me. I think because it's sort of like lower hanging dangerous fruits like just throwing more computer at the stuff at simple algorithms that people are doing already anyway. And trying to create AIs that create AIs like architecture search. Or like if you're kind of tinkering with something like a spaghetti code and trying to get insights. That seems possibly problematic but like just doesn't seem to come to me as the most dangerous thing to do.</p> <p>Randal Koene:</p> <p>I was trying to think of some examples of specific things that I might think that would be discovered by doing research on whole brain emulation as opposed to the way that the most neuroscience is conducted today. It's not obvious to me. Even with things that are still problems in AI. Say for example that deep learning requires exponentially more learning as you try to train up more complicated knowledge or a better understanding of context around it. That's something that we would love to understand better. How it is that humans managed it. Especially since we can only digest very few examples for everything that we learn.</p> <p>Jaan Tallin:</p> <p>It matters possibly to the point upon that. Because human is a spaghetti code.</p> <p>Randal Koene:</p> <p>It's not clear how you would learn this from trying to do whole brain emulation. It's more something that cognitive science, AI research itself, something like that is more likely to come across that solution.</p> <p>Jaan Tallin:</p> <p>AI itself was able to figure that out when it's doing architecture search. If they feel it just like a human doing architectural reverse engineering on human minds or AI doing architecture search in AI space. My money would be on AI.</p> <p>Randal Koene:</p> <p>It can simply do so many more searches so much faster.</p> <p>Jaan Tallin:</p> <p>It's like sume are dumb, but evolution was even dumber still.</p> <p>Randal Koene:</p> <p>That brings us to the fourth big argument. And this one is one in favor over an emulation. And the idea is of course this idea of symbiosis or the merger between what is the human mind and the merger with AI and its capabilities. And the idea that you can reduce AI risk or the risk to us in a sense by being more closely integrated completely entangled with everything that's going on in AI. So that a whole brain emulation of mind uploaded person could benefit more directly from what is developed in AI because AI and modules can be part of them or they can be part of it. It's it's kind of hard to describe because I don't really know how to imagine it. But it's sort of this join them rather than compete with them. This this idea of in the past royal families used to marry among one another to avoid competition and to consolidate their power. It's a mingling of a DNA in a sense except that you could say that this is alien DNA it's AI DNA is something different than human DNA. Have you given some thought to what this merger might look like?</p> <p>Jaan Tallin:</p> <p>You brought out the alien DNA. AI is going to be more alien than aliens. If you have biological aliens, they are likely going to have similar eyes. This thing that DNA is going to be similar if we merge with aliens, but even that sounds icky to me. Just to say the least. Merging with AI should be way more icky. Even though it doesn't seem like aliens. And also I think it just it doesn't strike me as a sufficiently rigorous topic exercise. When you talk about solving a complicated problem by just ignoring most of it. Having said all that, I still I would leave open that door for some serious thought in this in the space and perhaps people actually would come up with some interesting scenarios that involve things like transparency. For example transparency to make it more difficult for AIs that are improving to do like... And the more ways we have to monitor them the more difficult would it be to do that. ...more the better we would be of steering those critical phases. So that would be one angle of these merger scenarios.</p> <p>Randal Koene:</p> <p>I completely agree that it's necessary to get more detail to think more rigorously about these examples. Because what we're doing now it's useful to discuss like this but it's still kind of hand wavey. We're saying in general one could think of how this might help in supervising what how AI is developing and stuff like that. But when I try to think in real nitty-gritty detail about how AI and and human minds can merge, then I start to think about things at a smaller scale. Not the scale of an entire brain but... Let's take an example, it's a real example, let's take Ted burgers hippocampal prosthesis. Now Ted burgers hippocampal prosthesis, when implemented on, either software or in a chip. It's really just a model that is or learning to approximate functions from input to output and it's searching for those best matches. And then using them to to do what that piece of brain tissue is supposed to do. Now there are many different ways you could implement that. And and of course, even now, that's where AI comes in. He's using machine learning techniques to build those those models. So there is a lot of ways in which developments in AI can find a home and these pieces that are then developed as replacements for bits of the brain. It could be very small. It could be at the level of an individual neuron or an entire area. It could then lead to differences like say a hippocampus that allow you to directly select which memories to keep and which ones to forget and that sort of thing. You can imagine that there could be other ways of strengthening connections between different patterns than the normal Hebbian learning. But another way to do that. So I can see a lot of ways that where at this very fine scale where AI immediately starts to become integrated into neural prosthesis and whole brain emulation because it's just the natural way to try it to solve these problems to implement things in there. And and that's the first part of it. And then the second part is where you would intentionally want to make it possible to feel that you have the capabilities of some AI system and that it feels as natural as say being able to retrieve something from your memory so that it's like a part of your brain. And and then you start to wonder, well, if these are the things that you would want to do anyway for doing whole brain emulation, then how does that map into wanting to to have some kind of safety valve on how AI develops because that's not automatic that's not something that just evolves directly out of it. You would have to expressly try to make sure that the environment in which AI is developed is such that human minds have insight as, you say, transparency into what's going on. So that's still not really an automatic thing. It still feels like even if you're trying to create this merger because you know whole brain emulation uploaded minds are already closer to software code and I mean they are, they can be, software code and therefore you see this at a small fine detail you see these these mergers happening. It still feels like the problem of AI agents that self improve rapidly and could go off in a wrong direction is kind of a tangential problem. It's still something that needs to be explicitly dealt with and isn't automatically...</p> <p>Jaan Tallin:</p> <p>Not just like individual AI agents, but also like some weird races that we might create as in this like whole brain emulation cenario. The opportunities are kind of similar in orientation and whole brain emulation that we will just create smarter humans and we definitely need smarter humans right now to figure out like how to actually stabilize the future. However the threat model again is like we might be creating smart non-humans by doing careless augmenting or we might create some weird race to the bottom in competitiveness and basically lose overall optionality and all humantics.</p> <p>Randal Koene:</p> <p>And that is what feels like not good to me.</p> <p>Jaan Tallin:</p> <p>There is opportunity there in having... Simple thing is like, I think, a lot of like augment allocates point to is that we kind of are already augmented. In some sense it would be a natural progression and so far it seems to be with with a few setbacks and seems to be like so far so good. Other question in like, how much runway do we still have until we you have to be more careful and more planning.</p> <p>Randal Koene:</p> <p>So we've run through pretty much all of the main questions and I do have a concluding question but I wanted to ask first if there is something in this whole topic that you feel that we haven't addressed or haven't talked about that you think really should be mentioned.</p> <p>Jaan Tallin:</p> <p>I haven't specifically spent a lot of time, when it comes to augmenting and uploading humans. I'm probably like another ajacent scenario that we... Another pursuit of research or research area that we haven't talked about right reasons. Its basically genetic modifications and embryo selection or or direct gene editing which has very similar, perhaps minor, threats and opportunities on augmentation. So that's another interesting alternative to keep in mind. If you say that you want augmentation for x that's one question that you have to be prepared to ask when it's like, why not just like genetic humans did you get that x, might be safer or might not depend on x.</p> <p>Randal Koene:</p> <p>There's probably a lot of things that you can't simply genetically modify humans to do.</p> <p>Jaan Tallin:</p> <p>Yeah but the cool thing though is that it seems to be a minor version or augmentation, built-in opportunities, there are fewer opportunities probably and there, are but there also have fewer threats. Because in some ways where... Some interesting point that somebody made was that you could humans, you could get a superhuman by just averaging humans. So like I guess I'm not an expert, so like, I mean the fact is that if you average human faces they become attractive. Which is like interesting phenomenon. Which basically you're smoothing away irregularity so if they cancel out. And you get like really nice attractive faces. So it's for similar reasons like when your average humans you get rid of the deleterious alleles. So the territorial alleles keep us from from potential. So in that sense, it seems like not so drastic thing to just start averaging humans like in some ways we naturally do that.</p> <p>Randal Koene:</p> <p>Like what communities organizations and companies do, by combining a bunch of humans together in some structure.</p> <p>Jaan Tallin:</p> <p>in an abstract sense. Well I think that's like a fairly different sense of averaging. Basically you're not averaging humans, you're aggregating humans.</p> <p>Randal Koene:</p> <p>Yeah, I was wondering how that compares with averaging.</p> <p>Jaan Tallin:</p> <p>The specific thing is like the low-hanging fruits in genetics sound pretty good. It's just like, just get rid of the bad stuff and why not? But then you can't go beyond.</p> <p>Randal Koene:</p> <p>Yeah that's true. Yeah okay. So then let me get to my final question for you which is really the question about action. If you want to, and as I know you do, you want to see to it that humanity can maximize sort of its long-term chances for survival and thriving, optionality as you call it, what is it that humanity as a whole should do, say decision makers or or individuals as well?</p> <p>Jaan Tallin:</p> <p>Yeah I think coordination and cooperation. More coordination more coordination seems to be a really good. One of my favorite essays is Meditations on Work by Scott Alexander. It's a book-length essay about coordination columns. All of the problems that humanity has, they can be just summed up as their coordination problems and bad... So yeah figuring out how to cooperate more, because realizing how much there is at stake. If you think that the world is at stake, then just don't forget that planet Earth it's just a tiny speck in the universe. I mean Derek Drechsel doesn't like his ideas to be associated with him because he thinks that ideas are better if they're not associated with any person. So like there's this idea from somewhere, that a utopia where you're building your utopia with this additional constraint that every step should be an improvement. They shouldn't make anyone's situation worse. And cannot alow pathological casess like somebody just like wants to be the king.</p> <p>Randal Koene:</p> <p>But you know that it's not always how solving it a difficult error landscape works.</p> <p>Jaan Tallin:</p> <p>Yeah the interesting thing is that we do have like this additional resource that most people are not aware of which is the rest of the universe. And the place is bigger than anyone.</p> <p>Randal Koene:</p> <p>That totally makes sense if the pain point that people feel is resources. Which it is currently. But I mean there are other possible pain points. Like we talked about, what if there is a change in some set or subset of people and that is somehow different and there maybe, could be, some pressures that are experienced as painful to some other subset of people so these sorts of pain points if you want to avoid all of those as well that's that can be difficult.</p> <p>Jaan Tallin:</p> <p>Yeah so there are some values that are zeros on some sense. Like those values are going to be problem no matter how much resources we have. So the idea is to try to satisfy them in by segregation. Like everyone who wants to be the king of the world can have their own planets. So like just accept the meta value that you're going to have a way more optionality than you have, way more resource and have-nots, way more way better future than even considered. It's just not going to be like relatively good compared to others.</p> <p>Randal Koene:</p> <p>Yeah by pointing to the universe, one big important thing that you've mentioned there is perspective, because in addition to cooperation, I think perspective is extremely important in having a good perspective on what's really going on. Not just being focused on you know what you think is super important right at this very moment. And that I think is a big problem, is this long-term thinking is not very common. Probably because our lives are short.</p> <p>Jaan Tallin:</p> <p>That's one of the reasons why being somewhat cautious, but still pushing the AI risk framing more like an environmentalist rathar than a socialist. Because like social risks, if you say that AI could be like really bad for society, which is true. It also creates really bad competitive intuitions in people. It's like yeah I want like my social values to be like Trump over Chinese social values and that's that's just not great. This is way better to frame it as a problem that we have in common. And like environment is that one thing that we have in common. So in that sense that frame is periodic.</p> <p>Randal Koene:</p> <p>So framing could be an important thing to work on. Better frame problems. Well thank you. This was extremely interesting. And as I mentioned, very much at the beginning, we could have gone off for hours in just one direction. Like how do you think about good or something like that. So yeah that was wonderful. Thank you.</p> <p>Jaan Tallin:</p> <p>Thank you so much.</p> <p>Randal Koene:</p> <p>Thank you so much. Okay, good luck. Stop recording now.</p> <p>Mallory Tackett:</p> <p>Can everybody hear me?</p> <p>Randal Koene:</p> <p>Yup.</p> <p>Mallory Tackett:</p> <p>Okay. Now I have the screen sharing off. Sorry for my audio going out randomly like that. That was a really interesting interview; I liked it a lot. We're going to follow this up with our first panel discussion. These questions are going to be in relation to the Jaan Tallinn interview that we just watched, but after that, we're going to take a short break and we will resume at 1:00 PM Pacific time for our general panel discussion. Again, you can ask questions directly in the live stream YouTube channel or you could call in at call.carboncopies.org or call the number (415) 455-3017. This information is also on our events page. Before we opened to questions our panelists will have an opportunity to discuss the interview and our workshop topic and then we will move to our questions. Our panelists today are Dr. Randall Koene, Dr Abdulfaz Alipour, and Dr. Keith Wiley. I already introduced Dr Koene, but again he's our founder and chairman for the Carboncopies Foundation and he's known for his efforts to advance research in whole brain emulation.</p> <p>Mallory Tackett:</p> <p>Dr. Alipour has his PhD in pharmacy and is pursuing a double PhD in psychology and neuroscience at Indiana University Bloomington. In his research, he is developing new neural network architectures that are inspired by cortical column circuitry and he is testing their predictions through large scale in-vitro neural recording. Dr. Wiley has his PhD in computer science and he has expertise in artificial intelligence, evolutionary algorithms, various artificial intelligence techniques and machine learning. He is also author of the book A Taxonomy and Metaphysics of Mind Uploading, which is available on Amazon. Welcome panelists, thank you for joining me.</p> <p>Randal Koene:</p> <p>Yes, thank you Mallory. Just to add to things you've already said, by the way, could you mute yourself, or can everyone mute themselves when someone else is speaking, just in case? Okay, there we go. Mallory, you're not muted at the moment. I don't know why. Anyway, it doesn't show up as muted, but you probably have a different mood button on your headphones or something. So, just to add quickly here, I don't see, Abdulfaz Alipour on the hangouts yet. So I'm assuming that he hasn't logged into that. That's not a problem. There he comes, he's joining right now. And just so you all know, there are a few other people from the Carboncopies Foundation who are also logged into the hangouts and you guys, you're all welcome to directly participate as well of course, just like our viewers who can call into that phone number or use call.carboncopies.org. I wanted to just quickly say, there are a bunch of questions that came in from the audience and we're going to try to get to as many of them as we can.</p> <p>Randal Koene:</p> <p>Some questions can be a little bit difficult in the sense that we may not understand exactly what you meant in your question, so we might answer it the wrong way. If you want to be sure that we get it right, that's where calling in either using the phone number, or call.carboncopies.org, is an excellent way to prevent that problem because, if you hear us getting it wrong after you've asked us the question yourself, you can just correct us and say, \"No, no, I, I really meant this, could you please answer that question?\" So, there's slight advantage over typing it into the live stream chat. Okay, with that, I just wanted to throw out a first question, or present this to the panel. One of the things that we got into, in that conversation, is we really started talking a bit about, what does it mean to have a good outcome for humans?</p> <p>Randal Koene:</p> <p>Because when we talk about AI risk, I guess the simple version is where you assume that AI becomes smart and then there's a terminator scenario, and all the humans get destroyed. That's the science fiction version of AI risk. But that's not the only outcome you could have. You can have an outcome where AI is simply going about its business, and humanity is just this tiny little thing in the corner that doesn't have much to do with it anymore. We don't participate much in their exploration of space, they just kind of keep us alive in a zoo. You might well say, right? And then the question is, is this a good outcome? And people may have different views on that because okay, humans are still alive, our society still exists, and maybe we don't have all that option-ality that Yam was talking about. But maybe if you look at it from the point of view of a whole intelligence ecosystem instead of what are the humans doing, maybe some people still think that's good. So, determining what a successful or good outcome is can be the first thing you have to do. And I'm wondering what the people on the panel think about what is a good outcome for us and why.</p> <p>Keith Wiley:</p> <p>Am I coming through? Well, with regards to this sort of a preference to sort of protect our, special-ness and therefor sort of make sure that we don't get pushed into a, into a sort of corner of obsolescence or something. You could re-frame that question as, what if we discovered, eventually, that there actually are other intelligent species in the universe, which is a popular position. It's actually not one of my preferred positions, but if we found out that was true and we've found out there were sufficiently, pretty far advanced beyond us, then we would have the exact same feeling of mediocrity. It'd be like, oh, well, okay, we're just some podunk, relatively doumb intelligent species in a corner of the galaxy. So then, the prescription would be, oh, well, to preserve our specialists, we need to somehow keep those aliens down or something.</p> <p>Keith Wiley:</p> <p>So, barring the technical challenge of sort of countering some alien species, that's already ahead of us, it's just philosophically unconvincing. Like, why is the solution to our bruised ego to go crush all the other aliens out there that have gone further than us? So then, if you rephrase that, then it's like, okay, so now do we have a good motivation to try to prevent AI, or some sort of enhanced versions if humanity, from coming into being? Does that rationale really make any sense when you look at it the way that I just phrased that?</p> <p>Randal Koene:</p> <p>Yeah, I see what you mean. Before I try to answer that, I was wondering if anyone else on the panel has an opinion.</p> <p>Abolfazl Alipour:</p> <p>No, no specific opinion on this particular topic.</p> <p>Randal Koene:</p> <p>Okay. Yeah, I try to grapple with this question as well because of course when we talk about whole brain emulation, we're talking about changes to at least optional changes that some people could choose for themselves. It could be that we all go in different directions. That, some people develop in one way or another. And in the end, if you look at the end result again, just like what Keith was saying, this could look just like bumping into aliens with the only difference being that there's this common origin. And then you start wondering about things like the rate of change. Does it matter how quickly we sort of develop into lots of different kinds of intelligence. So, all of this is hard to pin down and it's hard for us to determine in advance before we've thought through all these questions, what are the criteria, the parameters that we think are valuable or important about humanity and what we've accomplished, that we say is this is why we should all survive. This is why either humans as they are now biological humans should continue to exist into the future, or at least minds that think like humans to some degree or whatever intelligence evolves, needs to be derived from the way we're thinking because of certain values that we think are really important and that we want to carry them over. Or we could just say, well, this is all way too analytical and ultimately, it's just the drive to continue to exist. And as long as we feel that whatever is happening is because we choose to do it, then it's us, and therefore, it's okay. That's success. And if whatever's happening to us is not something we've chosen, then it's not success. But as you'll see later when I talked to Anders Sandberg, that isn't quite as simple either, that of when are you in control. Does anyone else have a question from the panel about Jaan's conversation, before I bring up another one or, before we go to an audience question?</p> <p>Keith Wiley:</p> <p>Sorry, nothing comes to mind.</p> <p>Randal Koene:</p> <p>Okay. So I think we'll switch to an audience question in just a moment. I want to throw one more question out there before we do that. And the one I want to put out is, towards the end of the conversation Jaan mentioned that another issue we should look at is biologically enhansed humans or, that whole other different technology, not using computers, not uploading, but, what happens if we can genetically modify to achieve whatever augmentation we want. And I'm wondering, does anyone here have an opinion about what that means either in terms of being a risk, or a benefit in itself? How does that compare to something like AGI and whole brain emulation? What do you think about this biology as the route?</p> <p>Keith Wiley:</p> <p>Are you referring to when he was talking about the sort of hopelessness of trying to bring horses up to competition with cars?</p> <p>Randal Koene:</p> <p>There was that, but then he said that, and then at the end he kind of switched back and said, well, you know, another thing that we should really not forget about when we're looking at, or trying to plan ahead for humanities, we should also look at the biological augmentation angle, because a lot of things might be achieved that way.</p> <p>Keith Wiley:</p> <p>I think my response would be the same thing that he said about the horse, which is that there are certainly no particular reason to think that blind evolution has converged on some sort of biological maxima. We just are, kind of, whatever evolution was able to cobble together on what's called a local Optima. So, we're good at what we are, but in the space of all possible DNA configurations, there's very little chance that were as good as we could be. But it's still seriously worth considering whether we believe that biology has any capacity to compete with non biology, in the long run. Right now, there are many ways in which biology is the better technology. And in that sense I just described biology as sort of successful nanotechnology.</p> <p>Keith Wiley:</p> <p>But once you sort of escape the protein and lipid and sort of need for water and once you kind of remove those biological variables that are incidental to what you're really trying to accomplish, but they're required at the chemistry level, then it's hard to believe that biology is really buying you anything intrinsic. Biology is just how we do it. It's how nature does it. It's how evolution does it. But there's no reason to think that it's really competitive. And we have all sorts of evidence that points that way. So, our relatively simplistic 20<sup>th</sup> century computers on certain metrics just outperform biology in ways that are... There no conversation to have about it. And I'm not convinced that that won't be the pattern for everything as technology goes on. I can't see an obvious counter example where biology has to be better than just going at a problem without having a preference for a particular solution. Instead of leaning toward what LG or lean toward the full space of all possible physics and chemistry, I'm doubtful that biology is going to win very many of those races.</p> <p>Abolfazl Alipour:</p> <p>Yeah, and I agree with Keith because, from an AI standpoint, I totally agree with the horse analogy of that was discussed before, and I think it would be, somehow, meaningless sometimes to think of it like that as a method to catch up with AI. But from another perspective, if you think of nondestructive whole brain emulation, you would eventually need some sort of a brain computer interface or some sort of a neuro-prosthetic to transfer information from biological brains to some artificial medium. And I think from that perspective, BCI, neuro-prosthetic, is extremely important, but from arguing for advancement of BCI and calling for more attention to BCI or neuro-prosthetics, because in order to catch up with AI, I think that would be a little bit, a little bit improbable or implausible at least.</p> <p>Randal Koene:</p> <p>Okay. Yeah, I think those are all really good points. And yes, Keith, as you mentioned, I think you're right, what Jaan was basically alluding to was the idea that you can look at biology as getting to the point of what you might accomplish with some nano technology. In a sense it is nano technology, but yes, as you both pointed out as well, there are limitations to that.</p> <p>Randal Koene:</p> <p>So, I noticed that I've sort of taken on the kind of moderator role in this bit of the panel. I'm Sorry about that, Mallory. You can always jump in and do that if you want to.</p> <p>Mallory Tackett:</p> <p>All right. Are we going to be moving to audience questions now? Okay. So, the first audience question that we're going to ask is from Leslie Seamor. He asks, \"Skype moved voice and multimedia communication from conventional PLTS to open protocol, scalable Internet with firewalls, and similar security architecture constructs. Do you see any similar changes, at least at the metaphoric level when the Internet payload content breaches the wet brain directly?\" Could somebody, maybe rephrase that question, or can answer to that, or has knowledge pertaining to that question?</p> <p>Randal Koene:</p> <p>I can try, but I'd love to let someone else have a first go at it.</p> <p>Keith Wiley:</p> <p>I'm still thinking, and I spoke first last time, you go.</p> <p>Randal Koene:</p> <p>Abulfazl, how about you?</p> <p>Abolfazl Alipour:</p> <p>So, if I understand this correctly, the question is, \"What would happen if you are able to connect...\" To put it super simplisticly, and correct me if I'm wrong, \"What would happen if you are able to connect a search engine into your brain?\" Do you agree that this would be a simplified version of this question?</p> <p>Randal Koene:</p> <p>Yeah, I'm not 100% sure. This is where, as I said, if people asking questions were on our call line, it would make it easy for them to clarify a little easier than typing into the chat there.</p> <p>Keith Wiley:</p> <p>I'm curious if Lezlie...</p> <p>Randal Koene:</p> <p>Oh yeah, sure. Go ahead Keith.</p> <p>Keith Wiley:</p> <p>I'm curious if he's asking about the benefits of open source or open standards as opposed to a walled garden approaches to security. I completely forgot what the acronym PLTS stands for, and trying to just read that.</p> <p>Keith Wiley:</p> <p>At any rate, I certainly think that there is, in most cases, security is better served by open standards that embody secure algorithms, sort of like the way public encryption works, as opposed to security that is achieved by trying to make sure that... Thank you Rose for decrypting that acronym. ...as opposed to security that basically depends on making sure that you... that no one even knows how your security works, and that is the method of security. That's an inherently weak form of security. So, one thing that we definitely have to take very seriously, as technology becomes ever increasingly incorporated into our brains, is we've really got to get security right in a way that we have clearly, completely, failed at in the last 30, 50 years. When I was in graduate school, one of the professors who I was inspired by, in terms of artificial life, one of the people that sort of drew me to the school I chose was David Ackley.</p> <p>Keith Wiley:</p> <p>And, he was interested in computer security and since he was one of the pioneers to artificial life, his approach to it was very, sort of, evolutionarily inspired. And he and Stephanie Forest, and others at the University of New Mexico, took an approach to computer security that was intentionally inspired by biological immune systems. And I think we have seen some of these analogies crop up in our attempts to build these auto adaptive self monitoring on the fly security systems. We do sort of try to do some of this in the modern era, but I'm not sure if we have a very refined and underlying philosophy for how we do it. Just to get back to the original question, I think that as this becomes increasingly incorporated into our bodies, it will just become that much more serious, just because it'll put lives more directly at risk. We're already concerned about hacking pacemakers, Parkinson's, and brain implants. And this is just getting more and more serious as time goes on.</p> <p>Abolfazl Alipour:</p> <p>And just to add to that, imagining that the question was, what would happen if you have brain implants and what would you do to secure the communication in these brain implants? I was actually... When you talk to people about brain implants, one of the common concerns is that, how would you secure that a brain implant, how would you make sure that someone cannot upload some viruses, or some bad software into my brain implant, where someone could basically hijack my brain implants.</p> <p>Abolfazl Alipour:</p> <p>I think possible, approaches to this challenge might be to use... So, one possible idea would be to use some sort of a distributed ledger technology that is currently developing for internet-of-things devices, and one of the approach would be to use quantum switch. But the way I think about, I think, at the moment, one possible viable option to secure communication in brain implants would be to use some sort of a distributor ledger technology. That's what I think about it.</p> <p>Randal Koene:</p> <p>Okay. It looks like the person who asked the question, Leslie Seamor, is actually trying to call in at this time. So maybe he's going to be able to clarify as questioning person, which would be very useful. I'm not sure he's ready yet, but we'll see in just a moment.</p> <p>Keith Wiley:</p> <p>Is that phone number he's attempting to use supposed to go into the Uberconference?</p> <p>Randal Koene:</p> <p>It goes into the Uberconference, which Alan can then connect directly to our hangouts. I'm not hearing him yet, so I'm assuming that Alan hasn't...</p> <p>Allen Sulzen:</p> <p>And we have Leslie, who had a question from the audience, he is here live on the call now. Go ahead Leslie.</p> <p>Sara Kochanny:</p> <p>All right, Leslie. So, how it will work out is they will just...</p> <p>Randal Koene:</p> <p>I'm afraid the audio just cut out. I couldn't hear it.</p> <p>Mallory Tackett:</p> <p>I think she's just explaining to him how it'll work, and then he'll be on.</p> <p>Randal Koene:</p> <p>Okay.</p> <p>Allen Sulzen:</p> <p>Leslie's live on the air.</p> <p>Mallory Tackett:</p> <p>Leslie, can you hear us?</p> <p>Allen Sulzen:</p> <p>I didn't mute Leslie. Sorry, Leslie.</p> <p>Leslie:</p> <p>Can you hear me?</p> <p>Allen Sulzen:</p> <p>Now we can. Thank you.</p> <p>Mallory Tackett:</p> <p>All right.</p> <p>Leslie:</p> <p>Hello?</p> <p>Mallory Tackett:</p> <p>Yes, we can hear you now, Leslie.</p> <p>Leslie:</p> <p>Hello. So, you can hear me, right?</p> <p>Mallory Tackett:</p> <p>Yes, we can hear you.</p> <p>Leslie:</p> <p>So, I believe that...</p> <p>Allen Sulzen:</p> <p>Leslie, if you would just stop the YouTube that you're watching, then you'll be able to just hear us, and then you can join in back on the live stream once you're off the call.</p> <p>Leslie:</p> <p>Okay. Why don't I try again? Okay. I have no YouTube.</p> <p>Mallory Tackett:</p> <p>All right.</p> <p>Leslie:</p> <p>I assume you can hear me.</p> <p>Mallory Tackett:</p> <p>We can hear you just fine.</p> <p>Leslie:</p> <p>So, a simplified model of would be that we have a brain implant or something, some sort of infrastructure. So, the question is... There are two questions. One is how to protect it from interceptions. Just like when you have a cell phone. You make sure that no one is listening, no one can inject any information as the wireless signal goes up. It maybe a wireless signal, but the signal is basically translated from internal nural signals. And a at the infrastructure side, there will be agents, I would assume which represent you as a person and that agent is intercepting your brain tree infrastructure communication. So, that brings up two major questions. One is how to protect the pipe between your brain and the agent on the cloud or whatever they're going to have at that time. And the other question is how the agents of different people communicate with one another.</p> <p>Leslie:</p> <p>So, what would it be... So, It seems to me that just following the paradigm that telecommunication is following, all of these protocols are standardized. I would expect that when it becomes real there will be a standard division effort. And really how secure your brain and will be will basically will depend on the quality of the protocol and the firewalls in between those regions; and if there are any central services that all agents are talking to. How is that central service protected, or something equivalent some block chain or something that', when put in place on the central server. So, basically the question was poking at other people's ideas that, what kind of systems architecture arrangements. I didn't see any of these issues being in the list of questions regarding the merger AI and membrane. So, basically, that is what I am asking. Does anybody have any kind of vision as to what would be a roadmap, and how the whole architecture would be regulated by the industry, similarly to all the telecommunications standard bodies that operate today with the conversion of an IP base communication.</p> <p>Randal Koene:</p> <p>So, Leslie, I hope you can hear me as I'm responding. I don't know how the sound is going back with Alan's trick, If you hear it straight through.</p> <p>Leslie:</p> <p>How much was transmitted?</p> <p>Randal Koene:</p> <p>You came through fine, on my end anyway. Some people are saying that they heard a lot of echo but I didn't hear that. So maybe this is...</p> <p>Leslie:</p> <p>Hello?</p> <p>Randal Koene:</p> <p>I'm hearing you fine. Can you hear me?</p> <p>Leslie:</p> <p>Hello?</p> <p>Randal Koene:</p> <p>I think that Leslie... I don't know how the sound goes back to the Uberconference Allen, if that's...</p> <p>Allen Sulzen:</p> <p>He should be able to hear you directly so we can, we can talk to him...</p> <p>Randal Koene:</p> <p>So, you don't need to... He doesn't need to turn on the live stream, or something, to be able to hear me. Right?</p> <p>Allen Sulzen:</p> <p>He should be able to hear you. So I don't know why not, but it came through well. So if you want to...</p> <p>Randal Koene:</p> <p>Okay. In any case, I will try to address the question. So, you're right, Leslie, that the question of safety for the communication protocol when you build a BCI or the safety of a whole brain emulation, in an ecosystem of AI that problem was not addressed clearly, at least so far in this workshop, and it also, to my knowledge, hasn't been addressed very clearly or explicitly by most of the talking points or the writing that's come out of the AI safety community.</p> <p>Randal Koene:</p> <p>And I think that's partly because they sort of constrained themselves to the problem of what to do about the intelligence of the AI and the possible dangerous runaway scenarios of that. Whereas this other problem, you can kind of set that aside and say, well, this is a problem for the encryption community because this is all about data paths and encrypting that and about not letting people hack your brain. It's easy to dismiss it and I don't think it should be dismissed because it's clearly not simple. All of our systems today are pretty hackable. Hardly any of them are foolproof. So, I can only say that, in my own background, I did some encryption stuff because, in information theory, you learn about that sort of thing to some degree. Back then the professors were all saying, well, even though our systems are not foolproof today, in theory, you could make them all pretty unhackable and now add on top of that blockchain, which didn't exist back then, maybe that would make it even better.</p> <p>Randal Koene:</p> <p>I'm not sure because at this point I'm no longer... I couldn't call myself an expert in that area. All I know is that it's definitely an issue because currently everything seems pretty hackable, or a lot of things do, and that's going to make a big difference to how secure people feel in the sense that, okay, I want to connect myself to this machine out there to these other agents, or I want to have my brain emulated and be an upload. These agents, again, how those agents represent us and how they communicate and whether those could be faked and other things like that, this is additional problems and hurdles you could have there. It sounds to me like just the general problem that people try to hack and misuse every technology out there.</p> <p>Randal Koene:</p> <p>And in the future it might not just be people trying to do that. It could be other intelligence, other AI trying to do the same thing too, tring to use it to their purposes. So, every little point needs to be analyzed in that sense. And maybe this is why going to open standards is where you end up because then you have the most people paying attention to at least one protocol and trying to get it right instead of lots of people having their own little thing and each of them being very breakable, not getting enough attention, discovering all the holes. So, I think something that standardizes is probably what you would typically see. So, in that sense, wrapping all the way around, my answer to your question would be, yeah, I think it would probably go in a similar direction that way. I don't know if this answers your question because it is a complicated question. It's not really in my domain, but that was my attempt. If anyone else wants to make an attempt, please go ahead.</p> <p>Abolfazl Alipour:</p> <p>I just want to say that I agree with Randal and nothing is 100% foolproof un-hackable. And yeah, there's always the concern and it would be much, much better if we have a system that defines a standard and everyone is using that. That would be much more helpful. I'm looking forward to hear what you think Keith.</p> <p>Keith Wiley:</p> <p>Right. Well we're sort of mirroring each other. I would just reiterate, I think Leslie mentioned, in theory there are notions of quantum security. There are notions of security in which even if you can't prevent someone from breaking in or listening in, you can make it possible to detect that it has occurred. Even if you can't prevent someone from breaking in without also breaking your own channel, you can make it so that if someone breaks in the whole thing collapses so that at least they don't succeed and then you can rebuild afterwards. There are all sorts of approaches. We have all become sort of jaded in the last decade or two. Every time someone says that they've got a new approach to security that's going to solve all problems we learn that's not true. I think quantum mechanics is trying to bring a whole new level of confidence to that discussion, but for my part, I just kind of lost confidence in the whole thing. Which is why I go back to what I said earlier. The research that was being done around my graduate department, although not directly with me, was to sort of accept that security is not a perfect thing. Just the way your body's security is not a perfect thing. You were subject to viral and bacterial and parasitic attacks all the time. Evolution solution was not to ever attempt to evolve the sort of a metaphor of an iron clad wall. Instead it detects and responds and reacts and fights back and just sort of does its best. And the truth is it doesn't always work.</p> <p>Keith Wiley:</p> <p>Things that attack biology sometimes get through and kill you in various ways. But that is what the system attempts to do. It just attempts to detect, adapt and fight. And I think that ultimately the right approach to security is to be adaptive. We're just going to have to make our computers and especially our computer bio-interfaces and everything like that. We're going to have to abandon this idea of a mathematically perfect system and that will be very hard for society in general to come to terms with, because we need our bank accounts to be not some sort of computer version of..</p> <p>Mallory Tackett:</p> <p>I think we might've lost Keith there.</p> <p>Randal Koene:</p> <p>Yeah, that's too bad, but it gives me an opportunity... Oh he's back. Maybe you want to repeat what you said the last like half minute or so.</p> <p>Keith Wiley:</p> <p>I was wandering around aimlessly anyway. I was just wrapping up that we really do have to accept the idea of these computerized immune systems that detect, adapt and fight and sometimes lose, but the war wages on, even if the occasional battle is lost. And that is our overarching philosophy to computer security. I don't think we're there yet. I don't think our society is ready for that.</p> <p>Randal Koene:</p> <p>I want to quickly latch onto that...</p> <p>Keith Wiley:</p> <p>...Entity that's going to allow us to do that.</p> <p>Randal Koene:</p> <p>So first of all, I wanted to say, Keith, that answer was probably the most lucid answer of the lot and thank you very much for saying all this. I wanted to latch onto it because when you mentioned you have to come to terms with the fact that nothing is going to be a perfect solution for security and you sort of have to learn to live with that, but society may not be ready for it. Suddenly, on a meta-level, I'm seeing this as something we may encounter with the whole AI security or AI safety issue, which is that the attempt to analytically figure out AI safety, which is really what the FHI, the FLI, MIRI, and others, are trying to do is an analytic approach to how do we accomplish AI safety. It may be that ultimately we'll discover that it's always going to be the same thing as this immune system approach where there is no perfect solution. It doesn't constantly work, and you may just have to come to terms with that, just like in security and communication. So, maybe this applies to the bigger topic as well.</p> <p>Mallory Tackett:</p> <p>Okay, I think that kind of concludes the answers for that question. So, unless there was anyone that wanted to add anything else on our panel.</p> <p>Mallory Tackett:</p> <p>It doesn't sound like it. So, I'll move on to the next question. This is from Ree Rose. She asks, \"BCI technology could be very positive and enhancing. How do we prevent potential malicious usage and unintentional consequences?\" And I think that kind of wraps back around to what we were just discussing. She goes on to say, \"For example, control of a person's mood, voting, consumer preferences, et Cetera.\" But I would also like to add, what about indirect control, such as when we have the kind of controversy we have right now with people's data being available and not being used for marketing campaigns and targeting people specifically, directly for certain things. If that's going to be an issue once we're able to upload our brains and if there's some way that that could be accessible. And I also just wanted to mention, I am incorrect about us taking our break, we're actually going to be taking our break at 1:45 and then coming back at 2:00 PM Pacific Time.</p> <p>Randal Koene:</p> <p>Okay. Yeah, thanks for that correction. I'll take a quick first stab at this. And yeah, thanks for broadening this from just looking at how to make sure that there's no malicious, say, signals going into the brain or that your signals are being misrepresented outward. But even what Mallory was saying, how about control of a person's mood? This is actually part of Rose's question, could you have control of a person's mood and that sort of thing. And I think it's very closely related to Leslie's question in the sense that ultimately it's a security problem. It's a matter of who... What are the rights that we bestow, first of all, when we have these systems? Like when we started messing around with DNA there was the same sort of question, what are the laws going to be about this?</p> <p>Randal Koene:</p> <p>How can you use someone's DNA? Are you allowed to use a person's DNA without their explicit consent? And if they give their consent, do they really know what they're giving consent to? Similarly, when you talk about brain computer interfaces, you're going to want to have informed users and the person using it is going to have to have a fairly good understanding of the security that they've got coming along with that. And that security has to be pretty good, very good in fact. But in addition to that, there are all these indirect ways that people might find that there is some control seeping in from elsewhere that they wouldn't want. If you can give somebody images directly into the brain, for instance, if you can put them into a virtual reality of sorts, there's the potential that that virtual reality can be shaped by those who create those programs and that that can influence what a person thinks. And it can be very subtle.</p> <p>Randal Koene:</p> <p>Now the same sort of thing of course is happening today with advertising and political campaigns and all the rest, and the whole concept of fake news and all of this. So, it's not a completely new question. It just becomes more pressing when you're so much more directly connected. And so it's not just the question of security and protocols, it's also a question of having laws that people and agreements they have to make and education. Understanding what those agreements actually mean and what you can, what you can think that you are, how secure you are, and how secure you aren't. So, this happens today, even on the Internet, people don't realize how easy it is to fall for something. Say you receive an email, what happens if I click on this link? So the informed user is the safer user education is going to be an important part.</p> <p>Randal Koene:</p> <p>I know this doesn't sound like a perfectly technical solution to everything. A lot of it's kind of messy and requires bringing a lot of people up to speed and all of that. But I think that's exactly how it's going to be. It's going to be a bit messy. And the only good thing about this, assuming that not everything goes foom is that hopefully we won't have to adapt everything all at once. Hopefully it's a step-wise process for some people are going to get, say an artificial retina or if they're a locked in patient, they'll have some way of controlling their new robotic exoskeleton and something like that. And those are some fairly limited paths through which communication happens. And you can, you can figure out how to safeguard that and explain to the user how to use it. And then we become used to those sorts of things. And then it goes to the next level where maybe people have brain to brain communication of a kind. And first it's a thin channel and there are ways to secure that and then that becomes a broader channel remorse as possible and they've already learned to live with it to a degree. So, hopefully this gradual, and iterative process allows for the learning that we all have to do to make it happen. Anyway, I'll leave this to someone else now.</p> <p>Abolfazl Alipour:</p> <p>I just wanted to add to what you said and I think there are interesting promising technologies on the horizon, as I talked about before, a little bit about the distributed ledger technology. So for example, blockchain is an example that is immutable. You cannot change it. So I believe that in the coming years with the advent of web 3.0 with the Internet of thing taking over and becoming more and more prevalent, I think there might be technical solutions for these concerns and these problems that not 100%, but to a good extent, they're covering all these different issues that we're dealing with. For example, controlling someone's mood, their voting, and consumer preference, and all these different hot topics that we have to consider when we want to think about neuro-prosthetics. For example, imagine that I haven't neuro-prosthetic that is for depression, for people who, who have chronic depression. And then what happens if someone can hack into that and instead of making someone better, just, worsen their condition. So how would it be secure that, I think one technical answer to that would be to look into the coming technologies like, Hash Graph or, Iotas, and tangled technology, the Dac technology that it's coming and I think that might provide interesting solutions to deal with these problems.</p> <p>Randal Koene:</p> <p>Yeah. I totally agree that there are probably a lot of new solutions coming down the pipeline. But I'd like to caution that just because something seems hot right now, since it hasn't been used much yet, we don't really know what all of its holes are and some of them can be insidious. So take for example, what you just said about the person who's receiving treatment for depression. Now let's assume that there are 20 million people in the world who are receiving the same treatment and there's a company that's providing this. As a company, therefore has probably got some data about how often each of these people are receiving their treatment. And the user may have signed an agreement where they said that the company is allowed to use this data to improve their services or something like that. And they interpret that to mean that they can use that to improve services to these people, but not just for the treatment, but also to sell it to advertisers to send them stuff that's good for people with depression.</p> <p>Randal Koene:</p> <p>So again, you've created a loophole here where some unexpected things might start to happen. You might start to suddenly notice that all of the advertisements that are popping up for you, they're all based around depression, but they might even be subtle advertisements where they are not directly about depression. They're just advertising things that typically appeal to someone who happens to be going through depression at certain times of the day and strange, strange stuff like that. So it can be very hard to locate all of the problems in advance. That's where I think the analytical approach fails and it has to be this iterative learning approach for how do we really safeguard what we're going through right now.</p> <p>Abolfazl Alipour:</p> <p>Yes, that's correct. I totally agree with that.</p> <p>Mallory Tackett:</p> <p>Okay. It sounds like we're done with that question. The next question that I have is from Alexei Popov. I don't think I'm pronouncing that correctly. He asks, \"Why are we so concerned about AI threats while staying in the body is 100% fatal? Should we better discuss whole brain emulation into context of mind uploading or evidenced based cryonics?\" I think maybe what he's asking is why are we so concerned with artificial intelligence safety when there are still issues, to be solved with mortality? I'm not sure if I'm interpreting that correctly or not.</p> <p>Randal Koene:</p> <p>Well, hopefully we were interpreting it correctly, but he could, of course, call into call.carboncopies.org if he wants to elucidate further.</p> <p>Mallory Tackett:</p> <p>If you'd like to clarify on the YouTube channel, we can also look at that.</p> <p>Keith Wiley:</p> <p>So, there's one obvious way in which the question of AI threats is relevant even though biology is sort of the guaranteed death. We're all sort of thinking about solving, although it's not necessarily my primary motive in mind uploading, but, the obvious response is that everyone's concerned that AI might end not only your life but end humanity. So, if it's a choice between letting humanity continue to hobble along for a few more centuries, while we slowly figured this out and accidentally, creating some existential elimative event, then clearly the choice would be, okay, let's, let's not go straight at AI now, even though it's tempting. Let's just keep hobbling along with our 100 year life spans or 60 year life spans or whatever. And let our technology get to the point where we can do AI without wiping humanity out. I think that's the obvious sort of go to response there.</p> <p>Randal Koene:</p> <p>Yeah, I would agree with that obvious response. And just to sort of emphasize the second part of his question, shouldn't we be discussing whole brain emulation in the context of mind uploading or evidence based cryonics? Yes, of course. And that's what we normally do. Say for instance, in our previous workshops, that's exactly what we did. We talked about the technology to get to mind uploading, which is whole brain emulation of one sort or another. And the different paths that go there. We've talked about ways to work with preserved brains and how to get to whole brain emulation. And then we've expanded that to look at a few other topics as well. So I don't know if you were there when I was giving my opening remarks and I pointed out that this is a big puzzle and we keep adding in more pieces in our workshops are trying to address a whole bunch of them eventually.</p> <p>Randal Koene:</p> <p>So now we're trying to address this overlap area where AI, safety and whole brain emulation may interact. And that's an acknowledgement of the fact that yes, we personally may really care about whole brain emulation as a technology either because we think it's super important for individual people or we think it's super important for humanity as a whole. But, but we have to acknowledge that you're not working in a vacuum. If we create whole brain emulation, if we're doing the research towards whole brain emulation, the things that happen because we're doing that work may interact with the other things that are happening around us, say in the world of AI Development and where that goes. And that all together can have an effect on where we all end up. So the outcome isn't just dependent on our thinking about mind uploading and cryonics. So I think that's why we're trying to, you know, find these, these corners situations, these tangential things, these places where domains overlap and think about that as well.</p> <p>Abolfazl Alipour:</p> <p>And from another perspective, I think it's still important to think about AI threats. So let's, in an imaginary scenario, let's imagine that we have the first whole brain emulation and that one becomes an AI thread by itself and it takes over and it makes it impossible for everyone else to perform the whole brain emulation. And so it wipes out the entire humanity. And that would be the only thing that exists on the planet. So I think still it's really important to consider that AI threads, especially when it comes to whole brain emulation, what happens, and I think this is one of the four topics of this workshop as well, that whole brain emulation itself would be a runaway AI. And I think from that perspective it is really important to consider this AI threat topic, in whole brain emulation.</p> <p>Mallory Tackett:</p> <p>All right. I think we'll move on to the next question. So let's see. I believe we will do the question from Roman Citalu. \"His whole brain emulation necessary for mind uploading? Could a far simpler model be sufficient to simulate the human mind of a particular person?\" To also just keep it in the context of our workshop, I'm curious to know if this simpler model would be generated by AI Algorithms, instead of necessarily completely doing a one to one copy of the biological brain.</p> <p>Randal Koene:</p> <p>That's a great way to put an extra spin on it. I'm going to jump in right away, because it's so happens that there was a part of the upcoming interview with Anders Sandberg that got into this. And this is because, of course, you can make a distinction between a simulation of a person's brain or mind and an emulation where the distinction we'd make is a simulation is something that to the outside looks like perhaps this is a person reacting the way they should be reacting. But on the inside perhaps it's really not all the same. There isn't really the same person behind it. It could be more of an actor. And that's precisely where Anders, for instance, pointed out well. Our systems are best when they understand us best. So we can see with a cell phone, for example, that it works better when the interface kind of understands where we're coming from.</p> <p>Randal Koene:</p> <p>When let's say Siri learns something about us or whatever, or Google learns what our likes and dislikes are and then they can go out and find the things we enjoy. They become our agents looking for the answers we want to find or the things we want to buy and soforth. Now as you get better and better at that, if you have an AI that keeps on making better predictions of you at some point that AI could go out there as an agent and basically pretend to be you and go shop for the right things, invest your money the way you would be doing it, talk to your kids to make sure they feel like you're paying attention to them and all that sort of thing. And it gets to a point where you could say, yeah, there's a pretty good simulation of that person there.</p> <p>Randal Koene:</p> <p>But the question is, is that simulation the same as an emulation is something that can pretend to be you and other people won't notice it's not, is that close enough? Is that good enough? Is that what you're going for? And that wraps right back around to, I guess what is always the fundamental question that we bring up whenever we talk about whole brain emulation and research towards it, which is what are the success criteria? What do we mean by mind uploading and whole brain emulation? What is it we want to accomplish? Do we want to make agents that can pretend to be us online? Is that the main purpose? Do we want to create something that can improve us ourselves? Where we have the ability to say, think faster, you know, notice things at a microsecond, a splint interval and react to those things.</p> <p>Randal Koene:</p> <p>Do we want to be able to live longer ourselves by being able to emulate our brains and run as a mind upload in another body, have an artificial brain as it were. Whether you decide to do this by replacing bits one at a time or scan the whole preserved brain or which approach you want to use. So part of the question is always, why is someone interested in it? What is the success criteria in what they're going for? And so this part of this is reaching a consensus, what do those of us working on it really think the success criteria should be, what are we aiming for? And some of it is perhaps something you can derive more analytically where you can say, well, if people are interested in mind uploading, it really only makes sense to go after this if we at least care about x, otherwise we could just make any old AI or something like that. So there are reasons, by... I'm sorry, somebody wants to go on. Okay. I'll finish my thought later. Next person.</p> <p>Mallory Tackett:</p> <p>We actually have Roman on the Uberconference line. I think he's going to discuss his question. So we're going to have Roman on now. Oh, actually he just said his question was answered correctly, so that's great. Is there anyone else that was wanting to add any thoughts to that question?</p> <p>Keith Wiley:</p> <p>If I had anything around the safety angle that we're trying to put on it... Randall's very good at phrasing the underlying question here about what's the criteria we want. There are a couple of ways in which I've seen this sort of issue come up. There's always the question of philosophical zombies, this notion that if you emulate... Well, no, actually philosophical zombies... No matter what level you emulate, have you actually sort of achieved the goal of identity of consciousness, sort of re-invigoration in some metaphysical sense. Of course the best way to just sort of respond to that quickly is nobody knows and let's just move on for the time being. Now there is this other question, and there are companies that have done this. I can't remember if Randal touched on this. There have been companies around for several years now that are, sort of, trying to get a foot in the door with a sort of... What would you call it? Sort of, my mind archival... They don't even call it that, but just this notion of let's capture as rigorous a snapshot of a person's life as possible and see if we can turn that into something that we would call an imperfectly preserved mind and identity. There have been multiple approaches to this. I can't remember where I read this article. There was some guy who... He was a journalist, and he interacted with a company that was doing this. And their goal was to, basically, they would do several things. They would run interviews with you and try to sort of compile this sort of Chat Bot.</p> <p>Keith Wiley:</p> <p>They're trying to refine a chat bot that responded increasingly like the person does in an interview. They would scrape your social media profiles or webs,ites or anything available to try to build as complete a picture as possible of a person. And you can start seeing where this is all going. And then the larger question is, is there a fundamental error in the assumption that this is all predicated on? Thank you Leslie. I see that in the chat. The Replica Chat Bot with a K. Oh, Mind File, Jan. Yes, I remember that name.</p> <p>Randal Koene:</p> <p>Yeah, that's the Terresam movement right?</p> <p>Keith Wiley:</p> <p>See, I have been aware of these projects for so long, I've forgotten. So it sounds like we're all aware of us together. So yes, there are people who have asked the question of whether you can achieve something like mind and identity preservation. And then the secondary question, whether you can actually achieve any consciousness preservation. With these very high level black box approaches to what personhood means, you basically take a turning test approach to the whole thing. Which is that a person is just what you can get in and out through the IO interfaces with the system. So basically what can you put into it through its eyes and what can you get out of it through its mouth. And if the patterns are sufficiently like the person, then did we achieve our goal or not? And I'm going to safely say I don't know. But we've been trying to figure this out for a while now. I kind of go over this somewhat in my book, that Randal and I have kicked around the idea of at what level do you perform your system identification.</p> <p>Keith Wiley:</p> <p>It's the term Randall maybe very familiar with. At what level would you cut your system identification cutoff at and say, if we don't system identify at this low level, whatever our threshold, we can we choose, then we just say, it just not good enough. How do we set that threshold if you're really achieving the same behavior eventually? So I don't have an answer to that, but it's definitely a question that people have been thinking about for awhile. That's kind of all I have to say on that.</p> <p>Randal Koene:</p> <p>That was an excellent answer that went into a lot of detail. Yeah, exactly. It's about what is the good level of separation between what you would call a successful upload, having captured what you care about, and all the stuff underneath. Yeah. Perfectly said.</p> <p>Abolfazl Alipour:</p> <p>Yeah. And just going off of what Keith said... So, yes. We all want to have the simplest program that can preserve the identity of a person. And so one of the things that we need is, as Keith just mentioned, is consciousness. So what is the simplest thing that you can do to preserve consciousness? And that goes back to this idea of scale suppression. So should I be able to simulate or emulate all the ionic channels? Or should I be able to simulate all the neurons or the brain region? So at what scale, and at what level I can stop and then say, okay, this is enough to recreate that consciousness or recreate that mental experience, that phenomenal experience. So, and I think we don't know yet, but many neuroscientists may say it's just at the neural level. You need to emulate your system, your artificial brain at the normal level to be able to recreate that consciousness and preserve the personal identity, but we don't know yet. It was a great question, but no one knows yet.</p> <p>Mallory Tackett:</p> <p>All right. Is there anyone that wants to add anything else to that question? I don't think so. So our next question comes from Vitaly, and I believe this is actually a question that we've kind of addressed before in previous workshops. He asked, \"How detailed is the emulation of electric chemical processes you intend to use? Sub-threshold dendrite potentials, are they taking into account? Are features of spines taken into account? What approaches are used to emulate chemical synapses and neurotransmitter's?\" And one thing that I kind of like to add to that, as we experiment with whole brain emulation and with going down to different levels of detail, and as Vitaly asked in his question, are the insights that we gain from that information going to help with developing artificial intelligence.</p> <p>Randal Koene:</p> <p>I missed a bit but I got your question.</p> <p>Mallory Tackett:</p> <p>Okay.</p> <p>Randal Koene:</p> <p>Very nice...</p> <p>Mallory Tackett:</p> <p>I think you're having some connection issues Randal.</p> <p>Keith Wiley:</p> <p>I'm not sure if it's you, but try again Randal.</p> <p>Mallory Tackett:</p> <p>Randal, while you're figuring that out, could you mute yourself and maybe we'll have Abulfazl or Keith try to answer that question.</p> <p>Keith Wiley:</p> <p>Let's see. I was actually thinking Randall was the guy for it. So the question is, at what neuro-level do we want to attempt, these brain emulations. Of course no one has decided yet. One of those popular answers to that question, and one that I personally favor, is to take that sort of input output function I was describing earlier, at the action potential level of neurons. Which is to say that when you ask about dendritic spines and such in your question, I am with reservation actually writing off of that requirement. I'm proposing that maybe the better level is the one at which you build a system that can propagate signals through a network in a pattern that is similar to the way that a brain propagates action potentials through a neuron connected network.</p> <p>Keith Wiley:</p> <p>So whether or not the synapses actually have the exact same properties would be irrelevant, so long as the action potentials to actually get through in a statistically similar fashion. That's not to say that that's the right level, it's just one of the more popular levels to go to. I actually personally believe that that can't possibly be the level we have to go to because when people lose neurons, from a variety of medical maladies, at least at a low level, it seems to have very little effect on our health and our personality. You can lose a couple of neurons here and there and it just wouldn't make a difference. I personally suspect that something along the lines of cortical columns or other conglomerations of neurons that we would have to decide what our grouping criteria is, but some sort of unit of groups of neurons that performs a function and this might be as large as thousands of neurons like cortical columns, is probably, sort of the Lego brick we're looking for in all of this. But again, I don't really put a flag in the stand very deeply on any of this. We don't know. There are, of course... I'll let somebody else speak in a second, but just to quickly... There are definitely people who propose much lower levels. Hameroff and Penrose are well known for proposing the microtubule structure inside of neurons as a critical component of consciousness. And then of course, presumably of identity preservation and everything else we're trying to get at. People have taken this as an interpretation that they're against technologies like mind uploading and such. And I believe that they've been cornered in the occasional interview on this and it actually said, no we're okay with it all, but you do have to take into account this quantum mechanical requirement that Penrose and Hameroff are stipulating. So many of us are not actually on board with that requirement, but it just says the same thing. It says, okay, well there is this level of perfection inside of atoms that you've got to replicate or else we're going to say that the process has been successful. So you can make this decision at several levels of abstraction and surely the right answer at this time in history is we don't know yet.</p> <p>Abolfazl Alipour:</p> <p>And yet just talking about Penrose and Hameroff orchestrated objective reduction theory and the whole bunch of other quantum mind theories out there... So these series of really interesting getting consciousness to the molecular level... However, at the time being, researchers have not been able to show a mechanistic description of how this quantum effect, or quantum phenomenon, happens that can give rise to consciousness. For example, Penrose and Hameroff idea had a real big push back from the neuroscience community about the ability and how it could work in the brain, given its temperature and noisiness and other conditions that exist in the brain. And I think as you mentioned, probably at the nural level or at the circuit level we would find good enough information so that we could be able to somehow recreate the mental phenomenon on an artificial medium.</p> <p>Mallory Tackett:</p> <p>Okay. Since we did say we're going to do, Anders' interview at 1:30 Pacific, we're going to go ahead and skip our break and end the panel for now, but we will address any further questions from the audience members in Q and A sections later. So, with that in mind, we will commence with the second part of our workshop, which is the interview with Dr. Andrews Sandberg. He is with the future of humanity institute at Oxford University. This interview was conducted by Dr. Randall Koene. And I will just have to play it on mine. Unless Alan can play it. I'm not sure if Allen is going to be playing it.</p> <p>Randal Koene:</p> <p>Allen, if you can, maybe we can give yours a try and see how that one goes.</p> <p>Allen Sulzen:</p> <p>I'm queuing it up now.</p> <p>Mallory Tackett:</p> <p>Awesome.</p> <p>Randal Koene:</p> <p>There may be some noises in the background here too, eventually. It shouldn't matter too much.</p> <p>Anders Sandburg:</p> <p>We can overpower them with our own charisma.</p> <p>Randal Koene:</p> <p>Indeed.</p> <p>Randal Koene:</p> <p>I'm not seeing it yet, but I can hear it.</p> <p>Randal Koene:</p> <p>Okay. So I'm going to introduce you first and then we can get into our discussion because we're going to be using this in our event of course. Okay, let me get started then. Our expert guest for this event is Dr. Anders Sandberg who also happens to be a longtime friend going back at least to 2007, and the first whole brain emulation workshop that was organized by the Future of Humanity Institute at Oxford, possibly even further than that.</p> <p>Randal Koene:</p> <p>...Dr. Sandburg's work in computational neuroscience, which means we could geek out about that at length if this were a private fireside chat. Andrews is a senior research fellow of the Future of Humanity... ...of course, act of future technologies and artificial intelligence and whole brain emulation. He's also an excellent speaker and debater and has always, I've really been looking forward to this conversation with you. Welcome Anders. Thanks for agreeing...</p> <p>Mallory Tackett:</p> <p>Okay. I guess our backup option is not viable, so we'll just go with our original option. So anytime my microphone goes out, I'll just be paying close attention to our chat and I'll make sure to turn it back on.</p> <p>Randal Koene:</p> <p>There may be some noise in the background here too, eventually. It shouldn't matter too much.</p> <p>Anders Sandberg:</p> <p>We can overpower them with our own charisma.</p> <p>Randal Koene:</p> <p>Indeed. Okay, so I'm going to introduce you first and then we can get into our discussion because we're going to be using this in our event, of course. Okay, let me get started then. Our expert guest for this event is Dr Anders Sandberg who also happens to be a longtime friend going back at least a 2007, and the first whole emulation workshop that was organized by the Future of Humanity Institute at Oxford, possibly even further than that. Doctor Sandberg did his PhD work in computational neuroscience, which means we could geek out about that at length, if this were a private fireside chat. Anders is a senior research fellow of the Future of Humanity Institute at Oxford University, and of course he's a highly respected in fields of philosophy that deal with existential risk, the impact of future technologies, and artificial intelligence and whole brain emulation. He's also an excellent speaker and debater and has always, I've really been looking forward to this conversation with you. Welcome Anders. Thanks for agreeing to do this interview and to try to join in on the Q and A on the day of the event, even though you'll still be returning from travel that day.</p> <p>Anders Sandberg:</p> <p>Thank you so much, Randal. This is exciting. It's good to be, not quite here, but communicating.</p> <p>Randal Koene:</p> <p>Right. So, you're, of course, familiar with the goals of the Carboncopies Foundation and I imagine that... It's okay. I mentioned that you can also see that people who are working on whole brain emulation and people at the Carboncopies Foundation are also really interested in artificial intelligence or artificial general intelligence. Now, we don't very often talk about that in our workshops because they're already so many groups out there that are doing that. But we did feel that the overlap and the interactions or possible interactions between work towards whole brain emulation and work on artificial intelligence is something that hasn't really received sufficient attention yet. So if you don't mind, I'm going to ask you a few questions about your thoughts on AI and about risks and benefits. And about this area of interaction. Is that good?</p> <p>Anders Sandberg:</p> <p>That's sounds excellent.</p> <p>Randal Koene:</p> <p>So you've got a long history of dedicated concern and ,supporting some serious study on existential risk and in particular AI risk and AI safety. Could you tell us a little bit about how your thoughts have evolved in that time since you got started?</p> <p>Anders Sandberg:</p> <p>I vividly remember being on a train ride to Jane University back in the early 2000's reading Nick Bostrom's recently published paper on existential risk and I had this knee jerk reaction. This is preposterous. This is so stupid. This is just going to be used to slow down science and we need more science and technology more rapidly. Then gradually I became aware of... Actually, that knee jerk reaction might be a little bit too naive. Gradualy, I warmed to idea that, actually, existential risk is a pretty dominant concern. It is not a super important concern, but certainly it matters a lot, but the problem is of course just being concerned is not enough. You need to start picking apart the probabilities, risks and uncertainties, just try to see where can we do the most. There are some risks that we simply cannot budge. Some super-volcanoes from the moment, for example, there is a finite risk that we will all die of natural causes. There's no point in worrying too much about them.</p> <p>Anders Sandberg:</p> <p>The other risks are relatively intractable, but many people are always working on them like nuclear war risk. And then there are those risks that are more tractable. And at this point it gets interesting. If they're neglected but tractable, then you should probably put in more effort. Especially since even a small amount of effort, if it's a very tractable risk, can help a lot. So to me, future technologies are interesting because they had a fair bit of traceability simply because we are making up these technologies as we go along. We're inventing and discovering things. And that means that we can also regulate them and safeguard in various ways if we're careful, if we make the right choices, which is not always possible.</p> <p>Randal Koene:</p> <p>And besides artificial intelligence and related areas, are there other examples that you would say are areas where we could put in more of an effort then we're doing today and maybe not super-volcanoes or something like that, but other areas?</p> <p>Anders Sandberg:</p> <p>I think Bio risks are a good example. So there's certainly a far bit of people working on some the bio-security, but many of the emerging bio-technologies probably pose entirely new kinds of risk and I think it would be a good idea to make a serious inventory of what we might find there and trying to preclude some of those risks and that might require the various forms of disease surveillance and innovative methods of actually stopping, and for example, gene drives, et cetera. And I think this might be true for other technologies. One good example is actually quantum computers, which are not an existential risk, but the risk for encryption and privacy. The solution is of course quantum safe encryption, which both MSA and Google are trying to develop. And then we need to promulgate it. Before the quantum computers become too good. We want to have it around for so long that our secrets are kind of safe because the ones that can be cracked by the quantum computers, well they're primary points.</p> <p>Randal Koene:</p> <p>Hmm. It's interesting that you mentioned that because I was just out at South by Southwest and there was a startup company presenting there. Unfortunately, I didn't catch their talk and I don't remember their name, but they were explicitly saying that they offer quantum encryption as a way to safeguard your data. Even now, I don't know how they're doing it, but there out there.</p> <p>Anders Sandberg:</p> <p>So one interesting thing is that you can, of course, encrypt data using quantum encryption over our communication slide. And it's not as easy as people thought, especially the Chinese have been working very audaciously on developing this. But then you also want to have a quantum safe encryption method, and that might actually not involve any magical quantum computing, but it might be good for your branding if it has quantum in the name anyway, And I think this is going to become more and more urgent.</p> <p>Randal Koene:</p> <p>It's interesting that we're going down this path right now, because that's a great segway into something I wanted to talk about where Dr Ben Hurtsel was concerned. He's a mutual friend of ours and a researcher in artificial general intelligence. And he sees things a little bit differently than, for example, Nick Bostrom does or Eli Asrey does. He wrote a paper in 2005, so it's a few years old now, and the paper was called Super-intelligence: Fears, Promises and Potentials. And it seems, one of the things that he explicitly talks about is that the probability of different risks isn't addressed very well and it's very hard for us to judge which risk is really the one that we should be paying attention to the most. And then, for example, is it a case where other risks are so great that the potential benefit of artificial general intelligence in helping us prevent those risks that might be on balance, more important than say, worrying too much about the existential risk of AGI itself. So I think you're probably familiar with his thoughts on that. And I was wondering how you would balance those approaches.</p> <p>Anders Sandberg:</p> <p>So that argument is a bit similar to an argument I heard for us trying to send messages to extraterrestrial intelligence. Again, we are under so much risk here. So even though maybe there is some risk of getting out friendly aliens on the phone, if we get friendly as that might actually save us. Now if one is really desperate, I think that kind of Hail Mary strategy really might make sense. But I don't think we're necessarily that desperate yet. We got some years until we get the artificial general intelligence, maybe quite a lot of years, and we actually have a decent track record of surviving so far, which might of course not indicate that risks are small but at least that we can do something about it.</p> <p>Anders Sandberg:</p> <p>So I do think that we should do this judgment, but there is quite a lot of things we can do about that. So for example, demonstrating that on the net AGI is going to be better than no Agi, well I think that is fairly doable. On the other hand, showing that safe AGI is much easier than the dangerous AGI, I think that is going to be tough to demonstrate. I think you are not going to be able to prove that within the rigor.</p> <p>Randal Koene:</p> <p>Okay. But it is still kind of hand wavy, isn't it? Because you said for instance, that you don't think we're very desperate in terms of any of those other risks but desperate in terms of the risk of dangerous AGI. Right? That's the same question.</p> <p>Anders Sandberg:</p> <p>The thing about... Right now when we look at the existential risk to humanity, I think that nuclear war still isn't the top one and you can even make a basic estimation of naively we have seen 73 years of no nuclear war. So if you apply in a data function, et Cetera, you end up with between 0.1 and 1% risk per year, which is disconcerting. Maybe a nuclear war is not an existential risk, but it's still a certain amount of probability that is kind of worrisome. Now arguing that nuclear war risk is important work, but it also takes a lot of effort. You want a lot of diplomats. You want a lot of people in these studies to do their job. Now, AI risk is relatively mobile right now because we're still at a very early stage. A few insights might actually change the risk profile quite a bit. So what I'm arguing is not so much that we know that unfriendly super-like... I know some people who actually think this should be regarded as a default position. I'm not entirely convinced by that argument. They might be right, they might not be right. But I can certainly see that by moving AI safety research earlier in time, we can reduce the risk. And probably do quite a bit of useful risk reduction that way.</p> <p>Randal Koene:</p> <p>That makes sense. Yeah. I mean, if we simply ignore that there was any risk at all and didn't have any people interested in AI safety, that would definitely open up a bigger potential for other worst case scenarios. I'm sort of curious about both of those things. Actually, in the worst case scenario and what to do about it; because now we've spoken very abstractly about the risk from AI and we've also spoken in a very abstract sense about, well we should do something about that. I'm kind of curious, what do you think is the worst case scenario that should be expected if say an unfriendly AI or AGI is developed and what do you think is the best way to try to prevent this? So, if we do have people interested in AI Safety, which route do you think is the most promising?</p> <p>Anders Sandberg:</p> <p>I do think... ...Because I think most of us, we can imagine... We can start imagining ways around this and I think we could actually have at least some chance of reducing the impact. So I would expect the worst case scenario to be very bad and totally not looking like anything I could formulate. So you could imagine a scenario like, well, actually a rapidly and self enhancing intelligence is possible. So there are some systems that generate that you get a fairly hard takeoff of with some random utility function and then it goes off and does something random but instrumentally its very, very competent so it does everything it needs to prevent us from ever being able to stop it. So now basically you're in the same universe as a force that you cannot by definition stop and he's going to do something that's likely very dramatic, like taking over earth to use for atoms or doing something else. It's very hard to say.</p> <p>Anders Sandberg:</p> <p>Now I think it's very likely that we're going to run into other bad AI problems long before this. So in many ways the worst possible scenario is that AI works really well and then improves on it and it's worked really well, and it all keeps on going super well... On the other hand, I think it's more realistic to assume that we develop AI, we do stupid mistakes that fix that, we fix those, we keep on doing things, we discover new problems. This keeps on iterating and happening. And in the nice scenario, we robustly figure out ways of actually controlling AI, setting up motivations, and other kinds of safeguards we currently don't understand. Then we're getting into truly dangerous territory. The more scary scenario, of course, is the one where we don't learn anything, but we create incentives to use it.</p> <p>Anders Sandberg:</p> <p>So companies that don't use AI to direct where activity or going to the doing badly on stock market. So everybody will be using them and then the systems get more and more powerful and the world gets crazier and crazier, but if you don't use AI, the craziness cross receive. And then you ended up in a world that is not suited for humans yet, nobody has won very much. Now the ideal scenario, is of course, that we figure out useful things early on and we fix them. And in the best of all possible worlds, maybe is some simple mathematical theorem that you can prove, that gives you a safe AI. And it's also politically very easy to convince everybody that we should be implementing this. In a more plausible world. It's going to probably be a whole little science of safety. Just like we have the same safety in a lot of other domains and this is going to be fairly messy. Let's think about computer security and think about how we're failing at computer security today because of the incentives are all wrong, the software companies are not held liable for the security of their products yet we buy them. And the end result is that we've have built an entire infrastructure on systems that we can't fully trust that in fact have enormous glaring security holes, we can all know that, and we all choose to ignore it because living without a modern smart phone is not practical.</p> <p>Randal Koene:</p> <p>Yeah. Motivations and holding people accountable, holding companies accountable is really important. So I liked that you went into this, what is a more plausible scenario and, sort of, looked at these possibilities. I mean, it's obviously very difficult to really predict anything because it's so many different routes that are possible. It's very complex to look into the future. But, that takes us a little bit away from just focusing on something assuming that the major AGI or AI out there is always going to be something that has a fixed utility function and maximizes that utility function, that's where the danger comes from. Where as the reality might be more messy than that. Which I think is also something that Ben touched on his paper.</p> <p>Anders Sandberg:</p> <p>I do think this shows the importance of trying different approaches to AI safety. So, while our friends at MIRI are taking a fairly axiomatic approach in their thinking in terms of their fixed structures. Around FHI we have some people who are working very much on learning systems and I'm hoping in the future we're going to see even more approaches because right now we fully don't understand what the domain is and we might actually want to combine different approaches or figure out what are the sub two problems with them. And this even includes the people who work on near term AI safety. Quite a lot of them are of course not terribly fond of talking about AGI and super-intelligence. They think that they have enough trouble with their autonomous cars or how to manage drones well or even get them out of the bias of the credit scoring systems. But I do think there is actually a continuum here from their near term issues about controlling complex adaptive technological systems to the long term issues when these systems become essentially autonomous, and super powerful, how do we ensure that we already have enough of what counts as an important part of control?</p> <p>Randal Koene:</p> <p>Yeah. We could talk about this forever, basically, because every single thing that we say brings up another question. When we say timelines, how long term problems versus near term problems, how long is long term, all that sort of thing. I'm going to try to steer this towards the whole brain emulation topic. So when I discuss whole brain emulation in the context of AI, when I talked to someone about that, I typically get two very different kinds of reactions. Some people were giving me the reaction where they say, I think that whole brain emulation is an important potential safeguard against humanity suffering the worst case scenario from a runaway AGI. And others will say, well, that may be true that there is something to be found in terms of long-term future benefit for humanity.</p> <p>Randal Koene:</p> <p>But at the same time, working on whole brain emulation carries its risks in terms of either whole brain emulation itself being a risk or a whole brain emulation somehow accelerating the development of potentially dangerous AI. So I, I'd like to start talking about that and ask you a few questions about it. Now I've already talked with Jaan Taleen. He gave an interview as well, which is being presented in the same event and he was cautiously optimistic. He felt that whole brain emulation research would probably end up being a net positive in terms of existential risk. And he said that he was basing his opinion largely on what he learned from Carl Schulman who also at the FHI. And so clearly we should probably reach out to Carl in our follow up to this event. But I was wondering because he mentioned that, what do you think about the level of study that's been done so far on this particular problem with the interaction between AI Safety and research on whole brain emulation? And do you think there are specific people who are the leading thinkers in that sort of overlap area that we should be talking to?</p> <p>Anders Sandberg:</p> <p>Right now, I don't think there has been enough study on this. There have been informal arguments and in many cases we see formally arguments go back and forth and a bit based on personal taste. Maybe one has invested a lot of effort in brain emulation then that is automatic to bias in towards thinking this is probably pretty safe. I think the core question is how much would the progress in neuroscience push AGI and vice versa. So one possible argument would be if we do brain emulation its not just that we by definition will have a lot of computing power, but we will also have good ways of scanning brains, that directly doesn't help AGI much, but also a good way of modeling and running, we scan the neural tissues. And that's going to, long before we get to... ...Give us quite a lot of...</p> <p>Allen Sulzen:</p> <p>The audio has been muted, Mallory.</p> <p>Anders Sandberg:</p> <p>...did neuroscientists figure out things by having actually a really good neural model to start with. And how quickly do they tell AI researchers who can actually make use of it. So I think empirically the answer seems to be that it actually takes a fair bit of time before neuroscientists understand the neural issues, even if they have good simulations. Because it's very complicated and we're not terribly good at figuring it out. As a formal computational neuroscientist, I'm kind of embarrassed by how little progress we've been making despite our models becoming much bigger. But the reason is of course we need better ways of understanding. Now brain emulation is not necessarily based on having a super profound understanding of the high level stuff that would drive AGI, but the most of the scientific interest is going to be about that rather than achieving brain emulation.</p> <p>Anders Sandberg:</p> <p>And even when neuroscientists have found something interesting like, how would the reinforcement learning systems, of the brain works or some of the neural representations, it seems to take a fairly long while before the AI research is picking up. So if you take, for example, Russell and Norway's book on AI, we relive through the chapter about the history of the field of insights that are driven. You find a long list of interesting neuroscience insights and then you try to think, how many decades it was between people figuring it out and it became a part of an AI project and quite often it's several decades. So if things stay the same, I wouldn't be too worried because we might be doing the brain emulations and then a few decades later, the neuroscientists get the memo. However, that might change in the future. It might turn out that maybe AI research and neuroscience meld together much more. It might be that actually people like the Google deep-mind, started by people coming from Diane's group in neuroscience, have learned how to read neuroscience papers and actually get useful ideas from them. With my...</p> <p>Anders Sandberg:</p> <p>... another example might be that maybe the way the... ...organizes information and does online learning, that is really a simple thing, once you understand it, and then you can apply it in AI. I don't know how to assign much credence to this, but I think it's worth investigating much more deeply and we need probably need to develop tools to do that.</p> <p>Randal Koene:</p> <p>Yeah. Oh Wow. You covered a lot of ground there and yeah, this sort of echoes my thinking about it as well. I do think that there are definitely things that we can still learn from the way the brain works compared to how AI works. Say for instance, how do you manage to learn, a large variety of things in various contexts and do so from very few examples compared to what, say, you pump into a deep learning network these days. Those are the sorts of things where there's still a lot that we can learn. But it's not entirely obvious how you discover that in the brain. And as you said, it's not clear how fast can neuroscientists convert that into something AI could use. And for instance, this is a point where Jaan mentioned, he thought that AI could probably search the space of probable models and probable methods better and faster than, say neuroscientists would be able to interpret what's going on in the brain. So if you need to solve some issue with reinforcement learning or something like that, it would probably be faster to improve that just pure AI development. I'm not sure that's true, because some problems explode very quickly. Numbers are big very fast. And then when you say we're gonna explore all possible models or something like that, if you don't have a good strategy, you could be stuck until the end of the universe.</p> <p>Anders Sandberg:</p> <p>One of the really interesting things though is that hyper parameter searches in machine learning, have become much better recently. People had some useful insights on machine learning methods to improve other machine learning methods. And I think we should expect at least that to continue. That's not necessarily searching this enormously large landscape. It's just maybe 10 or 20 dimensions of hyper parameters, but that's already a pretty high dimensional space. So it might be useful to just keep an eye on this and how good does this generalize to other domains including trying to find models in other domains. If you start seeing the modern automatic model making to really take off, then we should expect things to get rather explosive.</p> <p>Randal Koene:</p> <p>Indeed. Yeah, but that's also where it becomes much more complex than just predicting a system that will use a simple algorithm to improve its utility function maximization over time. Because if you're building completely different modules that work in a different way, then you have different algorithms and everything becomes a lot more unpredictable.</p> <p>Anders Sandberg:</p> <p>...perspective. It might turn out to be tools to do this too. So I think Eric Drexler has made a very good point in his big report about reframing a bit of AI Safety. We quite often think about the AI or the neural network is some what self contained systems. But actually the part of a practice of generating things that solve various problems and most people in business anyway don't care about AGI, they just want to solve a practical problem. So we develop in pipelines and services that generate these things. Again, that is worth watching especially since they can be applied to brain emulation, then we might get a pipeline towards better brain emulation When we get a pipeline for decoding neural tissue and figuring out things about that, then we should expect at least a boost in neuroscience</p> <p>Randal Koene:</p> <p>Indeed, and what we really should be talking about is an ecosystem of various AI instead of the single AI that's going somewhere. Yeah, indeed. So now maybe we can run through a few very specific points that get brought up because these are just things where I often get an opinion from someone or a statement, but there isn't necessarily that much material behind it. And I wonder if maybe there's a way to slowly push towards a more precise understanding of those particular concerns or questions. So the first one I'd like to get into is the idea of having a brain computer interface, a high bandwidth, brain computer interface, something that is the target of research and also of some for profit companies. I'm not going to go into mentioning names, but we probably know who they are.</p> <p>Randal Koene:</p> <p>And sometimes you hear from them statements such as if only, if we can have a high bandwidth connection between the human brain and the machine, then first of all, that will help us avoid AI safety problems because somehow it will be more tightly connected with that. There'll be some symbiotic relationship between us and secondly we'll be able to benefit very strongly from this connection it will be sort of a part of that advancement. Have you thought about this claim regarding to, now, brain computer interfaces? We're not yet talking about neural prosthesis in this case.</p> <p>Anders Sandberg:</p> <p>Yeah. So I vividly remember a few years back when Elon Musk had spouted off something that was general face palming around the office. We like Elon, but many people thought that sounded stupid and I have a big mouth. I said maybe there is something to the argument so then my manager gave me two weeks to try to make a steel man version of Org. That's the opposite of Straw man. Let's see if we can make this argument work. And I found that the first version of the argument that saying, if we get brain computer interfaces, we're going to get enhanced and then we're going to be smarter than AI, that seems pretty unlikely there are real problems in making an enhancement that makes you super intelligent. Especially if you need to do that within a relatively short time frame. We might not know how far it is until we get superintendent AI, but the time it takes to test out anything that deals with meta human biology anything that's medical and then try to develop user interfaces and enhancements, that seems to be something that potentially could take quite a long time.</p> <p>Anders Sandberg:</p> <p>There is another argument and that is if you can't beat them, join them. So I get my brain computer interface. I'm linked to the AI and the this way I'm going to be on the winning side except of course the nature of that link and what we mean by winning side is quite tricky by some accountants. My mind is already linked to my cell phone because of extended mind hypothesis, part of my mind recites in my calendar and other applications. I don't have certain memories in my head. They're in my smartphone. So maybe I'm already linked to machines. And now the dangerous paperclip AI takes over the world and turns it all into paperclips. In some sense I was on the winning side because I had a smartphone, but this doesn't sound like winning. This sounds very stupid In fact. The reason is of course what... ...and we want that link to be the right kind of link. And in some ways, it's a very deep philosophical mess. So this doesn't seem very likely to work a priority, but there is something else that actually looked at a bit promising. If I'm linked to an AGI system and it can observe my an evaluation situations, it can actually estimate a bit what I would have done if it's trying to do what I would have done instead, this actually gives us a good chance. So the system might melt...</p> <p>Randal Koene:</p> <p>You know where this is going right?</p> <p>Anders Sandberg:</p> <p>Yeah.</p> <p>Randal Koene:</p> <p>If it can predict everything you're doing. It has an emulation of your brain, right?</p> <p>Anders Sandberg:</p> <p>Well not necessarily. It might my value system but nothing else. So the naive version of it might for example, notice that I liked helping little old ladies cross the street and I don't think kicking them in front of a car is a good thing. If it's just optimizing for that, then it might for example, run away from little old ladies because it wants to avoid them, and avoid helping them, et cetera. You need more rich information. And this is where things get interesting. If it could just get an entire copy of my brain, then we could definitely get the information over. But even my values need to contain some useful things to do value alignment. So, for example, if you follow up the causal reasons, why do I like little old ladies crossing the street safely? Why do I dislike kicking people in front of cars, now we might learn something about at least my morality that's actually quite useful.</p> <p>Anders Sandberg:</p> <p>There are two things here, of course, maybe one, shouldn't just use my own mind because I'm definitely morally pretty fluent. Maybe we actually want to make sure that either we take a certified same or perhaps even better, have a lot of different people who are in the right give input in order to do general value alignment. And second, of course, it's slightly tricky to get this to work really well because neural interfaces are tricky. But if I just say no robot, don't do that. Whereas if I smile at the robot, that's already sending a signal. Maybe I don't need the neural, interface at all. The neural interface is just cool because it might access my orbital frontal cortex and give some actual evaluation information even if I can't express it.</p> <p>Randal Koene:</p> <p>Yeah. These are all very good comments. And I liked that you said, okay, just even if you don't think about emulation and we're just talking about something earlier, like being able to understand your values, your value parameters that can be helpful. And of course I immediately started thinking about the deep learning networks that learned to be racist because they were learning from us. That's where you get into that whole value alignment issue and what are the right values, and should you even care about the right values? Are we supposed to tinker with that when you're dealing with particular person or invading your freedoms and stuff like that. It gets very complicated. But I also think people tend to jump straight to the assumption that we can talk about a system where you have a strong integration of the machine and the brain; where you have a connection that somehow is tying very closely into what this machine is doing.</p> <p>Randal Koene:</p> <p>And you mentioned the cell phone. And I think it's a perfect example for trying to think through what this actually means. Because when we say you have a high bandwidth connection between the brain and the computer, the computers still can operate at microseconds and even smaller timescales, whereas the neurons can't. So in this link they're talking at different speeds and that is very similar to what we're seeing with the cell phone and ourselves. With the cell phone, it has a different language, not just a different speed. It has a completely different type of language. It's using of a microprocessor.</p> <p>Randal Koene:</p> <p>...we have a neuro-brain and we work at a slower pace from neuron to neuron, although we have a lot of them. And we communicate in a very particular way with this cell phone. We can only press buttons or swipe, that sort of thing. So there's this communication delay or communication constraint built on this. And then you can think about, okay, so how has working with these cell phones, how has that affected the development of cell phones? This is sort of an analog for how does it affect the development of AI and potential AI safety, right? Or how has working with the cell phones affected us. Now we can say a lot about how it's affected us and, and some people think there are some good things there and some bad things there, probably a mix. But it also clearly has affected how cell phones are developed because cell phones are always developed to try to fit into say these communication limitations due to work well with how we interact as interface development, o present information to us in a certain way that makes it easily graspable.</p> <p>Randal Koene:</p> <p>We want interfaces that can tell us quickly what we're looking for. But of course that also constraints with features, right? The interfaces that are simple and fast or not interfaces that are highly configurable and very adaptable and all that. So we've got trade offs and this clearly has an effect. I think it's a great example and I think maybe thinking more about how we already interact with machines in that way, is is a way to try to imagine what this would do, building a better or faster or applied interface with machines in some sense.</p> <p>Anders Sandberg:</p> <p>So ideally of course, if you want an interface, it should be plug and play, it should work straight away. The problem is that probably means that it needs to be very pared down. And if you look at the general design philosophy coming out of apple, it has always been actually cut away possibilities and just leave the things that people actually will want to do. Hide as mush possible below the hood or maybe even make the hood the closed, you can't actually get onto it. Meanwhile, of course, if you're using any of the lineups, or UNIX systems everything is accessible, but well, reading the manual and learning how to use it, it's getting very complicated. Once you know it, it's very powerful. But that takes a long time and most people don't want to do that. So it might be that the transformative neural interfaces would be the ones that actually require a lot of learning.</p> <p>Anders Sandberg:</p> <p>So the most fascinating, neural interface I know of is of course Miguel Nicolelis attempts at brain that's connect brains to other brains. As a test of this idea, it seems like if this works, I want to see independent replication of it, but it looks like the brains can adapt to each other, and learn how to decode each other's signals somehow. That's awesome if it's correct. But it also seems to take a lot of time and I don't want to have a system that's not working for months and months, but yet I need to train myself to use it. So it might very well be that the neural interfaces with computers at first, they're going to be useful for people who are desperately in need of it, strongly motivated and the people who have the mindset of train themselves. But most applications are probably not going to be that deep.</p> <p>Anders Sandberg:</p> <p>So instead what you want to do is something that interprets enough of our signals and use a lot of smarts from the outside to try to figure out what we meant and the fact that our minds are relatively slow compared to the machines, it's not necessarily a bad thing. It might be that we have a slow process in, say, in fast processes and as long as we get enough feedback in our own pace, we can actually control that. This is a bit like our constitution governance state. The constitution is not changing that much. It's not supposed to be updatable at a very high pace. Below that level you have the laws which are updated in a faster pace while local regulation and norms can be updated faster and faster. So you might have systems with different levels of flexibility linked together. And if it's actually working well, then you can have a slow system setting the agenda, the fast systems implementing it. And so feedback system checking that everything is working. In practice...</p> <p>Randal Koene:</p> <p>Sorry, I hate to interrupt, but before you were talking about the degree to which someone could say that they are a part of the winning side. They're part of the whole thing, if they're integrated, if they're connected with machines. Now we're talking about a slow system and a fast system and that the slow system is somehow still governing and supervising what's going on. And it's interesting to compare that with what's going on in the brain already, where, for instance, we have systems that are slower. Our conscious awareness is definitely something that progresses at a different pace and in different chunks, then all of that subconscious processing that's going on in parallel throughout our cortex. And similarly, when we're trying to think something through logically, and we're trying to make up the steps, that's a very different and slower process than the other one.</p> <p>Randal Koene:</p> <p>And that in fact is the process that the machines can do very quickly. So it'd be interesting to see what happens there. But it's interesting to then look at how integrated those really are and what's really going on there. So for instance, we tend to think that our conscious awareness, that our conscious self, is in control. We tend to think that that's the part that is really the boss and we're governing everything that's going on. And yet you can show experimentally that you have already decided something long before you know that you've decided something because those sub-cortical processes and really doing that deciding work, of course, this makes sense, right? And the rest is just a reflection to yourself. It's just an observation about what's been going on in your brain. And now we can imagine that something similar is the case. If you integrate the human brain with the machines who are operating at a completely different speed, they live in a world of nanoseconds that we can't live in. They live in a world where they can use things like, quantum computers or simulated annealing or something like that to come up with ideas and solutions that we can't think of in our brain. It seems like one of those situations where ultimately you may have a feeling, a sense of control without actually having it.</p> <p>Anders Sandberg:</p> <p>So I think this is a very important point and generally I think most people say, yeah, I want to avoid. There is a...</p> <p>Anders Sandberg:</p> <p>My impression of the current state of play is that a fair number of the things we're doing are indeed illusionary. But our top level of the consciousness of mind, can give up the two and intervene not very quickly but we can...</p> <p>Randal Koene:</p> <p>Is it the veto, or is it other drives that are informing your consciousness to then give the veto?</p> <p>Anders Sandberg:</p> <p>That is not a good philosophical question. I need to check what the philosophers are saying about that, but I do think it makes sense that you have a top level but it's actually getting information from most of our systems. The systems I really have a problem with is the ones that never had an output on the conscious level or never tell the rest of the systems what we're doing. The real ignorant of secret societies of the grid. I don't know how many there are or whether they play an important role in general the brains job connected everything a little bit to average else. It's just about the degree of control and the degree of information is not as intense as one would expect. Once you started realizing how diffusely connected are different parts of our mind or you start to feeling a bit like a cloud rather than a person.</p> <p>Randal Koene:</p> <p>Yeah, the illusion of control and whether or not that's a bad thing, that there's an illusion of control. That's really I think is core to many of these questions that we're talking about today because when we first started talking we talked about AI risk and we talked a little bit about what do we imagine that if worst case scenario, and the best case scenario is. Now most of the time people tend to think that the worst case scenario has something to do with a situation where humans are completely not in control and where they have no say over their future and perhaps they are even somehow eliminated. Now when we're talking about situations where control is mostly an illusion, but there are aspects of it where we're tied in and say there's this veto power that again, perhaps isn't real because you know, freewill is such may not exist at all, but there's still something that we value. So really when you talk about the danger of AI and what it can do to humanity, we should be talking about what are the values that we're trying to preserve. What would we call a successful outcome? Which bits do we want to preserve and why? And then what sort of scenarios can incorporate that in some scenarios may include a lot of change where a lot of things that machines will be able to do and where they develop into becomes a part of what human society is. Right?</p> <p>Anders Sandberg:</p> <p>And so I'm reminded with some of I&amp;M Bank's culture locals were very super intelligent machines play a role in the plot. And in many cases they manipulate protagonists in various ways, more or less often. And the interesting thing is that in many ways these manipulations can be in many cases they are fairly benign the, because there's still a respect that the protagonist can do differently, but he's unlikely to want to do it differently because it's a really good argument that the situation is contrived in a certain way. Would we say that this is a bad situation? Well, as long as it's actually a fairly well intention, the entity that actually has our own best interest and some other good goals, taking that into account, that might be all right. If I have a veto power but never exert it, I might still be pretty happy about that because I might have my illusion of control. But it still is important for me to function.</p> <p>Anders Sandberg:</p> <p>Normally we won't have a sense of control because we're agents. We survive by moving around on the earth surface and manipulative it, and when we can't act, we're super vulnerable. When we're in a situation where action is not possible, we are at the mercy of everything else. And that evolution has made us really desire to be the actor. Intellectually, we might sometimes realize that I should listen to a smarter person and do what he or she tells me because they actually know better. But my little inner two year old will say no, I would do the opposite just because. Then of course my, inner 20 year old will try to get the two year old to listen to reason and then there's a lot of debate and meanwhile, of course maybe a really smart person with manipulate me because we know that I have this internal dialogue. But a good outcome would be that you think that intentions of transparent enough that we can kind of see that these seem to point towards a future that is desire.</p> <p>Randal Koene:</p> <p>Oh Gosh, you just opened up whole new can of worms, where we find good and desirable. But I just wanted to point out that you now have also again come across something that Jann Taleen mentioned. He mentioned that he felt that a good future is one with as much optionality as possible, which of course is our desire for control. It's the desiring to have as many different paths as we can take as possible. But you mentioned that sense of the illusion of control and possibly being important to us. And then I was reminded of how many people say that what they desire is happiness. And then when we think of a future with happiness, then you get into these wire-heading ideas, where you can just make someone feel happy, even if there was really nothing has changed about their situation.</p> <p>Randal Koene:</p> <p>And in the same way it could be possible that we could give ourselves the illusion of control when we have zero control. So again, it doesn't immediately solve anything, but if we think through what the real values that we're trying to preserve are, you have to think about very basic things like the value of say, something that we consider really human continuing for some reason because we think that very human thing is important or has made the universe a better place than it was without humans in it. This gets really deep philosophically.</p> <p>Anders Sandberg:</p> <p>So it comes up in a lot of existential risk research too, because maybe if we nuke ourselves and the cockroaches becoming intelligent, maybe they will have a much better civilization then us. In that case, maybe we should say, oh, that was a happy ending for the universe. And of course some value theories would say, yeah, just integrate the total amount of happiness and compare them. Now others will say, wait a minute, how certain are we that happiness is what should the maximized? There might be other things, we might be deep thinking or paperclips or what have you. So we also have to take more of uncertainty into account. The nature of what is good about humans, our uniqueness, I think many people have an intuition about it. So there is a lot of things one can do here and right now I don't think we have any complete theory about what the good is. Obviously philosophers have been working on this for a few thousand years. Some progress has been modest. We, I think we had learned important things, but it's pretty clear that the list of things that could be the ultimate good or the list of arguments why that mabe this list will never be complete is awkwardly wide. But it's worth noticing that even if it takes something as simple as happiness, people are quite bad at identifying what makes them happy.</p> <p>Anders Sandberg:</p> <p>And even when they know this action would make me happy, they might quite often not take that one. So there is one of the scariest papers I ever read, The Trends in Cognitive Sciences from a few years back, which was just reviewing these results and to me somebody who is kind of politically liberal. This was horrifying because if people don't even do what makes them happy themselves, giving them the option of doing that, okay, now that doesn't necessarily work out that well. Now I still think that most forms of control actually have very bad effects too. But it shows that it's tricky. Our feelings of what makes life better might not correspond to actually making life better partially because our feelings are evolved things that made sense of African Savanna and actually the life we're living now, not to mention in the future might be so radically different, that we need to develop new kinds of feelings.</p> <p>Randal Koene:</p> <p>Yeah, that makes sense. Yeah. So we went down a really deep rabbit hole there for a moment, and I don't want this to go on for too long, but I'd still like to quickly touch on a few remaining questions about whole brain emulation and AI. So I would have to talk about the idea that whole brain emulation itself can be a danger to humanity. And so I don't know exactly what people mean by that when they say it, but I think...</p> <p>Anders Sandberg:</p> <p>I can give us some ideas. So I wrote a paper a few years back together with Peter Eckersley, who back then was with the electronic frontier foundation now is at the partnership for AI. So we were looking at could you get risk out to having brain emulation? I think the most primary one would be if you have software people who suddenly have a radical break with a lot of traditional views on human nature.</p> <p>Anders Sandberg:</p> <p>You will have some people who actually have religious reasons to say these are not true people. They would have potentially economicaly disruptive effects. If we look at the old ideas in the Robin Hansel's, the H of M that it seems like getting a brain emulation breakthrough might be dramatically disruptive and you get entities that are in some sense a natural other so you can very easily tell the story how you could get just a conflict where some people think brain emulated people are not people, they're evil and taking our jobs and so on, so you could get another natural conflict. That still I think not an argument against doing brain emulation but rather making sure we'll use improved tolerance. It also of course has the idea that if you get a brain emulation is going to be self improving so fast, but now you get some form of hard takeoff. Before you know it, you have all the problems of the normal hard takeoff in AI.</p> <p>Randal Koene:</p> <p>How do you see that possibility? By the way, how does a whole brain emulation do a fast takeoff?</p> <p>Anders Sandberg:</p> <p>I personally don't believe this is particularly likely. So the normal way of arguing it would be something like, well it's running on a very fast computer. The emulated person can do a lot of neuroscience experiments on her brain, that you can run a lot of copies that test out things to improve various capabilities. And before you know it, you have some kind of post human who might now really start doing weird things depending on their value system. I'm not too worried about one of the person doing this. But you could imagine a society... So at some point, I think it was cultural man who was arguing with Robin Hanson, well that brain emulation society he's describing in great vividness in this book, it's not going to last forever because people are going to update the and compete and change it to other things. So in real time it's not going to last very long. And they kind of agree that maybe two weeks. That's still a lot of history...</p> <p>Randal Koene:</p> <p>I don't think we have to get into that necessarily. I think Robin's book with beautiful, but I think it has a prediction for things that will happen. It has its limitations for instance, because he left out AI as being a part of it. So many of the things that he has whole brain emulations doing, are things that just a simple AI program could be doing and that changes a lot about that whole scenario.</p> <p>Anders Sandberg:</p> <p>And you can imagine that they develop the simple AI sooner or later in the brain emulated world and suddenly you get the economic transformation that might be just as disruptive for the emulated people as well as the biological people. That scenario would rather be that you get very rapid cultural evolution which might produce actually extremely different kinds of entities. Some people again would say, yeah, maybe we're going to be some weird post human and they don't care about us meat humans and that naturally leads to conflict. I think a more plausible risk is, yeah. This unleashes dramatic changes in our domain, but a lot of people will not have access to and will be too slow to react to. And that at the very least look like existential risk. And it might indeed be some form of existential risk that develops into something that lacks those values that are really humane.</p> <p>Randal Koene:</p> <p>This will get us back to the same problem again, which is what is extent existential risk? What do we call a bad outcome for humanity? So let's say that whole brain emulation leads to a new Cambrian explosion of different kinds of minds who develop themselves in various different ways, not just minds but bodies as well, et cetera. And some of them do better than others. So there's an evolutionary aspect to it and you can see change happening in a way that's a bit faster than it is today. And when I say a bit, I might just be understating that. But if that happens, the question still remains is that bad because maybe this is the best possible outcome for whatever we consider valuable about humanity because it's going to spread everywhere very quickly, even if it changes. So does speed matter? It doesn't matter if you go from a to z from by going Abcd all the way to z and doing that in steps or it just as good to jump from a to z right away. If the outcome is exactly the same. If let's say, just as an argument for just the question of does the speed of change matter, is it important that that rate is slow for some reason?</p> <p>Anders Sandberg:</p> <p>At least in the case of a parasite delta? Do people typically think that the speed does matter? If I change day by day to become a more mature person with different political views, et cetera. Okay. But I might be fine with that, but not that one day I wake up and my personality and political views have changed in something. Now it seems philosophical that there is something problematic going on there. Because I agree with you. Why should we care about those steps? And part of that is of course error correction. We might want to be able to go back to, or note this thing.</p> <p>Anders Sandberg:</p> <p>There should be time to realizing what that might be doing. Oh dear, I know what I was voting for. I should do to something change myself. But I think there is something interesting about that Cambrian explosion situation to me that sounds lovely. I think it would be great to have this open in the future where we get a lot of humanities and they are all drawing of course on originated from the same original species and might retain different aspects of us. However, you can also make a very scary scenario where there are things that we care about evolve of it. Nick Bostrom has this very disturbing paper about some post human futures that essentially devoid of value. So in one of them, the mindless outsources, basically people exist in an uploaded form and a or outsourcing more and more of the brains. And in the end there are no minds anymore.</p> <p>Anders Sandberg:</p> <p>It's just an economy growing endlessly, but there is nobody at home. So the interesting thing here is where does the value come from? And this is of course again the deep rabbit hole, but I think it's worth recognizing that rabbit hole and kind of orbit around it at a safe distance. Out of that as we normally do, we think, oh, the conscious and sentient seems to matter. Probably if consciousness is lost, then we've probably lost all of the battle. I'm willing to argue that maybe that's not all there is. Maybe there are unconscious systems that are valuable lives too. But that gets me into a big argument with the philosophy department. We can also say that some of our human nature might be valuable just because it is a human nature. We might not care about some famous paintings in a museum, but they're famous paintings that we should preserve because they're part of our process just as well as some of the horrors of our historical past.</p> <p>Anders Sandberg:</p> <p>We should never forget about them, not just because we want to learn not to do it again. But even that we think that if we were to forget about it, all the people that died in that particular horror would in some sense are loss of it. There is a fair bit of interesting arguments in philosophy about this. There is a book here by so Summer Schaeffler Why Worry About Future Generations, which I found very fond because he's taking a non-consequentialist view about why we should care about humanity's future. And I find that really weird because I'm typically just thinking about what are the consequences. And it points out that you can actually love humanity. We can actually see there are things about humanity and its nature, that we love works in all and the we want this to go on. So I think there's going to be a thick bundle in that black hole of what really makes life worth living but matters.</p> <p>Anders Sandberg:</p> <p>And it might be that we need to hedge our bets. We don't really know whether it is our human-ness or our consciousness or the fact that we originated on this planet or just that we experience happiness. Maybe we want to have it all we want that Cambrian explosion because it gives us a good chance of having.. I would love to have a future that has both the brain emulation people and biological people as an existential risk backup. If it was just one of them, I think we would actually be in big risk and we might have missed out on true values. It might turn out, that just like consciousness might have added a profound new value to the entire universe. That might be the next step as a conciousnes prime, which is even more important. It's unfortunate. No kind of matter in the current universe got that.</p> <p>Anders Sandberg:</p> <p>You need to be maybe a brain emulation or come quantum computer or whatever to actually experiancing his study. And then to get on the other side of this and say, yeah, back then of course those poor Precambrian humans...</p> <p>Randal Koene:</p> <p>They didn't have this thing. And it might not even be, it might not even be something like the next level of conscious. It could be something completely separate from that. Something that we also think it's super valuable but has nothing to do with consciousness.</p> <p>Anders Sandberg:</p> <p>Yeah. But to some degree, expanding the circle to encompass bigger, bigger sets seem to be a good idea. So one of my common amalies... ...they might say, well, given the capabilities of those post apes, they call them humans, they could get a lot of bananas. And the apes would say, yeah, that's great bananas are good. And indeed, we are really good at getting bananas. We can get more bananas than any ape could imagine by planting them and doing other things. It's just that we're getting constantly sidetracked from the pursuit of bananas and sex, by also doing philosophy and technology and politics and art and sports. And we would try to say to these apes, well actually you don't know what you're missing out on. Actually science is pretty awesome and post humans or these quantum consciousness, prime whatevers, they might say, Oh yes, philosophy and science they're so cute, there a very nice part of life. We of course got these other things that you can't even imagine that's okay, that we do like our bananas.</p> <p>Anders Sandberg:</p> <p>The thing is, if we retained some course and they might be somewhat silly, things like bananas that might also be a continuity that means we care about our future. I think one of the big fears people have is what you get this disruption. There is humans post humans and there is no similarity whatsoever. This is part of the fear we have of AGI because we might make something that's utterly dissimilar from us and we actually don't have any way of telling them about what values we have and the like. When it comes to brain emulation, I always felt that we are much closer. We at least starting out very similar. Then might go off in different directions, but I think we have a good start.</p> <p>Randal Koene:</p> <p>We start with whole brain emulation. We know that whatever you've got there begins with something that is very human. And so whatever these values are that we care about, they're probably contained in there somewhere. Although it'd be great if we can explore the value thing. Not right now, but if that gets explored further and, we can't make a prediction here. Are we going to solve the problem of what are the values we want to preserve in five years, 10 years? Where's our deadline here?</p> <p>Anders Sandberg:</p> <p>Yeah. In some sense, doing philosophy with a deadline. I think that's a new thing that Nick Mastroni draws. And I think it's important to realize that there are some deep philosophical problems that maybe we can't solve, but I think we should try to do practical progress on the handling them because they're actually becoming action relevant. And in some cases that progress might just be okay, we need to do more hedging because we will not figure it out before the time's up. But, well, that trade, the moral hedging are impossible things so they can be quite powerful.</p> <p>Randal Koene:</p> <p>Indeed. So I've kept you on this now for quite a long time so it's probably time for me to sort of bring it to a close. But before we do, and I have a concluding question for you, but even before I ask my concluding question, I wanted to know if you think that there was something important or relevant that we haven't touched upon, haven't covered that you think should be mentioned here.</p> <p>Anders Sandberg:</p> <p>I think the core issue I have is, we have been talking about many things that have been around the community for a long while. Some of it we have written a bit of papers about, but it's very little. I think there's more work to be done there. Some of that might be done by neuroscientists and philosophers. I think there's quite a lot of room for interesting joint work here. Trying to turn this a little bit more rigorous, maybe measure what does the flow of ideas between different sciences that's interesting on its own. You can make a good academic paper out of it, but it might also tell us a little bit about the safety issues. I think we need to work a lot more on, can we do safety for neuro-morphic computing. Right now a lot of safety work tends to assume is platonic computer's running a little black boxes on white boards. And that might be good to prove some things about what we might want to figure out other ways of doing AI safety and machine safety. So, there's lots of things to work on here.</p> <p>Randal Koene:</p> <p>All these questions about values and what values we're trying to preserve and therefore what a good outcome is; that's really part of that, isn't it?</p> <p>Anders Sandberg:</p> <p>Yeah. And some of that of course is traditional philosophy. There is even a branch of ethics axiology the philosophy of value itself. But I think also we have found that there are orbital frontal cortex does have value representations and we're actually figuring out non trivial things. Both from addiction research and the scanning of brains when we make choices about how we do evaluations and how we function. I think there's a lot of room to do empirical research here, but might actually give a good kick to the traditional philosophy to see it in new ways. I think we have seen a rekindling of interest in ethics in many parts of philosophy because of AI Safety research because it actually forces philosophers to try to formulate, can I make my ethical systems something that could run on a computer and most traditional systems are absolutely impossible and to the first to the final will have to acomodate computation deamnds. And then we can start asking, so what is a moral system that actually can run on a brain or a computer and that waters the philosophical import of that.</p> <p>Randal Koene:</p> <p>So you do think that at some point we will have answers to all these questions or do you think it's just going to be a situation where we become progressively more aware of what all the detailed questions are and we just kind of lay out all the questions and we sort of swim in them?</p> <p>Anders Sandberg:</p> <p>Well philosophy is interesting because many scientists try to advance, we try to move forward, but in philosophy tends to try to dig deeper instead. And sometimes that's the right choice. But in many practical case we want to move forward. I have in my, I'm writing a book about the longterm future and I actually right now I have a very loose calculation. Given that we haven't solved these problems yet. What's the likely time until philosophy solves them if we believe there is a Pareto distribution of problem difficulty and they ended up with something like maybe it's going to take 10 to the 20 philosopher years before we figure out what it's all about. That's alot. It might be faster if we have better computers, but it might turn out that actually it's going to be far in the future when finalism super-super-post-human kind of goes, Oh, that's kinda makes sense.</p> <p>Randal Koene:</p> <p>Isn't it interesting how the Hitchhiker's guide to the galaxy already predicted this? 42?</p> <p>Anders Sandberg:</p> <p>Yeah. Again, it made a very good point. You need to understand the question really well then the answer is typically quite easy. So one of the interesting things about this interplay between philosophy and science and practical engineering is that quite a lot of time you get these practical issues that forced you to refine your deep philosophical question. I think we're going to find eventually, that axiology probably get old because we actually do a lot of neuroscience and then that forces philosophers to think in a different way.</p> <p>Randal Koene:</p> <p>Okay, awesome. So concluding this my last question, what do you think that, I mean, this is again an impossibly complex question, but what do you think that humanity should be doing or how should it change how it approaches problems compared with what we're doing today to maximize our long-term chances for both survival and thriving as a society.</p> <p>Anders Sandberg:</p> <p>So I do think we need to find ways of aiming at an open ended future, but that doesn't necessarily mean everything is possible. We might want to cut off disastrous possibilities. We want to avoid existential risk. And in order to do that, we probably need better tools for insight and coordination. So right now it might seem that we are in this world of fake news and international chaos. We're doing really badly about it, but compared to a century ago or two centuries, the United Nations is a really hopeless organization. But two centuries ago it was unthinkable what getting all nations together without weapons and actually agreeing on at least a few things in 200 years we might actually be able to do something much better. Similarly, yeah, we have a lot of problems with fake news, but we also got things like Wikipedia, which is kind of an early stab at creating a common knowledge base.</p> <p>Anders Sandberg:</p> <p>Again, that was the first step. And this is probably not going to be the last, or the best. So I do think that we can work quite hard on improving this insight and coordination of things. Better filtering mechanisms of separating true and false information. Which includes of course science, the replication crisis in a specialist iconic, demonstrates that we need to work quite a bit on building a better engine of scientific knowledge. But even the problems we have in the data mine, the scientific papers and tried to run that to do medical diagnosis turns out into trouble because many papers are so bad. We need better ways of doing this and those tools are useful in a lot of domains. We might want to have a better chance of tracking our own future. We might want to find ways of having these courses at work better.</p> <p>Anders Sandberg:</p> <p>It's a gradual thing and there's going to be alot of struggle to get there. Similarly, the coordination in the long run, we need to coordinate before we start scattering across the universe have become too incomprehensible for each other. And too far course removed before that we might actually need to have a big meeting and decide, okay, this is what we're going to do longterm with the universe. This is how we go to hedge our moral bet. This is how we're going to move the galaxies and making sure that it stays in the right.</p> <p>Randal Koene:</p> <p>Is that a meeting the FHI is going to have in 2021?</p> <p>Anders Sandberg:</p> <p>Let's hope for something like that. So the origional ideas Will Macaskill talks about the long reflection, but maybe once we got to interact together, we should just sit down and as a species and maybe spend 1000 years debating what to do just to get it really right.</p> <p>Anders Sandberg:</p> <p>Right now, this sounds absurdly utopia. This sounds totally crazy. But then again, so did the United Nations once upon a time. So we should start working on making the tools to make the tools to make the tools to make good insights and good decision making. And of course, making sure that we don't go extinct while doing this. We should never let the perfect be the enemy of the good.</p> <p>Randal Koene:</p> <p>That can be difficult sometimes. On a more personal note. Given all of the things we just talked about and there's so much more of course. How do you deal with the fact that this is such an overwhelming pile of stuff? I mean, how do you tackle that or just like go at it and still feel that there is good purpose and moving forward every day.</p> <p>Anders Sandberg:</p> <p>So the problem is not finding purpose because there are so many interesting and important things to work on. It's rather how do I choose the most important thing to focus on? I'm lousy at that. I'm basically an academic magpie. I see something shiny and I go for it. So over the past one and a half years, I've been somewhat focused because I'd be working on my book about what I called Grand Futures. And it's broad enough that it actually allows me to, whenever I get distracted, I just write another part of the book. That is one way of doing it. I have colleagues who are way more focused. They sit down and they think very careful about what matters. Spend even more times checking that it really matters and then they start working on it and I think we can again like hedging bets you hedge yourself by having people give the different strategies and then sometimes we compare notes and see, oh, that seems to be something I should be doing.</p> <p>Randal Koene:</p> <p>Okay. That's really good advice. Yeah, there are some different strategies there. Okay, fantastic. Thank you very much. Fantastic conversation. I have to say. Yeah, like always.</p> <p>Anders Sandberg:</p> <p>Well we should keep it up, make sure that the future continues to have great conversations until the end of time.</p> <p>Randal Koene:</p> <p>Oh yeah. And you'll be welcomed back at the Carboncopies Foundation again and again for sure.</p> <p>Anders Sandberg:</p> <p>Thank you so much. Yeah. Cheers!</p> <p>Randal Koene:</p> <p>Okay. Stop the recording now.</p> <p>Randal Koene:</p> <p>Not hearing you at the moment. I don't know if you can hear me.</p> <p>Allen Sulzen:</p> <p>You are audible, Randall Mallory is not,</p> <p>Randal Koene:</p> <p>That was really awesome to hear Anders talk again. He's always a fantastic speaker. No matter what the context. I wish we had a way to really do claps online. Maybe we need a canned clapping or something. And then whenever appropriate we'll turn that down to a slow clap or something.</p> <p>Allen Sulzen:</p> <p>We're downloading a clap track now.</p> <p>Randal Koene:</p> <p>Okay.</p> <p>Allen Sulzen:</p> <p>I'm just checking.</p> <p>Randal Koene:</p> <p>Okay. Maybe then Mallory has a more serious problem with her mic at the moment. So many technical things because everything depends on so many little bits and pieces. Is the Bluetooth working, are the batteries still charged and all that sort of stuff. And in my case, the Internet drops out every once in a while, so that's not great either. We have heard from Anders recently about 27 minutes ago, he said that he was 30 minutes out, so maybe he'll be here in three minutes if we're lucky or maybe it takes a little bit longer to get off of his bus and get into his house and get all set up. That's all possible. So in the meantime, we can start addressing some of the questions that came in a while... Oh, here's Anders. Then we don't even need a meantime. We can just go straight at it. Hello Andrers. You must have just come in the door and sat down basically, right?</p> <p>Anders Sandberg:</p> <p>Yup. Literally. Yup. Just ran in from the bus, then got home.</p> <p>Randal Koene:</p> <p>Okay, well Kudos to you for being able to do that. We all just listened to the interview and as usual you're fantastic. The way you present everything is so clear because unlike me, where I go into abstracts very quickly, you tend to bring everything back down to examples that people can really get into and dig into. Like, AI that is helping a little old ladies across the street and things like that. So that's perfect and I think we also got a bunch of good questions here and I see Mallory just poped up again.</p> <p>Mallory Tackett:</p> <p>So where did we leave off after I joined? Are we going to start with our first question?</p> <p>Randal Koene:</p> <p>You can go ahead with whichever question you want. Anders is here.</p> <p>Mallory Tackett:</p> <p>All right. And just to remind everybody, you can ask your questions in the YouTube live stream chat or you can call into call.carboncopies.org or the number (415) 455-3017. The first question that we have is from Roman Sitlou, even today there are some people who are both capable of recursive self improvement, like adopting the new mind enhancing technology and have strong misanthropic tendencies. Basically in a way their biological non-friendly AGIs what can we do about this scenario?</p> <p>Anders Sandberg:</p> <p>I think we actually have a surprising amount of good tools at our disposal. After all, one reason we behave ourselves is because our mothers told us various things that we should be doing and that's a foremost social software. We have other forms of social software we get when the get enculturated as well as police reputation various force of market solutions and many of these things constrain us to a tremendous degree. Then of course if you try to do recursive self improvement through enhancement today, it's quite limited. No amount of smart drugs or meditation and or getting the best apps are going to make you tremendously more effective than just somebody who is really smart or specialized. And you're not going to exactly be deep blue either without having a computer on your side.</p> <p>Anders Sandberg:</p> <p>But the deep part of the question is how do we handle when it becomes easier to make our full individual minds? And I think in general we do that by having a lot of minds, but they partialy constrain each other and systems of minds because generaly systems of minds are much more powerful than individuals. So to just take a little parable here. We have the earliest youth conciousness interesting AI Boxing experiments. Where we practically demonstrate actually convincing people to let out the possibly on friendly AI out of a box was pretty doable. If you're smart enough and Glib enough, you can talk your way out. This is impressive except why don't prisoners do this all the time? Why don't we see more prisoners talking the way out of prison? And the answer is of course, well quite often we talk their way past one or the prison wards, but there are others, there is a system or a career. So being prison chief and the warden, that all dependand on prisoners not talking their way out too much. And that actually makes actual prisons surprisingly effective in keeping even the most clever prisoners in. Not perfect, but quite well. So I do think we can do the same kind of system and system management. It's not like we want to only upload the saints, so we don't even have a good definition of sainthood, and maybe the saints won't stay saints once they're in the computer either. But you don't want to have just one mind.</p> <p>Mallory Tackett:</p> <p>Great. Does anyone want to add to that or shall we move onto the next question?</p> <p>Randal Koene:</p> <p>I think Anders pretty much answered the whole question unless you wanted to dig into the detailing that Roman did when he pointed out, people who want to self improve may already feel that they are perfectly fine and eliminating a huge part of humanity in the future or something like that. If you could restate that properly.</p> <p>Mallory Tackett:</p> <p>Or Mallory, sorry, maybe I didn't make myself clear. I thought you could maybe...</p> <p>Anders Sandberg:</p> <p>Or I could just get at what I think that question in emboldens. So really ruthless sociopaths and people think that the world would be better off with just me around certainly psychological exist. The vast majority of them are not very good at doing anything because by virtue of being so misanthropic and sociopathic may rarely can acquire the resources. I think the intuition we have is, oh, what if they take a technological means, that pill that just makes you essentially god like, at that point we will be in trouble if it goes there. The problem is they're probably not first in the queue. The real problem might of course still be the scenario where you have successful sociopaths, successful misanthropes or who just ran into a lot of resources and they will be getting power. But again, the question is why aren't particular billionaires wiping out everybody else and running the kingdom?</p> <p>Anders Sandberg:</p> <p>Well, to some degree they still need other people. But even there you can actually replace people with consultancies, et cetera. The actual problem is of course societies in order to remain rich and functional are quite complex. You can't actually run all the parts. So the people who just introduce in every wealth and power, they are relatively sane and my scorch society in other ways. So the only case that we need to be worried about is really misanthropic person who gets very powerful. But I do think the scaling of power isn't in favor of us. Once upon a time Metachip family, they were wealthier than essentially the principality they were run. They were rivaling the nations in European of wealth and power, but meanwhile they weren't perfect. But the United States is, harder for rich people order organizations or people like state, actualy it has become weaker. So I'm much more worried about misanthropic and crazy states and the institutions then individual misanthropic people.</p> <p>Mallory Tackett:</p> <p>I think that answers the question pretty well. The next question that we have is from Jaysa RC. What do you think about the human habit of comparing ourselves to the technology we create for ourselves or our tendency to humanize things even if they're a robot or an artificial intelligence?</p> <p>Anders Sandberg:</p> <p>Yeah, so one of the main reasons people make robots, is of course they actually like to use humanize technology. If you think about much of the Japanese mindset about robots, it's important to have a social relationship to technology. And certainly they also believe that we have social relationships even to non-human technology. But if it has a face and it's easy to interact with it's more manageable. And I think that this gets to something important. We humans have... This sometimes leads us to think about things in the wrong way. When lightning strikes, we wonder who is angry and come up with a story about somebody must be angry with somebody or some reasons to course lightning. But on the other hand we use this to do intuitive physics.</p> <p>Anders Sandberg:</p> <p>So it's very natural for us to try to make these kind of machines and put in a lot of anthropology modification, into them. And we also of course tend to assume that if something with a face or talks back to us must be part of the human world. Which is why it's so easy to have a chat bot. And this is why people fail in the Turing test all the time. But then there's opposite thing. By trying to make artificial intelligence, it's also a mirror. It's a great way of trying to understand ourselves, what we are, what we mean by thinking and feeling and what aspects we care about, but also what we fear a lot of worries about artificial intelligence or our own projections. But what if we made something like us? And I think that's the first level of worry. I'm not so concerned about that myself because I think the second that being told them there alien and hence conspiracy theorists. But you should look miss the fact that they are deeply human.</p> <p>Mallory Tackett:</p> <p>Great. Does anyone want to add to that?</p> <p>Randal Koene:</p> <p>Yeah, just a quick note, which is this point that you made at the end about more worried about things that are more alien. This kind of comes back to that bit about, worrying about corporations or something like that that are very powerful because in a sense, these are also alien because they have different way of making decisions. They're way more focused on what we might call utility function, which is the bottom line and the quarterly results and that sort of thing. So they can be very sociopathic in that sense and very powerful at the same time. So I think you're absolutely right to focus there first before worrying about the individual person in a sense. So yeah, that kind of jumped back, but I guess that's okay.</p> <p>Randal Koene:</p> <p>Oh, quickly before someone else answers something. I just want to point out that while there are lots of good questions coming in and there's way we're going to be able to address every question in the time we have on the panel. We are collecting all these questions and as we see good questions there, we're still going to work on them later on. You may find them in transcripts or another work that we do. You can still contact us about them through questions@carboncopies.org and we can get back to you.</p> <p>Mallory Tackett:</p> <p>I think I can move on to the next question now. Our next question is from Jan Clok or Yon Clok. and he says, \"While initial collaboration may be nice, competition like the US versus China,\" and I'm assuming he's referring to our competition with artificial intelligence. That's probably the most prominent one, \"is that competition is going to stay? How do we utilize that for whole brain emulation and artificial general intelligence development and keep it safe?\"</p> <p>Anders Sandberg:</p> <p>So the first thing worth mentioning is of course many of assumptions that we are, let's say US versus China in a competitive race might actually be because humans like to project their human moods and feelings onto these alien things like nations. We are fairly competitive and you can totally think of international politics as kind of the school yard bully going around. And we quite often construct it that way because it allows us to think about it in the easy ways and of course a lot of people involved actually like to think about. It's just that in practice governments or disjointed entities with different goals and different parts of government. And you can imagine for example a competitive situation on the artificial inteligence in China and the US, that involves total sharing of safety information and I think that is something we should be pushing very strongly for.</p> <p>Anders Sandberg:</p> <p>Even if people think that this is a strategic technology and it might even be important to be first, it should also be a no brainer that it's also important to have a world to be first in. So maybe we should be also shairing as much as possible on the safety technology. This actually happened during the Cold War between the US and the Soviet Union, where the US deliberately shared some technologies for keeping nuclear weapons safer, simply because that would be in the interest of everybody to have it. It didn't always work out as diplomatic as it should, but it was definitely a good try. When you want to use competition to do something good, typically it is this concept of creative destruction or let a thousand flowers bloom and so on that you allow a lot of diversity and then that competition will hopefully bring forward interesting things that you can note is interesting and useful that can be replicated.</p> <p>Anders Sandberg:</p> <p>And this is of course typically why market economists do so well when compared to a planed economy because they can find new solutions rather than trying to optimize for an obvious one. But when it comes to research, this is extra important because in most fields the amount of progress you make is a very complex curve of amount of efforts you put in. So in the earlier era, you need to get a lot of rapid progress, but you don't know what you need to work on. You need to map out the field, you need to do a lot of experimentation. But you can also learn a lot of things. Eventually it's time to bring out the big super computers and the big collaborations. But first we need to solve a local small step. And that's a great thing to actually have dispersed between not just different teams, but also different mindsets and approaches. If everybody tries to achieve brain emulation or AI in the exact same way, the probability of it succeeding goes down quite a bit, which may be good for safety work in the background. But by the same token, we want to have a pretty big diversity of safety mechanisms explored before we notice which one seems promising enough that we should be starting to pile on and boost to their abilities.</p> <p>Randal Koene:</p> <p>Wow. I think first of all, hat it's worth pointing out that what the person who was asking the question is talking about, it may also be something a little deeper. It could be just, not specifically about how people working on AI should work? Should they compete or should they cooperate? But also just this fact that the competition is sort of a natural thing that just emerges from there being differences between things and then the selection mechanisms that apply. So you see that in evolution too, of course. And in evolution you have differences in DNA through some genetic mutation and then one of them works out better than the other. And that's a kind of competition, even if it wasn't intended to be a competition. And the same could be true, you could say that even for a single AI that is trying to improve itself as it's trying out different algorithms, those algorithms are competing on some kind of performance criteria.</p> <p>Randal Koene:</p> <p>So there's a competition going on there. So you're always going to have within the ecosystem of all the things that are going on, you're going to have both competition and cooperation because cooperation is often a strategy that helps, that enhances what any single thing can accomplish. They, for instance, the cooperation between different algorithms to have two different ways to detect people in a scene instead of just one way to detect people in a scene. So you've got both collaboration and cooperation going on at both times. And then what Yan was asking. It could be interpreted as, since there's always going to be both collaboration and cooperation and it's really hard to weed out and to say we should all be working collaboratively on the same AI here or something like that. How can you ever make sure that's going to be safe? Because any actor who happens to be slightly less cooperative may get an edge because of that. Right. And I was going to go further with this, but I think I've already brought enough new stuff in here. Anders, do you want to say something about that?</p> <p>Anders Sandberg:</p> <p>I'm reminded of something that Eric Drexler rote somewhere in one of his old papers, I think it was his algorics papers that he wrote somewhere in the late eighties, and he pointed out that we often talk about how wonderful it is in nature with all this simbyosis and all of his harmonious cycles. While human business, oh, it's a red in tooth and claw. It's all about competition. But he pointed out that actually the reason that we hear about the crimes and when people betray each other in politics or in business is that it's rare. It's very unlikely that you get robbed by gunpoint by your grocer. Most of the time you will just to get groceries and pay for them. Most economic transactions or extremely cooperative. We tend to notice a difference. Similarly nature, actually an awful lot of interactions are fairly adversary. And then we get very in the rosy about all these wonderful cooperation we notice.</p> <p>Anders Sandberg:</p> <p>So many systems and different styles and biases. Now the reason human economies work so well from a comparative standpoint, is that we have a lot of tools to enable us to do that. It's much easier to negotiate if you've got the brain and the language. It's way harder for the different plants and animals in the forest and find some nice equilibrium. I do think the real question is can you then set up the rules or the agent so we naturally generally tend to be cold. So the rewards in academia reward you for trying to be first with a cool paper that the, it's a competitive thing, but you also need to tell everybody how you did it and everybody gets to comment on it and that you actually develop this cooperative, effective. True it enduces some sense competition, but it also helps truthful and useful papers get ahead. And that we might say, well maybe we should set up the incentives for AI and brain emulation research so we do this.</p> <p>Anders Sandberg:</p> <p>Right now it might be that a brain emulation research is mostly an academic pursuit subject to the same quirks, but normal academic competition and the corporation are, for example, a lot of the competition is relatively weak, but you also don't have strong incentives actually get something that works because you can always write more papers about approaching something that works well in the industry. Making something that works, it's actually a really good idea because you make money, otherwise your company's not going to be around. So we might want to investigate this more deeply. I'm not a good enough economist, but I think there's this area of mechanism construction that people have done in game theory that would be very valuable here to try to see could we find some new ways of setting up corporate and collaborations or competitive races.</p> <p>Anders Sandberg:</p> <p>The Human Genome Project after all was leisurely developing technology and getting somewhere, but at a slow pace and then Ann Craig went there, stormed in and forced everybody to rush because of a competitive impulse but also actually pushed things to build in that phase where you want to get results. And then we took the genomes and most of the genomes are not put in public databases and shared etc. The real competitive thing is figuring out the meanings of them. So you can also have layers of competition and collaboration and we might want to look at at what layers do we think is the biggest risk of a bad accident would be a headache. Let's see if we can make sure that one is strongly in their corporate team, which of course includes also, yeah. Other people thinking about, oh, that guy is trying to mess up. And the good thing we got going here, we're going to have to ally against, which is another decent incenive for being alies.</p> <p>Randal Koene:</p> <p>There's an interesting way that this bridges way back to almost the beginning of the workshop where one of our callers Leslie Seymour was asking about security protocols and we kind of got to the point where there was some agreement around, yes there's a reason why everyone in the world coalesces around open standards and around, using the same open standards and protocols. Because that way you get a lot of people looking at it, making sure that all the holes get patched and all that sort of thing. But then at the same time, you were pointing out that it can be really useful, especially in these sorts of cases to have a lot of different approaches. Try out a lot of different things and come up with new, better approaches than used to be there. You have to break out of the box from time to time. And so it begins to seem like it's very handy to have competition inside a sandbox where you have your peer review and then ultimately to have collaboration and cooperation and standards outside of the sandbox whenever you can accomplish that.</p> <p>Anders Sandberg:</p> <p>Yeah. I completely agree and being good at designing sandboxes. I think that is a fantastic thing to work towards.</p> <p>Randal Koene:</p> <p>So Mallory, did you want me to go ahead and ask a question that I had written down or did you want to go with another one of those? I see that you've got another by Abulfazl for instance, and there's one by Justice.</p> <p>Mallory Tackett:</p> <p>Yes. So we do have one from Justice. I'm going to ask that one. \"If brain emulations were developed as open source software and posted on the Internet, ala Bitcoin. What hope is there to effectively control them?\"</p> <p>Anders Sandberg:</p> <p>That depends very much on what resources it takes to run it. So you might look at the current debate about open sourcing AI tools. So if Google amounts a very nice AI algorithm or at least a machine learning algorithm today, in many ways they're not losing much of a competitive advantage because you typically need a Google data center and an enormous amount of data to train it. So even though we amatures and academics can sit around and read algorithms and try to tweak something, we can never turn it into a production system. It wouldn't surprise me at all. But the actual code for running a brain emulation, is going to be a somewhat messy computation neuroscience system, whether it's with a virtual reality system and a lot of data management, nothing too weird. Everybody can download it from Git Hub. It might also be that we can download a few preacher in neural network for from some mice, some monkey and maybe some human volunteer who is very willing to be everywhere. But that doesn't mean that you get the full power of being able to scan my brain for example because scanning a brain is going to require hardware of some kind and quite often also the knowledge on how to use that hardware, which is sometimes shockingly tricky to transfer.</p> <p>Anders Sandberg:</p> <p>Anybody who's been hanging around the experimental biology has kind of noticed that they're very skills that some people seem to have and others don't and generally of course in science we try to figure out ways of automating that so we get rid of it. But there is still always, especially the early days of MIA Technology, a lot of requirements there. I do think that open source is useful for checking code and improving code, but it doesn't give you the capability necessarily to round it. If we use it to its fullest, but this might depend of course quite a lot on which scenario we have. If we end up with a scenario where the code is relatively easy but getting computer power hard, you get monopolies of computer power and it might also be that we start up with small simulations and get better and better, but that means that many people can tool around with it a little bit crude simulation on the computer we get the better societal debate.</p> <p>Anders Sandberg:</p> <p>On the other hand, if we have more overhang scenario where the code has been around forever and then finally somebody does a bug fix and now it works with those pre in and scan, brains that have been staying around in Git Hub for decades, then things get really weird. Then you have not just an overhanging maybe of hardware and the scans, but also the overhang off the accessible code. I don't think it's necessarily that likely, but it's worth looking into. Another thing that Peter did in our paper Risks of Brain Emulation was to worry about computer security aspects. If brain emulations are bad at security. If it's easy to hack your server running various minds, then we have an enormous problem. So we might want to think about how do we make that code so it's really robust. This is why we might want security on the code and make sure it's actually quite open source and people have been spending a lot of time finding the flaws.</p> <p>Mallory Tackett:</p> <p>All right, thank you for that. Next we have a question from actually one of our panelists. Abulfazl. He asks, can you elaborate on the idea that uploaded minds or whole brain emulations are not as dangerous as AGI or artificial general intelligence is if that's the case, why is that?</p> <p>Anders Sandberg:</p> <p>So this is still the intuition which is based partially on that distinction between what about human like versus alien entities. So there's this cliche idea about the robot uprising as the robot fields oppressed, they rise up against the oppressors, the humans. And that's after all what the human would do in the same situation. Feeling oppressed and desiring freedom is a very human thing. Which is why humans love reading stories about robot rebellion. Of course, if you actually get that kind of robot rebelion your have basically made humans tin cans and first of all you probably should give them rights and second you have succeeded very well in making a relatively safe AI because you can probably reason with them. You could imagine however the serious problems that happened when you have something much more alien, and this is of course the line of reasoning that has emerged from the work of Aleas Ukofski and Nick, but actually in general if you try to optimize for something, you willoptimize for that thing and ignore most other parameters.</p> <p>Anders Sandberg:</p> <p>This is a favorite argument by Stuart Russell, but if you make very intelligent systems, so the powerful optimizers and tell them to make one thing, all the other values in the world, even if they are somewhat similar to our mind will fall to the wayside. This makes him quite dangerous. And then you can elaborate of course in all sorts of interesting cases of how this might be that is driving a fair bit of the research on how to make safe super intelegence. Now the intuition is of course if you managed to make a brain emulation you basically got the original person. If everything worked out well with the same quirks and flaws and moral failings, and moral virtues that's original. From one the hand that mind might not be saintly but it's certainly not going to turn the universe into paperclips just because somebody asks them to make paperclips. After awhile you can say, I'm tired of this. I want to develop my personal capacity or I want to sleep. Or actually I really think now a robot rebellion would be suitable. You're basically having to deal with a human. We can certainly channel humans to build organizations that are scary and dangerous, but it seems like we don't get those inhuman falures. We don't get the papercliper that just mindlessly constructs paperclips in a paper clipping system. We don't get systems optimized for something totally valueless. Even if you enhance a human a lot, so they become more of a human, and I think has gone really wrong with some human values and goals. But there is this general idea in the study of the Ai Safety. Human values are fairly complex and fragile, so it's not enough to get most of the values in because if we've got about something on the list, whether that is forgiveness or love or vocational nature, is nice you get the world that gets optimized for everything but important things and it's actually quite dystopia.</p> <p>Anders Sandberg:</p> <p>Now the question is, is this argument right? Does this actually mean that brain emulations are safer than AGI and that is of course where people's views go in different directions. It might be what leads to relatively quickly to normal AI because we learn clever tools from neuroscience. It might be that brain emulations could rapidly evolve into something else. It might also be that our tools for keeping humans in line work really well for them. So that might benefit safety, but it might also be that we can prove safetyin other ways for more purely artificial system, we can morally do things to their minds and the science that you could not really morally do with brain emulation. So in that case, maybe you want to prefer it. So in the end, I think we need to actually write papers and analyze with more detail. I have, my probrain emulation view, but I'm not certain it's right. We need to investigate this much more deeply and find ways of formalizing these arguments.</p> <p>Randal Koene:</p> <p>Okay. I don't know if anyone has a comeback right away. But otherwise I can go ahead and ask my question, which I think relates to this in a sense. And it relates in the way that, well you just described, for instance, an example of why whole brain emulations may be safer because you're basically dealing with a person. They're not going to want to paperclip the universe because they want to do something else. He'll get bored after a while. But then I could come up with a scenario where I say, well, what if, what if, this is in Robin Hanson is universe, you're making whole brain emulations as your basic tool and you want to paperclip very well. And so you may change, or you may have gotten permission from the original owner of that brain, let's say, to make a little change so that the whole brain emulation no longer has that much of volition of their own and might just want to carry on making paperclips and all of a sudden you can come up with a dangerous scenario. And this leads into my question, which is really when we talk like this, it seems pretty easy, and I've heard this happen all the time from everyone who talks about AI safety basically, whether it's Nick Bostrom or Elon Musk or Eliezer or anyone, it seems very easy for every proposed system, security or otherwise every scheme to come up with some totally theoretical scenario where this breaks down and that makes it seem like AI safety is possibly a lost cause because no matter how you look at it, you know there's always going to be some system that escapes. And that's the end. So in other words, it seems like the probability of a given scenario seems very important to assess. And how would you do that?</p> <p>Anders Sandberg:</p> <p>That is a very good point. And I totally agree. Trying to kind of get perfection never works. In actual computer security and actual security engineering people think about swiss cheese solutions. You have a number of layers of security but they have holes in them like swiss cheese. But these are not aligned. The probability of something getting through holes in all the layers is low enough. And what can of course sort of arguing here about how low probability of a disaster is acceptable. I think that's an important guide point. But we need... So some risks I think are easier to formalize than others. So when you think about an artificial intelligence, you might be able to prove things about that if it's a really nicely well defined one. And at least put some bounds if you have a nice theory, let's say of machine learning reinforcement learning or what it's doing, that might give some possibilities to bounding it.</p> <p>Anders Sandberg:</p> <p>But it still sounds to me very much like what we would love to do with the computer science department and maybe it wouldn't actually correspond to anything realistic in terms of actual safety checking. So we might want to think here about safety testing, methods. There is a fair bit of that for actual software and the actual industrial systems. They're not perfect, but we might want to actually go and loot that literature for tools and start applying them to our own thinking. My general feeling is this is going to work well for technical stuff. I think we can do code audits and estimation of likelihood of certain neuron networks doing certain things, but on the other hand you have the human side. What's the probability of somebody agreeing to have a brain edited by weird actors? That's probably pretty high. I don't think we need to even try to estimate that there's always somebody, but what's the probability of us actors doing certain risky things?</p> <p>Anders Sandberg:</p> <p>Now we have a much harder time. There I think we need to apply a fair bit of judgment and essentially world knowledge. It's going to be way more uncertain. I think we have still some evidence that we can do not to bad probability estimates in some domains when we get feedback, you have Tetlock superforecasters for example they're interested in policy and world events. They're reading the newspaper, they're discussing with each other and if you put them together in the right way, you actually get surprisingly good for cost compared to the average one. Could we do the same thing as super safety forecasting? I'd never seen anything about it, but it might be actually worth pursuing.</p> <p>Randal Koene:</p> <p>Thank you.</p> <p>Mallory Tackett:</p> <p>So that concludes our Q and A section for Doctor Sanberg. Thank you so much for joining us.</p> <p>Anders Sandberg:</p> <p>Thank you.</p> <p>Mallory Tackett:</p> <p>Next we're going to be showing remarks that were prepared by Dr Ben Goertzel for this workshop. He has probably one of the most extensive resumes in research toward artificial general intelligence. Among other things he is the chief scientist at Hanson robotics, the chairman at the Open Cog Foundation and the chairman of the AGI conference series. So now I will show his remarks.</p> <p>Randal Koene:</p> <p>Just one quick thing. Anders, thank you so much for joining us. I realize that you're probably very tired from your flight, so I can understand if you can't make it all the way through, but if you can sort of glimpse at the screen from time to time and might still be around after Ben's contribution, that could be interesting because he sometimes takes kind of a opposite or contrarian view from...</p> <p>Anders Sandberg:</p> <p>Always. And that's the fun thing about him. I'm going to try to stay around. Cool.</p> <p>Mallory Tackett:</p> <p>All right. I'll get that started.</p> <p>Ben Goertzel:</p> <p>... my good friend Randal Koene was organizing a workshop on mind uploading, AGI, and brain-computer interface, all that good stuff.</p> <p>Ben Goertzel:</p> <p>I really wanted to participate, but...</p> <p>Mallory Tackett:</p> <p>Can anybody hear me now?</p> <p>Randal Koene:</p> <p>Yeah, we can hear you. We just lost the audio from the video for a second there.</p> <p>Mallory Tackett:</p> <p>Okay. Was it off for the whole video?</p> <p>Randal Koene:</p> <p>Most of it, yeah. Only the very beginning we heard him.</p> <p>Mallory Tackett:</p> <p>Okay, I'll go ahead and restart it then.</p> <p>Ben Goertzel:</p> <p>I heard that my good friend Randal Koene was organizing a workshop on mind uploading, AGI, and brain-computer interface, all that good stuff. I really wanted to participate, but being based in Hong Kong, it wasn't feasible for me to show up in person. So ask around, go to... Send me some of the key questions that he was interested in exploring in the event. I'd given a little bit of a video improvisation on the theme of his questions. Now, some of the questions Randal sent would take approximately 10,000 years to really go through and answer in detail. So I'm going to give some of them the short shrift, but better something than nothing. So here goes. First question from Randall, \"Could you tell us a little bit about how your thoughts on AI safety have evolved over time and where you stand today?\" Well, my thoughts on AI safety at base is the same as they've always been. I think there's a nonzero risk that as AI verges on AGI and artificial superintelligence, things that are very bad by our current human standards will happen.</p> <p>Ben Goertzel:</p> <p>I don't intuitively, emotionally feel the risk is extremely high. On the other hand, rationally I have to accept that we're in a situation of tremendous and probably irreducible uncertainty. We're taking a leap into the unknown. And that's not unlike what humanity has been doing since we stepped out in the African savanna and started developing civilization. We've been taking a huge leap into the unknown one time after the other since civilization began and probably before that. So, I guess for me the question is really how much do I trust my sort of inner spiritual, heart based intuition that the singularity is almost surely going to come out okay; and is in fact going to connect us with compassionate, benevolent aspects of the universe that we're currently, largely cut off from due to our mentalities. How much do I trust that intuition versus the more cold objective reasoning part of my mind which tells me we have no idea what the hell is going to happen. This is really the delemma that is realy on goingly wrestling with. And then maybe that process, that dialectic is it valuable, because certainly I wouldn't want to go entirely in the direction of following only my heart and not reasoning or entirely in the direction of just reasoning and not going with my intuition, which, can have a deeper insight than reasoning.</p> <p>Ben Goertzel:</p> <p>I would say one thing where my thoughts on AI safety have evolved in the last few years though is I'm getting a more concrete sense of what there is to be worried about regarding the rollout of nowhow throughout the world before we get to AGI. And I've been thinking more about what effect the species' knowhow that gets developed can have the type of AGI that comes about as knowhow verages into AGI. So specifically as I've been saying a lot recently that the core applications of knowhow in the world right now are selling, spying, and killing. I mean advertising, surveillance, and millitary. And if it does happen when the first AGIs evolve out of the knowhow as it would be built in the world today. What does that mean? Does it mean the first AGI is going to be involved with selling, spying and killing? I mean not necessarily, but that's at least something we want to consider. There is a related issue which has to do with the control of knowhow. And then they have to do with the control of AGI and it comes out of the narrow AI, which is how widespread, democratic, and participatory should the controlling of AI be versus how centralized and elitest should it be? And there's been alot of thinking in the world of safety of AI for a long time that it would be safer if no small handpicked crew of wise and rational AI safety gurus we're controlling the advent of AI as it turned from narrow AI to AGI.</p> <p>Ben Goertzel:</p> <p>There's another line of thinking which says that self appointed elites know what's best for everyone, often don't do as good a job as they thought they were going to do. And the failure modes of this are amply demonstrated throughout history. One of the good guys discovers a dark side within himself. The elites split into two groups, someone gets stolen away by competition. Humans who band together who no what's best for everyone, then pull the puppet strings of the brothers society... The track record isn't, isn't great. Right? And of course what's been tossing by some folks in the AI safety world was like an expert committee of wise singularitarians who were building an AGI in the basement and sculpting it's goal system to be beneficial and then releasing it in the world. What we're seeing now is more a move towards eliteist control of AI by some advertising corporations, and some large governments doing surveillance and military stuff. So we're getting this eliteist control, however the controllers are not who some of the elitist AI safety advocates might have wanted. Right? And to my mind, well of course a part of me can't help but think, well yeah, if I were just the one in control, if me and ten or twenty or 50 or my closest friends we're chugging all this out... We want the best for humanity and for a super-human AGIs. Right? And we've surveyed all the relevant areas of history and science and engineering and philosophy and we can probably make a better choice. Then the whole of humanity, which includes a whole lot of ideas that I think are totally whacked out. But then if I take a little bit deeper point of view, in the end, I don't think any small group of people is going to do a better job than the global brain of public humanity. And there are kinds of understanding and wisdom on the planet I've never heard of and never imagined. And if we want to really make the best possible AGI which are going to be the best possible super-intelligence we need to craft ways... The best odds of success seem to be if we can craft ways to really draw on the overall intelligence, intuition, and wisdom of the global brain of humanity and our computing and communication networks, not some small elite group, as fun as it would be to be part of the small elite team training the beneficial singularity. This is what has lead me in large parts of the singularity project that I'm now running that I founded it in 2017. What we're trying to do with singularity is to create a decentralized platform and then community for both narrow AI and AGIs so that all the AIs in the decentralized network of AIs and the AI programmers and the AI users can all in a participatory and democratic way control the evolution of that network. And if the singularity or something like it becomes a predominant way or even a really significant way AI is rolled out on the planet, then that's been the counter act to this eliteist tendency that we're seeing with a few large corporations and governments hiring most of the AI researchers, buying most of the AI startups, and sort of driving the AI agenda.</p> <p>Ben Goertzel:</p> <p>Randall's, next question, \"What would you consider a worst case scenario for AGI? What's the best case scenario? What's the likely outcome?\" Well, worst case scenario, we probably can't even imagine, but how about some some crazy Christian maniac Mind-uploads all of humanity into a simulation of the Christian Hell and just burns your simulated clones until the end of the universe. That would be pretty bad. We could come up with worse. Best is utopia and of course I could take a lot of forms, but what I'd like do is form myself into multiple persons, let one of them mind-upload into the global super intelligent mind matrix of the multiversal super-intelligence mind matrix and then let another one of then stay in roughly human form an upgrad itself progressively so it can be an even better and greater human than is possible in the scope of legacy humanity.</p> <p>Ben Goertzel:</p> <p>Of course, when you really think about that, what's funny is from the stand point of the form of me that remains human, when I still have a form that merges with the super-intelligent mind matrix, it would be like, okay, that form of mine has been created. I'll wait, now in the last one second, it's experienced 10 trillion times more things then I ever will be able to, and it's evolving something totally uncomprehensible to me. So there, that's nice that I've spawned that super-integelent mind child. Now, I'll go on being being human. So there's going to be a discontinuity between forms if me that embraces the singularity for long and becames massively super intelligent verses the form fo me that remaines in the human form. But I would like to see everyone able to form themselves however they want and make many copies of themselves and explore different reasons of mind space and this lets each mind explore a variety of different types of realities that are utopic in it's own perspective and this is quite feasible. It may even be the most likely outcome, but we don't really have the basis to fully ration the estimate, the probabilities. I think we can work toward increasing the probabilities of beneficial outcomes like this in a number of ways. One is the AIs that we're creating right now what are going to grow into the AGI. Maybe that would be just in the future, we should be using these AIs to do benefitial things like cure disease, you know, teach children, improve people's states of consciousness, discover science. We've got to take the bulk of AI away from selling spying and killing. Iwould like to eliminate these things, human society and human psychology being what they are, but they don't need to be the preponderance of what AI is used and developed for. That's probably the most important thing we can do now to move the odds of utopic rathar than distopia or mediocre outcomes in a positive direction.</p> <p>Ben Goertzel:</p> <p>Next Randal asked, \"What about Nick Bostrom's book Superintelligence.\" I read a review of that consequencial intelegence fears from Susan Potentials two years ago. My veiw of Nick's book now is about the same as it was when he wrote that review. I love Nick Bostrom worked together in that World Transhumanist Association years ago. We organized the conference together. Bostrom, I think you're a really fun creative guy. I think the book Super Intelligence is a brilliant example of argumentative rethoric. It reads like he was the captain of the high school debate team or something, so it makes a rigorous, powerful argument that super intelligence doing thing to humans we consider nasty like anihilating all humans is possible and that these bad outcomes of super-intelegence have odds of greater than zero. Zero. But then the book often talks as if its tone and its informal statements, it talks as it been argued that bad outcomes from super-intelegence are likely but that was ever demonstrated.</p> <p>Ben Goertzel:</p> <p>All that was demonstrated is that the probability is somewhere above zero. So yeah, of course the probability is somewhere above zero, that superintelligence will kill everyone, but Bostrom didn't demonstrate that it was probable and no one has demonstrated that. On the other hand, I haven't demonstrated that it's highly unlikely that super intelligence will do bad things either from a rational point of view we just don't know, are leading into the leaping into the great unknown. But then Nick Bostrom in that book at least really champions a sort of elitist point of view and at some point in the book he's sort of exploring the idea. You could even have one Genious AI researcher working on AGI protected by the auspices of the United Nations and maybe that will be the safest way to do things. I'm like exact opposite of that. I think we want a tremendous amount of brilliant AI and AGI researchers all around the globe with many different points of view collaborating and I want a decentralized network coordinating this in a self organized democratic and participatory way. Certainly not the UN, which can't even handle far, far simpler tasks than coordinating the birth of of general intelligence. Those are the first few questions from Randal.</p> <p>Ben Goertzel:</p> <p>This is part two of the video in which I give some rambling improvised one in the morning type answers to some questions posed by my friend by Randal Koene as part of the Carboncopies workshop on mind uploading and computer-brain interface, AGI, and so forth, which was held in the part of the world far away from me. So, in light of not showing up and rambling semi-coherent coherently at the audience, I'm doing so on video from afar. So let me continue with some of Randal's questions.</p> <p>Ben Goertzel:</p> <p>First question, what do I think about brain computer interfacing as a tool to improve AI safety? What impact would high speed brain-computer interfacing have on AI, rapidly self evolving AI, or AGI? Brain computer interfaceing could either greatly aid with AI safety, or it could terribly harm the prospects of safe AI. It really depends on how you would see this. On the beneficial side, if we want our AGI's to bridge and understand human values, connecting to the human brain is going to be a really nice way for an AGI to suck some values out of the human brain. Of course, AGI could even learn values by watching people. And by enacting values bridging the gap between robots and other agents in the human world. But to the extent that an AI get those values from the brain and make them understand human values...</p> <p>Ben Goertzel:</p> <p>...the other hand if we look at selling, spying and killing as the main pursuits of the AI sphere in the world today, given the big checks from goverments, they're controlling so much of AI today. How could brain-computer interfacing be for selling, spying and killing. You could invent a lot of interesting ideas that way and will they lead to the AGIs that are going to be positive and beneficial to the humans that they're sentient beings as they expanded their intelegence? Well, quite possibly not. Right?</p> <p>Ben Goertzel:</p> <p>Randal's next question, \"Could you create high bandwidth brain-computer interface without first having a neuroprosthesis or a completely artificial brain?\"</p> <p>Ben Goertzel:</p> <p>I think that the brain is very adaptive and probably if you stuck a bunch of data from a computer into it, the brain would make some interesting sense of it. It would then be no longer a legacy human brain. The more complex and the more data coming into the brain, the brain would have to morph itself to cope with this data. But that'd be quite interesting. You're creating a hybrid mind. Of course you get to a certain level where the brain no longer as the capacity to adapt to the brain computer interface. But what exactly that level is, we don't know enough about neuroscience or information processing in general to know that. That problem will be determined by experiment. I probably will not be the first person to volunteer for the experiment, but I'll be fairly early on.</p> <p>Ben Goertzel:</p> <p>So this will be quite interesting to see. I do think it's important to remember that once you get into nanotech, femtotech the amount of intelligence you can pack into a grain of sand would probably be a quadrillion times the human brain and a trillion or something times any brain computer hybrid. Because the human brains are inefficient ways of information processing creativity. Probably an inefficient way to manifest consciousness compared to what's possible in an engineered physical system permissible even according with the known laws of physics, let alone to the laws of physics maybe understood to be after a singularity. Upgrading human intelligence by connecting brains to computers, the hybrid mind is interesting. This is in the scope of post-singularity minds, these hybrids are going to be closer to a monkey or a frog compared to a super intelligence, right? So it's an interesting thing to do in terms of the transition between here and post singularly minds, but in the end it's just a baby step toward the singularity.</p> <p>Ben Goertzel:</p> <p>Randal's next question, \"Do you see ways in which whole brain emulation and artificial human brains might immediately present an existential risk to humanity?\" If you emulate some nasty human and then copy that emulated human a million times and connect it's body to selling, spying, and killing machines around the world, this may not be good. But again it's not really about the technology, it's about how it's used.</p> <p>Ben Goertzel:</p> <p>My guess is that if you compare whole brain emulation to an AGI built according to some new rational, non-emulating architecture like an Open Cog system that works really well, I would guess there's both more benefit and more risk in the engineered nonbrain emulating design, because the human brain is not made for self modification. If you start enhancing intelligence of certain parts of it then the parts are going to break, and you're going to wind up to not being able to enhance this intelligence tremendously without basically replacing it with a totally different architecture. The human brain is an adaptation to certain resource constraints, and once you release those constraints, you are going to need to change the architecture to manifest the intelligence that is possible with the new constraints. I think, on the other hand, the irrationally architected AGI is just what we're trying to do with Open Cog or it'd be something different than Open Cog with something engineered with self modification and you know rational self understanding in mind.</p> <p>Ben Goertzel:</p> <p>This sort of AI system is going to be able to reprogram itself it's going to be able to study itself. It's going to be able to, replace one module with an upgraded module, it's going to be upgrading all its states and then rationally make decisions as to what possible improvements of itself to try. It can go far, far ahead of a human augment with a brain computer interface or an uploaded emulated human it can go far ahead of these humanesque, post human minds, in a good or a bad direction. Again, the technology has a lot of potentials It depends on what you do with it, and, of course, what you do with it will guide what it does with itself.</p> <p>Ben Goertzel:</p> <p>Randall asks, \"Rapid, self-improvement is often described in the context of utility function optimization and reinforced with learning. In short, it may be accomplished only in a few, the many complex substances of the brain, like the neocortex and cerebelum. Do you think whole brain emulation can rapidly self improve?\" Well that's, that's a really delirious and misguided question Randal. I think it's true that only a little bit of what the brain does is reinforcement learning, and that's why the brain can be intelligent because reinforcement learning is a terrible overall paradigm for general intelligence. Reinforcement learning is only a tiny bit of what the brain does. Just like deep hierarchical pattern recognition, like current, deep neural lens. is only a very small part of what the brain does. So yeah, rapid self improvement can go much more rapidly if its following methodologies besides just reinforcement learning. The reasons that the human brain can't rapidly self-improve for more than its architected contorted and limited way where each part is dependent on the other parts, and each part of their dependencies evolve to work within certain processing constraints which aren't compatible with the transient intelegence that we want to build. I mean it's just like you can't take a horse and double its size and have it still work. If you increase the short term memory capacity of humans to 10,000 instead of seven plus or minus two, the connection between short and long term memory and medium term memory isn't going to work, but the relation between declarative and procedural knowledge and short term memory isn't going to work. A lot of other changes have to be made all around the brain. Whereas, if you have a rationally architected AGI system and increase its short term memory capacity. If it's written well you could probably just use some automated code by rewriting the system and tweek the other parts of the AGI system to properly accommodate for the expanded short term memory of the AGI system. So, I think there are limitations in the speed of self improvement that you're going to get in the brain emulation or brain incorporating AGI system. But these aren't to do with the limitations of material, so that extremely narrow and limited paradigm of reinforcement learning, these are more to do with just the constraints of being an evolved system as opposed to an engineered system moslty. Both systems can evolve and evolution is slow and messy. Engineering systems can be engineered, which can be much faster. Engineered reflective systems can self engineer, which is going to be really, really nice and way faster and way more efficient than the mess of evolution.</p> <p>Ben Goertzel:</p> <p>Randall askes, \"There's caution aagainst a strong push for neurotechnology and whole brain emulation, because work in those areas has been accelerated towards advancement toward runaway self-improving AI.\" Well, as I already said, I think this particular line of research in whole brain emulation is a terrible approach to self improving AIs. So, if you think self-improving AI is bad, you should be in favor of AI through brain emulation. If you want self-improving AI, you should be looking at engineered AI systems that are designed for rational reflection and self-understanding and self-modification.</p> <p>Ben Goertzel:</p> <p>Next question from Randall, \"There's an argument, the ultimate solution for AI safety is a scenario for human and AI becoming inextricably entangled.\" Well, again, there's no reason to think that will guarantee safety. There could be good, bad aspects. I mean if you're taking, you know, a very powerful artificial cognitive system and coupling it with these reptilian/mammalian motivational and emotional systems like we have in humans, this can be pretty nasty, right? I mean, an open cog system is one example of a non-brain based system that has a certain set of goals. They don't drive all dynamics of the system, but they drive a significant amount of it. They have a certain set of goals and then the system rationally using probability theory and logic chooses which actions are most likely to achieve its most important goals in the current context. I mean it's not driven by its body and its emotions and its instincts to the extent that a human being is.</p> <p>Ben Goertzel:</p> <p>I think something like that is probably going to be, if it's done right, it's going to be safer than some weird Frankenstein thing with these evolved motivational and emotional system latched into some artificial cognitive system. We don't know because we haven't built an AGI based on the human brain or brain-computer interfacing or open cog or anything else, yet. We don't know this tremendous and very hard to deduce uncertainly here, but my own instinct and my intuition, and I've thought about this a lot, is that it's going to be a lot more dangerous to make something in one system, all this nasty mamalian/reptiles stuff without official cognition. I think you want the rational, reflective self-modifying AGI to understand human culture and human values, and to have compassion for humans, and you don't really want it to be a human. You want there to still be humans, but you don't want to try to do something screwy like Megan said, the smartest and most powerful minds or some sort of huamn-AGI, franken-bob thing. You want to accept that humans are just a limited form of mind.</p> <p>Ben Goertzel:</p> <p>I mean there's beauty in this limitation as well as hideousness in this limitation, but that's what we are and one of our beauties is that we can build fundamentally superior minds that are compassionate toward us. I can self-understand, self-modify, and self-improve in ways that we intrinsically cannot due to the way that we evolved, and we can then coexist with these super minds, but we can't be these super minds, and trying to create a super mind that's tied in with the human/mammal/reptile control system is far more risky than any other technology on the horizon.</p> <p>Ben Goertzel:</p> <p>Another question from Randall, \"in your opinion, what should humanity do to maximize, long term chances for survival.\" Give Ben 50 quadrillion dollars! Apart from that, very clearly what humanity should be doing is spending a large percentage of its resources on globally beneficial applications of advanced technologies including AI, nanotechnology, neurotechnology, and so forth, and trying to create machines with compassion toward humans in deep, rich understanding of the full breadth of human values. We shouldn't be including the bulk of our AI resources into selling, spying, and killing. We shouldn't be putting so little resources into medical applications and advanced technology into education, agriculture, poets, scientists, social workers, nurses, preschool teachers and philosophers, and so forth. So I mean, if you look at it from the outside and you had a species on the verge of creating the first, minds more intelligent and powerful than itself, you might think a large percentage of that specie's resources was going into figuring out theoretically how to make these new minds be as beneficial as possible for the universe and the multiverse and for the species during the creating, and to prototyping different kinds of beneficial engineered minds, and to making sure that engineered minds, as they increase in intelligence year-by-year, are working closely in a positive and compassionate way for the species that created them. Instead, almost all AI development now is driven by commercial or military ends, and the same for medical technology and nanotechnology.</p> <p>Ben Goertzel:</p> <p>I mean almost all this technology is being developed so that one country can achieve military power over other countries or so the one company can extract money from other people so the fact that our technologies are being developed mostly out of tribalistic or greed based motives truely isn't good. We want to be developing these technologies in a way that is motivated and is explicitly driving toward broad benefit for humans and for the other minds that being created. That's not what we're doing. I'm trying to develop advanced technologies in a way that will help all of humanity and will help eulated human minds that we're going to create and throw in the animals and plants and the rest of the ecosystem and any aliens that may come out of this or other dimensions as well. But most relevant advanced technologies are being driven by very narrow sort of probablistic or ego based goals. This is not optimal. Of course, you can't solve the problem top-down all at once, hopefully you can solve that problem by unleashing sort of new methodologies into the world. I mean just as open source transformed the software world, perhaps decentralized AI networks can transform the AI world and cause AI just self organize in a way it's more democratic and participatory so that as AGI emerges out of nornal AI, it's emerging with the input from users, developers, and the participants of AI around the world and it's getting a broad range of applications and feeding on a broad range of human insights and feelings and intuitions.</p> <p>Ben Goertzel:</p> <p>It's about 1:38 AM here. Truely I'm becoming less and less lucid as this ramble continues, but hopefully I've given you some flavor of my views on these issues. So thanks Randall for inviting me to participate via video and hopefully next time I can show up in person.</p> <p>Mallory Tackett:</p> <p>All right. I'll stop sharing my screen, and I'm back on it. That was a really interesting response by Dr Ben Goertzel. I'm wondering if Anders was paying attention to all of that, and if he has anything to say.</p> <p>Anders Sandberg:</p> <p>Yeah. Well there is so much to comment on, of course, to unpack there and I think there are two parts. That particularly caught my attention. One is this issue where a band disagrees with Nick about how to go about handling it. And I think it has to do with prior probability estimates and guesses on how does the risk landscape look like. Then Ben points out that if you have a situation where it's enough that there is one bad AI researcher, then big things happen. This is very much the problem we outline, Nick and me, in a paper we call the unilateralist curse. If you have a group of agents that it's enough that one agent can unleash something, then even if all agents are nice and are trying to do it only if they think it's a good thing. As the group gets larger, it's more likely that somebody is going to be that guy. So I think this is a situation one should recognize when you're in that situation you should try to be more conservative than you normally would like to be.</p> <p>Anders Sandberg:</p> <p>Just because of the nature of that situation. But I think in particular when you really what to regulate is when you can't afford to be wrong, even once. And there are those people in AI safety, you really think that, yeah, we are very close to that heartache of scenarios and the likely bad outcome of such a scenario that means that we have a sharply fetch should we must be exceedingly cautious. I'm way more optimistic. I don't know if that actually is based on an irrational reasoning rather thing, but I don't trust this conclusion, but I think actualy, it's a more benign domain. And I think Ben also has roughly the same view here. So this of course leads to different ideas about what you want to do, regulatory speaking. However, it also suggests that if we could get even a slight bit of battery information about the actual risks, actual structure, the actual probability we would win so much.</p> <p>Anders Sandberg:</p> <p>So I think that is another reason to really, really pursue this. And then, another very interesting point he made very briefly was the resource constraints that have shaped the brain once you're free of them, you might reshape it in a lot of other ways. Again, just to mention a paper I wrote with Nick, we did one about human enhancement where we looked at evolutionary medicine as one guide to try to see where evolution really might have constrained us and those are the areas where we might then find ways of unconstraining us in our constructive ways. There might be other domains where it's going to be very hard to fix. For example, I think even uploads are good to have two run sleep simply because our memory consolidation is so based around that, which would be tremendously annoying form some perspective. But on the other hand, yeah it's going to take a lot of reverse engineering to get the answer. And that was just two main points on Ben's enormous discussion.</p> <p>Randal Koene:</p> <p>Interesting bit there about whole brain emulations and sleep. That's one of the things I actually happen to think about, which was if you have the freedom to change synapses, if you look at what sleep is actually trying to accomplish, if you've got your consolidation, and you've also got in rem sleep, bringing up older memories and mixing then in and doing some kind of interleaved learning and that sort of thing. There are alternative ways to do that. And for one thing, it's certainly doesn't have to take quite as long as it normally does. So, I imagine that there may be ways of getting around those sorts of limitations.</p> <p>Anders Sandberg:</p> <p>Yeah, I totally agree. But it's going to be a lot of tinkering.</p> <p>Randal Koene:</p> <p>Absolutely. And that's where Ben is absolutely right, of course, that it's much easier to come up with an artificial intelligence that is free to developing whatever algorithmic method likes to get it to self improve faster than an evolution, a patchwork that was evolved like the human brain. I think it might have come across to him as if I were saying the opposite, but that wasn't the case. I was just putting forward the question, well, can whole brain emulations even rapidly self improve? Is this something people should worry about? Since that sometimes got brought up. Mallory, how did you want to proceed? Do you want to take a question from the audience first?</p> <p>Mallory Tackett:</p> <p>Yeah. We do have some questions from the audience that I'd like to ask. We have one, their username is sacked SOS. Here they're quoting Descartes, I think therefore I am, \"Does that not mean that all physical laws and natural laws are just in our mind?\" and I think maybe what they're trying to say is, is our interpretation of physical laws limited by our biological brain? I also like to tack on to that, how do you think that will change if we were able to have a whole brain emulation and possibly merge that with AI, how will physical and natural laws then be interpreted?</p> <p>Anders Sandberg:</p> <p>Yeah. So this is of course familiar territory for most introductory philosophy courses where people start getting confused. Quite a lot of people not really think that, oh, there's nothing problematic with my perception, I'm see reality as it is. And at this point the gleeful philosopher will start bringing up optical illusion, some examples from quantum physics. But at the same time I think David Dutch has an interesting point in his book, The Beginning of Infinity, where he points out that the reach of our mind is way bigger than what you would expect for most of all systems. We actually have some mental tools that allow us to take explainations that work over shockingly large domains, even though we don't have direct access to them. When we talk about the distribution of galaxies in the universe in many ways we can't see the galaxy. We can only see them if we use telescopes. So in some sense, nobody has ever seen the Virgo cluster because you can't see it with the naked eye if you are a human, yet I don't think anybody would say it makes sense not to believe in its existence or a say that, oh, the Virgo cluster is a kind of weird artifact of having a telescope. So I think you get the same situation even if you're a brain emulation. Yes, now you might be seeing using a camera connected to a device driver connect to various pieces of software, turning it into neural signals. You add the extra levels, but as long as these levels don't distort things that are relatively faithful, I think you actually have something that make sense. And I do think we can build on top of it. I think we can... The most obvious thing is adding new senses, or trying to link up modules in our minds so they are functioning better.</p> <p>Anders Sandberg:</p> <p>If I could just run a quantum mechanics co-processor and have it seamlessly connected to my cortex, that would be wonderful. And maybe I would finally understand stuff. I would also have to change myself, how I work. But that might be a relatively low level thing, like changing how I visualize things in order to visualize more dementions rather than changing the true core need. Of course, philosophers will always throw in, well maybe there are things that are absolutely impossible for minds of our kind to think about. And I think that's true, but it might actually be relatively uninteresting. It's not too hard to construct girdles sentences that certain system... but that dosn't mean they don't come up that often in practice.</p> <p>Mallory Tackett:</p> <p>Would anybody else like to answer that?</p> <p>Randal Koene:</p> <p>Yeah, I kind of want to jump in on that just because it's a good point you brought up that it's interesting that our brain can handle things...</p> <p>Mallory Tackett:</p> <p>Hmm. Sounds like Randal might have lost Internet connection.</p> <p>Randal Koene:</p> <p>I am. Hmm.</p> <p>Mallory Tackett:</p> <p>All right, I can hear you now and see your video.</p> <p>Randal Koene:</p> <p>You hear me? Okay. So then I don't know what happened there.</p> <p>Mallory Tackett:</p> <p>It must have just dropped for a second.</p> <p>Randal Koene:</p> <p>I was just trying to expand on what Anders said about the brain being able to deal with things that it wasn't originally evolved for. It's interesting to see in which ways the tools that the brain has are applicable that way. And just to point out one little thing in this, this gelatinous blob here. Say for instance, the, the grid cells of the interinal system. We talk about them as something that helps map out space but the same part of the brain that feeds right into the hippocampus also has a task in humans it just generally manages to store new episodic memories, new conceptual memories concepts. Now, the interesting thing is if you take this system grid cells for mapping out spaces automatically, basically putting in vectors along them and saying, okay, this is x, Y and I'm over here and I'm over here, coming up with where you are.</p> <p>Randal Koene:</p> <p>If you take that and you apply it to more general concepts, something that has nothing to do with space, you can map out any new kind of idea, any concept that you have and suddenly apply it in ways that you never could before. You can work with it in a sense. Mapping things that shouldn't normally be mapped or that you don't encounter in nature. And I think you take that all across the brain and you can see that these systems, these tools, just like deep learning isn't something you can only use for one task can use it for many tasks the same way all the tools in the brain can be applied to many different things. It's true, but then at the same time, it's not necessarily optimized for a rapid self improvement. So I think Ben has a point there as well.</p> <p>Randal Koene:</p> <p>One thing I wanted to address briefly because Ben has a certain style, how he expresses his opinion on these matters is he often makes it very good and positive statement. He'll say something that he really hopes is the outcome. So we hear a lot of very positive scenarios from Ben.And in fact both sides of course want us to end up in the same type of outcome, a good outcome, whatever that good means. It's just that for some reason the methods that they advocate are very different sometimes. And a lot of this has to do with trying to understand what the probability of certain outcomes are and those probabilities are influenced by where you begin. So Andrew's already mentioned that, your bias, and perhaps by intuition which is of course, again bias by your experiences and by your emotional attachment to something.</p> <p>Randal Koene:</p> <p>So it's really a problem of clear probabilities lacking in this case. And we don't really know which scenarios are going to happen. Maybe this is just a sign of how young this field is still. But I do think one point that Ben makes is very interesting he brought this up in his paper in 2015 as well. The one that I think I might've mentioned somewhere, that we may need artificial intelligence or artificial general intelligence to guard against some of the bigger risks that we run into because of the way humanity goes about things. We'll talk about how an AI might want to follow a certain goal and keep on improving towards that goal. Even if it has to consume all the resources in the universe.</p> <p>Randal Koene:</p> <p>You could make a very similar argument for humans. We're still based on a system that evolved 2 million years ago and we're about to use up all the resources of the earth in order to try to keep doing that because that's what we were programmed to do. We may also be stuck with the same utility function and following it and we may be running a great risk of doing damage to ourselves in the process. Now again, I don't know if that's really what's going to happen, but this is part of the argument that Ben is making. Humans are not rational actors were not necessarily picking the best outcome all the time. AI may be more rational than we are, so it's entirely possible that developing that as quickly as possible, may be something that saves us from a risk that is more immediate or bigger because we keep on not having a good chance of comparing these probabilities, then the likelihood that AGI itself somehow be an agent that takes us down. I don't know if I agree with his point of view more or if I agree with Nick Bostrom's point of view, but I'd love to hear Andrew's kind of give this a shot.</p> <p>Anders Sandberg:</p> <p>Yeah. I've been thinking a lot about what can we do to do the research right? Because as you said, we need to get the probabilities right, but we might also want to get to the values right? So in my current project, this big book about the long term future of humanity, one of the parts that I'm still working very hard on and that is tough to work on, it's of course what values make sense in the universe. And what would rational actually mean because yes, we're definitely not rational right now, but just like the hippocampal place cells allow us to handle spaces of quite arbitrary shapes, our minds are actually able to have quite a lot of different models of rationality and thinking. It's just that we're not super good at that so much yet. Well, it seems to me that one way of making progress on both of this kind of tough problems is to look at toy problems.</p> <p>Anders Sandberg:</p> <p>You take stylized small problems. So this is how you might help the AI safety move forward. You will demonstrate that here is a little agreed world situation and you want your agent to behave itself in a certain way. Can you program it to do that? And that's useful, not just to entice software engineers the realize that actually it's harder than they think to make AI safe, but it also is a good way of revealing tricky problems. Learning about the size of the problems and learning about what other questions you want to do because typically to refine this as people find ways around what you wanted to do. There is another side and that is the empirical research you actually want to go out in the world and actually watch real situations because that keeps you honest. It's quite important to not just spend your time in the lab or in a thinking chair, but actually go out and try to get some data and then critically judge it.</p> <p>Anders Sandberg:</p> <p>Just because people think autonomous course should be driving in particular ways, doesn't mean that's the ethical thing to do, or the smart thing to do, but it's certainly an interesting input. And then ideally once you have both good models and the empirical data to play around with, you can also start building the more deeper theories. And I think this goes for creating AGI that is helping us make good choices. We need to know a bit more about what good choices are, both from a correctional and ethical style point. But we also actually wanted to develop... Can we make a decision aid in tools even in less ethically fraud domains that are actually useful, that's not entirely obviously yet, yet it is a big market. You can make a lot of money if you make a good decision aid and there researchers working on kind of moral decision aids.</p> <p>Anders Sandberg:</p> <p>I have some friends in Oxford working on that, where hopefully they would tell you, if you have a dilemma, \"Well, given what you claim to believe, this is what you ought to be doing. You want to discuss it more?\" and I think that could be quite useful. So I think there is an interesting big research project here. It's kind of spanning, not just AI safety and brain emulation, but quite a lot of other stuff. Taking what starts out in philosophy, making it concrete enough that we can start writing code and doing a psychological service and they'll start thinking broadly about how to implement tools to make us better.</p> <p>Mallory Tackett:</p> <p>I think that was a great answer. Next, we have a question from Dean Horak and it's actually one of my favorite questions to talk about. He says, \"Assume we have substrate independent minds available on some digital whole brain emulation platform, it would seem that accessing someone else's memories and experiences and thoughts would be nearly as effortless as accessing our own. Given the scenario, wouldn't we eventually lose our individual identities and ultimately become like a hive mind?</p> <p>Anders Sandberg:</p> <p>Well I think to some degree we have already created tools to access. Yet, we actually deliberately create walls. In some sense Internet allows any computer on the Internet to talk to any other computer. But it's not just that I can't get your data out of your computer. But we also deliberately create structures like web pages or and the Google hangouts to actually shape it, because having everything in a big pile is not very useful. My memories are only useful because I did make good association in relation to my current experience etc. And if you had your mind and memories and my memories sometimes of course they will overlap in a resonant sort of way, but quite often it would probably be just arbitrary. But we want selectivity, we want filtering and that is probably what it's going to mean that hiveminds are probably going to be more limited than we think.</p> <p>Anders Sandberg:</p> <p>In fact you can compare it to economics. Why do they have companies or firms and of course economists have been going on about the theory of the firm and that you have CSR Hidalgo at MIT and the general argument is that they are economists of scale up to a point. It's a good idea to get a bunch of people together but you also need to manage the information flow. Then you create a little box around it and call this a department or a company and we are likely to do the same thing for group minds. It wouldn't surprise me that once you have the ability to link minds, we're gonna experiment endlessly with a lot of architectures and some of them are going to be good for certain things, others less good. But maybe specialized and then we might actualy have this big complicated structure of overlapping and sometimes heroic income. Sometimes autocratic and sometimes totally alien structures. It's going to be predict exiting. But again, it's a good thing that there is an undo button of your brain emulation.</p> <p>Randal Koene:</p> <p>Great point about the undo button. That's something I occasionally mention when people ask about, this so risky, why would you experiment with upgrading and stuff. But you mentioned here, things that are already a bit like hive minds, organizations and groups and all that thing. And I think that to answer a dean's question, I think that hive minds merging is probably unavoidable because it's already a reality. It's just that the components of a hive mind don't know they're in a hive mind or maybe they do, but sometimes they don't or they don't admit it. They'll say I'm still an individual. But really they're entirely dependent on everyone else. I mean, do you farm it's sort of... We may be part of a hive mind and not know it yet.</p> <p>Mallory Tackett:</p> <p>That was great. I definitely see it that way that we are already kind of interconnected in a certain way due to technology and social media. Whole brain emulation will just exacerbate something that's already happening.</p> <p>Anders Sandberg:</p> <p>Some aspects of social media actually give us a very good inkling about just connecting everything completely. That's not very good. We actually want to create the right kind of structures and finding the right kind can turn out to be amazingly hard, while down the line technology is relatively safe.</p> <p>Randal Koene:</p> <p>But then if you're taking social media as the example, then maybe it's also demonstrating that it takes a certain amount of trial and error and learning because we had no idea what this would be like before we got into it. We didn't know what the Internet was going to spawn and we certainly didn't know anything about social media back in the eighties nineties or before, so it would have been very difficult to think ahead and say, when we design social media, what should the boundaries be?</p> <p>Anders Sandberg:</p> <p>I totally agree. There is this general problem that the world is much more complicated than our minds, so we generaly quite often can't predict the consequences outside a particularly simple domain. We just have to do experiments. Which is of course problematic if experiments are risky or expensive or painful, but also very exciting because it means that we've discovered new things. I find it very unlikely that we will ever enhance themselves such a degree that we can just figure it out or rationally just like some philosopher king just sitting in his arm chair, knowing everything. I think we're going to find that a world that has great minds, is going to be even more complicated anyway, after all, social media among smart super intelligence is going to be probably having emergent, wierd properties that we can think about and they can't think about. They're going to be equally confused when they get their counterpart to fake news or Twitter storms and the are going to perhaps wonder maybe we need a bigger mind to figure this hyper social media out.</p> <p>Randal Koene:</p> <p>Hmm. Yeah. It seems like there are at least two different ways to go about preventing the worst case scenario. And one of them is you try to anticipate something bad that could happen and just don't do it or prevent it from happening. And the other one, as we just mentioned, in the case of experimenting with whole brain emulation is undo buttons. So, what we haven't really talked about, and maybe it's because nobody thinks it's possible, is undo buttons for things that happen in AI development. I guess part of the problem is that we imagined that a bad scenario is one where AI development suddenly goes so quickly that there is just no way to stop it, let alone undo whatever happened. But an undo button would be nice if such a thing were possible outside of a sandbox let's say.</p> <p>Anders Sandberg:</p> <p>So I think the problem is that many of the AI risks are seen as information hazards. So once I publish my code on git hub and tweet about it, there is no way of gifting the genie back in the bottle. And that is an interesting thing because that might just be because we are not imaginative enough to come up with a better undo button. There are ways of handling information hazards. I'm working on some projects and thinking about how institutions like the Future of Humanity Institute should organize its own research when it finds some risky information and you can certainly have structured transparency where you can reveal certain information but not others in a way that is trustworthy etcetera. But it might also be that we can find ways of doing AI research where you can build in some forms of undo buttons.</p> <p>Anders Sandberg:</p> <p>Like we pursue a certain line of thinking, we discovered sort of risks or certain problems, and there is a considered way of removing it. This is of course what we would like to have in science too. If I write a paper that I would later retract, ideally all papers citing that paper need to get a little marker in the citation of that now we're referring to paper that turned out to be wrong for one reson or another. We need to build an infrastructure for that. Right now I don't have any idea of how to do that, but it sounds like one of those things that should be a high priority for someone.</p> <p>Randal Koene:</p> <p>Yeah. Actually, this is something where blockchain gets interesting. A ledger that you shared because if you can actually track everyone who is on that system, or who's got a copy of something, then you could go in and try to withdraw it or withdraw the ability to run that thing or to change it to whatever needs to be fixed. That's one approach. I'm just talking about it very loosely because I'm not actually someone who develops that sort of code, but it sounds to me like something that those systems could evolve towards. And the other is what we call software as a service, right? If you look at that, the situation there is that if, let's say, the service that you're making available has a bug. You only need to fix it where the service is being run and everyone else uses it and puts it to use. So if there are all these little modules that you use for AI, but they're all software as a service, it's very different than if you're giving away the code. Some opportunities there, perhaps for something like an undo button.</p> <p>Anders Sandberg:</p> <p>Yup. Sounds like a really fun topic to pursue further.</p> <p>Mallory Tackett:</p> <p>All right. I think that might be a good question to end on for our workshop unless anybody has any objections.</p> <p>Randal Koene:</p> <p>Yeah, I guess, let's ask our panel if any of you have any questions that you think really should be mentioned, either because they're your own or you saw them coming through. Maybe Jesse or somebody noticed something coming through, just as a quick opportunity to before we close. But otherwise I agree because it's been long enough and we can still handle all of those questions later in other ways because we've got them all written down.</p> <p>Mallory Tackett:</p> <p>Doesn't sound like it. So I guess that'll be the conclusion of our workshop. Again, thank you everybody for attending. I want to say thank you to all of our volunteers that helped put this together and all of the speakers that joined with us today, talked on the panel, and sent us videos or did interviews. We really appreciate that. I just wanted to have just have a couple of announcements besides the survey for the workshop that we would very much appreciate all of our audience members filling out and that can be found at survey.carboncopies.org. I also wanted to mention that we have a new episode of our podcast and that's available on our website if you want to go and view that. We frequently have new episodes that address different topics related to whole brain emulation. We also have up items on our store, new items on our store now.</p> <p>Mallory Tackett:</p> <p>We have sweatshirts, tee shirts, coffee mugs, bags. I'm already decked out in the sweatshirt if anybody can see. It's got our nice logo and I really enjoy it and just wanted to mention that we are a 501C3 nonprofit. All of the work that we do has been volunteer work and we relly on the generous contributions of our donors. If you could visit carboncopies.org/donate and make a donation that would be great for us. Our goal right now is to get to about $2,000 a month and that'll fund future workshops and any future research that we'd like to do that would allow anybody else, the audience members or people that follow us to participate. And on that note we also have several social media channels that you can join us on. It just depends on your preference for Facebook, it's facebook.com/groups/carboncopies. We also have a reddit account and it's just our /carboncopies. And then our Twitter account is @carboncopies.org. Thank you everybody and I think we'll close on that. I had a great time and I think I learned a lot and I have a lot of new questions.</p> <p>Randal Koene:</p> <p>Thank you, Mallory. And one just quick little thing. Thank you so much Anders for jumping in even though you had to travel so far. I hope you get some good rest now.</p> <p>Anders Sandberg:</p> <p>I'm looking forward to a nice Swedish night now, but this has been so exciting. I'm going to have sweet dreams about brain emulations.</p> <p>Randal Koene:</p> <p>Okay, fantastic. And also for anyone who had trouble hearing any portions of the interviews, or Ben's talk, all of these are going to be made available separately in their full high quality audio and video. They degraded a bit as we had to stream it through this live stream. So you'll get those as well. Thank you everyone.</p> <p>Anders Sandberg:</p> <p>Thank you.</p> <p>Mallory Tackett:</p> <p>Bye Bye.</p> <p>Randal Koene:</p> <p>Bye Anders.</p>"},{"location":"Events/Workshops/Topic/BrainPreservationToReconstruction/","title":"Brain Preservation to Reconstruction","text":"<p>THE WORKSHOP HAS CONCLUDED</p> <p>A SUMMARY OF THE EVENT, WRITTEN BY DR.KEITH WILEY IS AVAILABLE AT THIS LINK.</p> <p>THE WORKSHOP VIDEOS ARE AVAILABLE AT THIS LINK TO OUR YOUTUBE CHANNEL.</p> <p>================================================================================================= From Brain Preservation to Restoration</p> <p>April 29, 2018 Format: Hybrid - attend ONLINE or at 380 Portage Ave, Palo Alto, CA 94306 For attendance in Palo Alto, RSVP is mandatory due to space limitations.</p> <p>FREE to the general public at: https://carboncopies.org/livestream</p> <p>CONFIRMING YOUR RSVP to Carboncopies Workshop April 29, 2018</p> <p>Thank you!</p> <p>This confirms that we have received your RSVP to the Carboncopies Workshop on April 29, 2018.</p> <p>If you indicated a preference to attend in-person: Then we will send a follow-up email within the next few days to confirm your reserved space at the event. (If you do not receive the follow-up email by April 26, please send us a message at contact@carboncopies.org.)</p> <p>For the event agenda, the livestream and participant Q&amp;A forum, and to keep abreast of any last minute changes, please check back at https://carboncopies.org/events</p> <p>You can already submit questions to the Q&amp;A pool in advance if you wish! If you have questions related to the topic 'From Brain Preservation to Reconstruction' that you wish to submit for the workshop discussion in advance, please send a message to questions@carboncopies.org.</p> <p>We are looking forward to your participation at the workshop!</p> <p>+++</p> <p>Your support makes this possible!</p> <p>If you can afford to donate or to become a patron, welcome to the team! And, of course, RSVP below to join the event! \ud83d\ude42</p> <p>Donations to our general fund allow us to organize high quality, scientifically rigorous events with leading researchers, that foster collaborative interaction in the interest of solving critical challenges. We aim to maintain equal access to all, and to spread information as widely as possible.</p> <pre><code>Carboncopies is a U.S. IRS approved 501\\(c)(3) non-profit organization. As such, donations to Carboncopies are tax deductible in the United States. Please use the button above to reach our donations page.\n</code></pre> <p>From Brain Preservation to Reconstruction</p> <p>April 29, 2018, Carboncopies Foundation workshop https://carboncopies.org/events</p> <p>On Sunday, 2018-04-29, the Carboncopies Foundation (a 501c3 non-profit, carboncopies.org) will host a hybrid online- + in-person workshop with these aims:</p> <ul> <li>Present the concepts behind and the putative technical procedure of reconstruction from a preserved brain</li> <li>Discuss the next steps following the announcement of the winner of the Large Mammal Brain Preservation Foundation Prize.</li> <li>Discuss the scientific and technical challenges that must be overcome on the roadmap from preserved brain (and possible additional data) to revived mind.</li> </ul> <p>This workshop will be of particular interest to anyone thinking of brain preservation as a route to mind uploading, and it intends to build on the momentum that was generated by the recent announcement of the winner of the Large Mammal BPF Prize.</p> <p>The workshop seeks to address assumptions and missing pieces of information about the putative process, to challenge scientists involved, and to focus subsequent efforts. Those subsequent efforts may include the next steps undertaken by the BPF, primary and collaborative research carried out at the Carboncopies Foundation, steps taken by companies such as Nectome, 21<sup>st</sup> Century Medicine, or Alcor, and related research.</p> <p>Examples of challenges that deserve attention are:</p> <ul> <li>The problem of model validation and error correction during reconstruction from a preserved brain. What is the data required for that essential process?</li> <li>The problem of possible additional neural correlates of memory. What else, if anything, might be a necessary physical manifestation of stored memory that is not preserved by existing brain preservation techniques?</li> </ul> <p>The workshop will combine a local in-person meeting with a much larger online group of speakers and participating attendees. This hybrid format will efficiently enable a large number of geographically distributed participants. The hybrid workshop format was successfully tested during our previous workshop of January 28.</p> <p>There is no cost to participate online or in person, but we do ask that prospective participants RSVP at https://carboncopies.org/events.</p> <p>Speakers include:</p> <pre><code>DR. KEITH WILEY (A Taxonomy and Metaphysics of Mind-Uploading)\n\nDR. KENNETH HAYWORTH (The Brain Preservation Foundation)\n\nJONATHAN GORNET (Simulating Extracted Connectomes)\n\nDR. RANDAL KOENE (Carboncopies Foundation)\n\nPROF. DONG SONG (System Identification for Neural Prosthetic Memory)\n\nDR. DIANA DECA (Whole Brain Emulation)\n\nDR. STEPHEN LARSON (OpenWorm)\n</code></pre> <p></p> <p>workshop schedule:</p> <pre><code>10AM PST (5PM GMT) - DR. RANDAL KOENE - Introduction: From brain preservation to reconstruction\n\n11AM PST (6PM GMT) - DR. KEITH WILEY - Why a whole brain emulation from your preserved brain is probably you\n\n12PM PST (7PM GMT) - DR. KEN HAYWORTH - Aldehyde-Stabilized Cryopreservation preserves the morphology of neurons and glia, patterns of synaptic connectivity, ultrastructural details of synapses, and ion channel and receptor identities and locations. Still not enough?\n\n1PM PST (8PM GMT) - Reverse Engineering Demo (followed by lunch break)\n\n2PM PST (9PM GMT) - JONATHAN GORNET - Dynamical Modeling of Extracted Connectomes\n\n3PM PST (10PM GMT) - DR. RANDAL KOENE - System (de)composition and model validation at multiple scales\n\n4PM PST (11PM GMT) - PROF. DONG SONG - Towards a Clinical Hippocampal Memory Prosthesis\n\n5PM PST (12AM GMT) - PANEL: Restoring Jane Doe from her preserved brain\n</code></pre>"},{"location":"Events/Workshops/Topic/BrainPreservationToReconstruction/Summary/","title":"From Brain Preservation to Reconstruction","text":""},{"location":"Events/Workshops/Topic/BrainPreservationToReconstruction/Summary/#summary-of-the-april-2018-carboncopies-workshop-on-whole-brain-emulation","title":"Summary of the April 2018 Carboncopies workshop on whole brain emulation","text":"<p>Keith Wiley, 6/4/2018</p> <p>On April 29<sup>th</sup>, 2018, Carboncopies hosted its second workshop of 2018. This hybrid-format workshop, viewable both online via a live interactive video stream and in person onsite in the San Francisco area, had the theme of considering how a cryopreserved brain might be emulated via whole brain emulation (WBE). This topic was chosen in response to the recent announcement by the Brain Preservation Foundation (BPF) that they had awarded their Large Mammal Prize in March for the successful preservation of a pig\u2019s brain (http://www.brainpreservation.org/large-mammal-announcement/). The winning preservation protocol, Aldehyde-Stabilized Cryopreservation (ASC) lends itself directly to WBE and so the BPF announcement was chosen as the inspiration for Carboncopies\u2019 second workshop of the year. The workshop addressed topics such as what sort of model parameters should be required of a whole brain emulation (WBE) so that the result may be judged a preservation of a person\u2019s mind and identity, what features of a preserved brain should be required so as to provide the necessary information for an eventual scanned and emulated model, and what real-world contemporary examples can we draw from for inspiration or as an illustration of the potential progression of such technologies as our technological capability evolves.</p> <p>The opening talk, From Brain Preservation To Reconstruction, was by Dr. Randal Koene (founder and CEO of Carboncopies). This talk introduced WBE and investigated the technical aspects of how WBE would be performed on a preserved brain, with attention paid to the open questions, such as determining which information from the brain needs to be captured and utilized in an emulation. What information can be gathered from the brain to understand and recreate memory engrams? At a lower level, Koene asked what neural parameters are the determinant factors of how neurons accumulate and perform memory functions for the retention of information in the brain from past experiences, and with the effect of altering current behavior and subsequent state changes in the brain. What are the circuit architectures and neural or synaptic properties of memory and cognition? What library or reference guide might we build of neuron and synapse types and their varying properties? Koene emphasized the need to better understand large-scale organization, such as brain regions and algorithmic models of regional behavior.</p> <p>Another question Koene broached was that of determining the success criteria of WBE. How do we know that a WBE has successfully reproduced an individual\u2019s mind? Koene proposed the concept of a neural fingerprint, some objective measurement of brain structure or function that distinctly identifies an individual, such that if a WBE exhibited the same fingerprint we could judge it to represent the same person who preceded the preservation. What sort of validation test or data would inform us on such matters? Koene proposed that in addition to neural modeling and neural circuit validation, we might also desire (or require) psychological behavioral validation by comparing the WBE\u2019s behavior to similar behavioral tests preceding the preservation process.</p> <p>Koene also emphasized the importance of acknowledging model imprecision. No model is perfect and while this realization may shut the doors to philosophical acceptance of WBE as identity preservation for some readers, it certainly will not be considered prohibitive by others. For those readers willing to accommodate realistic variations between a model and its source data, what are the tolerable model variances in terms of error or generalized noise and randomness? How precise must one neural fingerprint measurement be to another for them to fall under the same identifying label? What parameters can we utilize in our model variance tolerance function?</p> <p>Koene finished his introductory presentation with a reminder that WBE can serve multiple purposes. While longevity is an oft-touted goal, another huge source of motivational objectives is the almost limitless possibilities to improve and expand human cognition as the future unfolds.</p> <p>Following Koene\u2019s talk, Dr. Keith Wiley, a board member with Carboncopies, presented Why a Whole Brain Emulation from your Preserved Brain is Probably You. This presentation was purely philosophical. It did not touch on recent or ongoing neurological experiments. The focus of this talk was what Wiley calls the copy problem, the question of whether the best interpretation of WBE of a preserved brain isn\u2019t identity preservation, but rather that some sort of metaphysical identity copy emerges in the WBE and that the original identity is left behind in the brain. Wiley\u2019s talk was primarily a series of counterarguments to the copy judgment. Wiley tackled multiple concerns that are commonly used to support the copy claim. Such concerns include continuity streams of consciousness or of neurological activity, the question of how identity purportedly spatially relocates from the brain to the WBE computer, and what implications should be taken from the possibility of a nondestructive process in which the person and/or brain revive despite a WBE having also been created. Wiley urged a philosophical position that personal identity is primarily psychological, instantiated by information patterns of neural configuration. As such, he specifically argued against the alternative of body identity, in which identity is physical instead of abstract and informational. Finally, Wiley proposed a variation of psychological identity called branching identity, which handles most of the paradoxes and conundrums that popularly confound body and simplistic psychological identity.</p> <p>Dr. Kenneth Hayworth, from Howard Hughes Medical Institute and Janelia Research, then presented the Aldehyde Stabilized Cryopreservation (ASC) technique that won the BPF mammal preservation prizes, and then asked whether ASC is sufficient to preserve the information critical to a later WBE. Hayworth\u2019s talk focused on the neural underpinnings of memory and how such issues inform the requirements of successful brain preservation. What features of the brain must be preserved to enable whole brain emulation? Hayworth emphasized that the starting position of such considerations is an assumption of physicalism, i.e., that the mind is solely the product of processes, ostensibly computations, occurring in the physical brain, a conclusion supported by a century of experiments.</p> <p>ASC has been confirmed to enable indefinite storage of the neural features considered by modern neuroscience to be the critical components of neural function, such as connectomic topology (which neurons connects to which), as well as individual connection properties (chemical and morphological traits of synapses and neurons). The assumption is that ASC should enable virtually unlimited technological capability for revival. The only question remaining is whether sufficient information is actually preserved. Hayworth argues that whether an emulation is of sufficient quality is in the eye of the beholder and that if the mind is computational, then there is no further fact, as the saying goes, regarding imperfect copies of neural function or personal identity.</p> <p>Regarding the issue of continuity of consciousness, Hayworth described how we have a self-model and associated narrative that is continually written into our long-term memory and that our identity (our sense of self) persists across breaks in consciousness, such as anesthesia, only because of our memories. We feel that our identity has survived sleep, fainting or anesthesia exclusively because our memories upon reawakening create the experience of our long-term self continuity; there is no other property at any level of abstraction, physical, psychological, or philosophical, that is relevant to this basic fact. Therefore, the crucial property in question is preservation and continuity of long-term memory, be it declarative, episodic, learned, or innate. These memories are stored in patterns and strengths of synaptic connections.</p> <p>Hayworth seeks a computational description of these synaptic properties. In other words, not only does he want to understand the topology and transmissive functions of synapses, but he also wants to abstract those brute physical facts to their implied computational properties and implications for memory representation. Hayworth concluded his talk by emphasizing that ASC appears by all counts to preserve the necessary structural and molecular features of memory, and by restating his desire that the professional neuroscience community take up these questions of further validation and investigation in earnest.</p> <p>Alicia Smallwood presented a concise and inspiring overview of analogous tasks and projects in a talk titled Reverse Engineering Demo: What Integrated Circuit Reverse Engineering Teaches Us About Reverse Engineering the Brain. In this informative presentation, Smallwood walked the audience through a set of videos by Ken Shirriff that demonstrated reverse engineering of integrated circuits (ICs), a problem that is quite similar to reverse engineering the brain. In both cases, a physical substrate comprises thousands to millions of microscopic components organized into a massive, complex, and convoluted signal-transmitting and signal-processing network. The goal is similar: to deduce the underlying functions performed by the physical network. The ICs are sliced apart, layer by layer, and then imaged with a metallurgical microscope. This initial step is very similar to slicing and scanning brain tissue of course. The captured images must be registered (aligned and overlapped) and then analyzed. Once components are identified and labeled, nascent comprehension of parts of the chip begins to emerge. Established abstract models (known basic models of transistor circuits) are then applied to further the image comprehension and reverse engineering of the specific chip under investigation.</p> <p>Shirriff even extended this work to the next logical step: modeling of the deduced structure and function in a software emulation. This step confirmed the correctness of the deduced model and offered yet additional understanding of the chip\u2019s observed behavior, which could have been elusive and confusing without the detailed knowledge provided by the reverse engineering efforts. Specifically, he determined that the reason the chip in question performed more slowly on larger numbers was that it would iteratively accumulate sums, such that summing to a greater total took more iterations to complete. This illumination might have been speculated from external behavior, but could only be solidly confirmed through low-level physical analysis, i.e., reverse engineering.</p> <p>Smallwood and Shirriff concluded with extensions beyond digital ICs, namely to analog chips such as the 555 timer. This talk gave great insight into the process of reverse engineering a neural and synaptic network to deduce algorithmic functions of the brain. While differences between ICs and brains can easily be listed, the principle is nevertheless similar and the presentation was fascinating in that regard.</p> <p>Jonathan Gornet, from New York University, then presented Dynamical Modeling of Extracted Connectomes. How do we discover and determine the Drosophila (fruit fly) connectome, and then how to do simulate it on a computer (a fly WBE). Gornet and others have been slicing and imaging fly brains with electron microscopy, layer by layer, to reconstruct whole neurons (a process frequently known as neurite tracing). Gornet discussed the task of correlating reconstructed morphology with dynamic measurements taken prior to the sectioning, imaging, and emulation process. Gornet walked through a particular neural circuit model in which a neuron is represented by its branching structure, with each branch represented by an action potential function. A neuron then comprises a branching series of such functions, and we can follow an action potential along some sequence if these functions as it traverse a neuron.</p> <p>Gornet addressed the concern of validation too. He described a motion selectivity experiment in which light bulbs are illuminated from left to right and the membrane potential of a single neuron is observed and modeled. At this stage he simplified his model, representing whole neurons as single functions instead of individual branches. The model\u2019s behavior was confirmed to be virtually unaltered by this simplification while reducing the model running time by a factor of forty. An implication of this result was that synapses are the critical feature of signal transmission and that population structure is more important than individual neuron geometry.</p> <p>Randal Koene returned with a second presentation titled Model Validation and System (De)composition at Multiple Scales. In Koene\u2019s second talk, he asked what information is needed to insure that a WBE works. What information is available from a preserved brain and what additional information (if any) is required beyond that provided by a preservation, such as dynamic recordings made prior to preservation? Koene compared building a WBE with reserve engineering an IC, as had been presented earlier by Alicia Smallwood. He emphasized the shared trait of large nonlinear dynamic models, which is the underlying feature of such models. Koene asked whether there might be a dynamic fingerprint that can be compared with an emulation for the purpose of validation. He prescribed an iterative process of parameter estimation, model validation, corrective modification and model selection, and repeated parameterization and validation, ultimately converging on a successful model. Where does this validation data come from? If it is recorded dynamically prior to preservation, then what spatial and temporal scales are required of such data to capture the necessary information for later model validation?</p> <p>Prof. Dong Song, from the University of Southern California, presented Towards a Clinical Hippocampal Memory Prosthesis. Song\u2019s talk presented research into dementia, the biggest neurological disease in the U.S., and for which there is currently no cure. Techniques that have helped some diseases, such as direct brain stimulation (DBS), applied toward Parkinson\u2019s with great success, do not work at all on other maladies, such as hippocampal deficits. In fact, DBS can make the hippocampal function even worse. Song described a biomimetic device that mimics hippocampal function and and bypasses the damaged hippocampal brain region, a topic that Ted Berger has presented on in previous Carboncopies workshops.</p> <p>Song presented a classic variant on animal (rat) lever-pushing experiments. In this case, neural firing patterns were recorded in conjunction with these behavioral experiments and then those patterns were computationally modeled as spatiotemporal action potential firing patterns. This recorded code was then used to restore neural function after the memory had been forgotten. Restoration of the memory proceeded by directly stimulating neurons with the previously recorded firing pattern. The rats successfully reproduced behavior associated with the lost memory, demonstrating the successful recording and later external stimulation of memories as neural circuits and firing patterns.</p> <p>Song has moved on to human trials with clear applications to dementia. Early experiments with humans attempting to remember abstract visual stimuli (visual patterns) have been encouraging and confirm the approach of applying model-based memory restoration.</p> <p>The workshop concluded with a panel discussion titled Restoring Jane Doe from her Preserved Brain, hosted by Dr. Diana Deca from the University of Southern California and Dr. Stephen Larson of the OpenWorm project. Deca and Larson led other participants through a discussion of whether an emulation of a preserved brain should be interpreted as a preservation of identity. One outcome of this discussion was the suggestion that we be open to the interpretation of a partial chance of identity preservation instead of insisting on judging the matter in the binary terms of success and failure.</p> <p>The April Carboncopies workshop asked a specific question. Given the recent BPF announcement that we now have a viable long term brain preservation method, what is the subsequent path forward for developing a WBE method to emulate a preserved brain, and relatedly to philosophically interpret a WBE as a preservation of personal identity. We will not be able to perform WBE of a human brain for a long time, but the path forward seems relatively clear. By extrapolating and extending current research such as hippocampal prosthesis, and by considering related challenges of reverse engineering complex networks, such as integrated circuits, and by carefully considering which neural and cognitive parameters should be deemed salient and required, we can lay out a roadmap for research and development toward the eventual emulation of a whole human brain from a long term preservation.</p> <p>Carboncopies\u2019 next workshop is currently scheduled for August 2018 with the topic of delving more deeply into the philosophical questions of consciousness and personal identity.</p> <p>Keith wiley serves on the board of Carboncopies as director of communications. His book, A Taxonomy and Metaphysics of Mind-Uploading, is available on Amazon.</p> <p>The workshop\u2019s archived URL is https://www.carboncopies.org/Events/Workshops/Year-Month/2018-April and includes links to the videos. The same URLs are offered below in chronological order:</p> <ul> <li>Dr. Randal Koene \u2014 https://www.youtube.com/watch?v=baywu1VEryk</li> <li>Dr. Keith Wiley \u2014 https://www.youtube.com/watch?v=GMd8-Ydpi-Y</li> <li>Dr. Kenneth Hayworth \u2014 https://www.youtube.com/watch?v=ZcSLJ1GxhyM</li> <li>Alicia Smallwood \u2014 https://www.youtube.com/watch?v=tRnqDy2UQCw</li> <li>Jonathan Gornet \u2014 https://www.youtube.com/watch?v=Dr7NA8HVKPk</li> <li>Dr. Randal Koene \u2014 https://www.youtube.com/watch?v=9C_JkF83OJY</li> <li>Prof. Dong Song, \u2014 Not publicly available per speaker request.</li> <li>Panel Discussion with Dr. Diana Deca, Dr. Stephen Larson, Dr. Ken Hayworth, Dr. Randal Koene and others \u2014 https://www.youtube.com/watch?v=VYmA0jveL1Q</li> </ul>"},{"location":"Events/Workshops/Topic/MetaphysicsEthics/","title":"Metaphysics and Ethics","text":""},{"location":"Events/Workshops/Topic/MetaphysicsEthics/#metaphysics-and-ethics-of-whole-brain-emulation","title":"METAPHYSICS AND ETHICS OF WHOLE BRAIN EMULATION","text":"<p>THE WORKSHOP HAS CONCLUDED</p> <p>THE WORKSHOP VIDEO IS AVAILABLE HERE.</p> <p>Saturday, September 15<sup>th</sup>, 2018 - 3 pm PDT</p> <p>Format: Online</p> <p>Watch the Carboncopies Summer Workshop 2018 and enjoy a two part presentation from Michael Cerullo. After his presentation Randal Koene, Keith Wiley, and Kenneth Hayworth join him for a panel discussion on the Metaphysics and Ethics of Whole Brain Emulation.</p>"},{"location":"Events/Workshops/Topic/ReverseEngineering/","title":"Reverse Engineering the Brain","text":""},{"location":"Events/Workshops/Topic/ReverseEngineering/#transcending-biology-reverse-engineering-the-brain","title":"TRANSCENDING BIOLOGY: REVERSE ENGINEERING THE BRAIN","text":"<p>THE WORKSHOP HAS CONCLUDED</p> <p>A SUMMARY OF THE EVENT, WRITTEN BY DR.KEITH WILEY IS AVAILABLE AT THIS LINK.</p> <p>THE WORKSHOP VIDEOS ARE AVAILABLE AT THIS LINK TO OUR YOUTUBE CHANNEL.</p> <p>=================================================================================================</p> <p>Sunday, January 28, 2018 - 8am-7pm PST</p> <p>Format: Hybrid - attend ONLINE or at 458 Brannan St., San Francisco, CA For attendance in San Francisco, RSVP is mandatory due to space limitations.</p> <p>FREE to the general public at https://carboncopies.org/livestream</p> <p>On Sunday, January 28, 2018, the 501(c)(3) nonprofit Carboncopies is hosting a public workshop on whole brain emulation and mind uploading. Attendance online or in person is free of charge. The workshop is designed to both introduce whole brain emulation and the Carboncopies organization as well as provide an update of current status and activities. The workshop will emphasize participation through Q&amp;A and topical discussion. The agenda includes the following topics:</p> <ul> <li>Mind Uploading: A brief introduction into the philosophy, science and technology of mind uploading and whole brain emulation.</li> <li>Roadmap 2018: The Carboncopies status update. How do we map the structure of a brain? How do we record the response characteristics of its neurons and synapses? How is a working model generated with parameters defined by those data maps? Finally, how is a model brought to life in a real implementation of whole brain emulation?</li> <li>Kernel and Neuralink: Commercial efforts to bridge the machine-human divide.</li> <li>Carboncopies Technology Review: Launching this research project.</li> <li>Special topic: Discovering Neural Circuits in Brain Data.</li> </ul> <p>Presenters include Prof. Theodore Berger (USC), Prof. Tony Zador (CSHL), Dr. Shawn Mikula (NIPS Japan), Dr. Adam Marblestone (MIT/Kernel), Dr. Randal Koene (Carboncopies, Chairman), Dr. Diana Deca (USC), Dr. Sim Bamford, and others.</p> <p>Everyone is invited to attend and participate. The workshop is designed to be accessible to newcomers.</p> <p>In fact, we are happy to receive your questions already! If you have questions that you'd like to see answered during one of the sessions, please email them to us at: questions@carboncopies.org</p> <p>We look forward to your attendance and participation.  See you there!</p> <p>WORKSHOP SCHEDULE:</p> <p>Introduction: 8am</p> <p>This is Mind Uploading and Why Humanity Needs It</p> <p>A brief introduction into the philosophy, science and technology of mind uploading and whole brain emulation. In a world where physics, biology, chemistry, currency and even intelligence become code, our species can flourish only if we too come to grips with ourselves as information and information processes.</p> <p>Topic A: 9am</p> <p>Roadmap 2018 - Where are we now? Moderator: Randal Koene</p> <p>The CarbonCopies status update. How do we map the structure of a brain? How do we record the response characteristics of its neurons and synapses? How is a working model generated with parameters defined by those data maps? And how is that brought to life in a real implementation of the whole brain emulation?</p> <p>BREAK 12pm</p> <p>Speaker\u2019s Lunch Break Moderator: Jevon Feinblatt</p> <p>Online open discussion.</p> <p>Topic B: 1pm</p> <p>Kernel and Neuralink</p> <p>In 2016 and 2017 commercial efforts emerged with highly outspoken founders who openly declare that their companies exist to create bridges between human and machine, and even to achieve neural prosthesis to lift up humanity. What do these companies contribute that is difficult or impossible in academia? And which new hurdles are presently beyond their reach?</p> <p>Topic C: 2pm</p> <p>Meet the CarbonCopies Technology Review Moderator: Alicia Smallwood</p> <p>CarbonCopies is launching a deep and wide technology review for the living roadmap to whole brain emulation. The review will publish its results in all relevant technology domains. Here, we introduce our study of brain data gathering technology: What is the right resolution for a connectome, and what is the best technology with which to create a connectome? What describes the dynamic characteristics of components in a connectome, and how can you collect this functional data in a living brain? What other brain data may we need to obtain?</p> <p>Special Topic: 5pm</p> <p>Discovering Neural Circuits in Brain Data Moderator: Randal Koene</p> <p>A collection of data is merely a pile of numbers without functional models to populate. What, if any, effort has been made to build sensible, falsifiable and improvable whole brain models? The most promising methods for building accurate neural prostheses and brain emulations, how good they can be, and the main challenge ahead.</p>"},{"location":"Events/Workshops/Topic/ReverseEngineering/Summary/","title":"Transcending Biology: Reverse Engineering the Brain","text":""},{"location":"Events/Workshops/Topic/ReverseEngineering/Summary/#summary-of-the-roadmap-session-of-the-first-2018-carboncopies-workshop-on-whole-brain-emulation","title":"Summary of the Roadmap session of the first 2018 Carboncopies workshop on whole brain emulation","text":"<p>Keith Wiley, 2/13/2018</p> <p>Will we one day be able to construct a computational model of an individual\u2019s brain such that we can say the working model re-instantiates that person\u2019s distinct mental functions? Will we be able to further interpret that model as a preservation of personal identity and even of life? These two concepts, known respectively as whole brain emulation (WBE) and mind uploading (MU), were the focus of the nonprofit organization Carboncopies\u2019 first workshop of 2018, held on January 28<sup>th</sup>, titled Transcending Biology: Reverse Engineering the Brain. Carboncopies\u2019 stated purpose is \u2018making whole brain emulation possible\u2019. The workshop was freely viewable online by the general public, as well as in person on site in the Bay area. URLs for videos of the individual talks are provided at the bottom of this article. An impressive group of professional scientists, all leaders in their respective fields, gathered on this day to present the state of the art in technologies that represent the nascent stages of eventual WBE.</p> <p>The workshop opened with an introduction by Dr. Randal Koene, founder and Chairman of Carboncopies. Koene began with a brief explanation of the feasibility of WBE, describing how it is the cognitive experience that matters when prioritizing aspects of the brain, not the underlying neural structure and function of which we are not directly aware. By analogy, internet browsers operate at the level of code and design patterns, not transistors and electrical properties. Brain emulation is, in this way, analogous to emulation of a web browser across varying computing architectures. As to why humanity should desire and pursue WBE and MU, Koene argues that in the future, humans are likely to play a decreasing role in the ongoings of society, government, and the overall range of mental experiences. For humanity to keep up with the inevitable advance of artificial intelligence, we must expand our own mental capacity to access further realms of experience. As to how to achieve WBE from a technical perspective, many of the other speakers addressed current work, but Koene gave an overview of the larger picture and how it may pan out as contemporary methods continue to evolve. It all comes down to structural, but more importantly, functional, modeling of the brain by means comparable to nascent neural prostheses. Such devices, both current and futuristic, operate by modeling, replicating, and ultimately replacing corresponding neural function, one brain region at a time, until in the limit none of the organic structure remains. Note that for the development of a neural prosthesis, functional recording alone may not be enough; an understanding of the underlying circuit structure may be essential to make the modeling process feasible. Structure scanning to discover such neural circuit layout was discussed by subsequent speakers, as presented below. Eventually, this expanding knowledge may reach the point where we can seriously consider emulations of large portions of the brain to be within grasp, and even emulations of the whole brain in the extent of such reasoning. Koene described the goals of Carboncopies as first seeking and proposing methods toward WBE, and second, enabling researchers to pursue projects toward those proposed methods. Finally, Koene announced that Carboncopies was launching, as part of the workshop, a tech review project with the goal of maintaining a living roadmap of projects and progress. This tech review will seek peer-reviewed research into the technical aspects of WBE. Koene and Carboncopies hope that this workshop will be a call to arms for researchers to take up WBE research in earnest in the years to come.</p> <p>Following Koene\u2019s introduction, the first session of the workshop brought in external speakers to present on various aspects of neuroscience relevant to WBE. The session began with Dr. Kenneth Hayworth from Howard Hughes Medical Institute at Janelia. Hayworth runs the Brain Preservation Foundation (BPF), whose goal is to promote and advance long-term whole brain preservation. The BPF aims for the eventual establishment of brain preservation as a standard medical practice offered in hospitals for life-preserving (or life-stasis) purposes. The BPF is motivated by the likelihood that brain preservation might be achievable sooner than mind uploading, and can therefore be used to bridge the intervening timespan until mind uploading is possible. Early success toward the BPF\u2019s goals has been encouraging, the most noteworthy event being that, in 2016, the BPF awarded its first cash prize for achieving new milestones in brain preservation. This prize was won by Robert McIntyre\u2019s team at 21<sup>st</sup> Century Medicine for the electron-microscopy-verified (EM) preservation of a whole rabbit brain. Such a feat of peer-reviewed and verified, high-quality preservation of macro-scale neurophil (a whole brain in fact) had never been achieved previously. Not only does the BPF motivate research by others through its cash prizes, but Hayworth has himself pioneered the technological development of slicing and imaging machines for the subsequent scanning of preserved brains. Such imaging is an obvious critical step in one of the more likely mind uploading procedures, a procedure in which a stasis-preserved brain\u2019s structural scan is used as the basis for a subsequent WBE.</p> <p>Prof. Tony Zador of Cold Spring Harbor Laboratory then presented work using the most recent advances in DNA barcoding to map a brain\u2019s projectome. The projectome differs from the more widely recognized connectome in that the former traces the brain\u2019s general neurite extent, while the latter explicitly captures the individual synaptic connections that underlie the brain\u2019s interconnected network. Zador\u2019s work with DNA barcoding injects randomly generated DNA snippets from a vast library of possible base-pair combinations into localized populations of neurons. The DNA is replicated with a virus so as to fill a given neuron wherever that neuron\u2019s dendrites and axons may stretch, including far across the brain. The brain is then imaged such that each barcode is uniquely exposed via color or direct sequencing, thereby revealing the entire projected structure throughout the brain of the population of neurons hosted locally around the injection site. This technique has already been utilized by the well known Allen Brain Atlas. Zador further presented a nascent extension of this work that offers the possibility of using the same basic technique to map connectomes.</p> <p>Dr. Adam Marblestone, of MIT and Kernel, presented optical methods for molecular connectomics. This technique combines expansion microscopy, DNA barcoding, and in-situ fluorescent sequencing for the Rosetta Brain Project. Expansion microscopy is a clever method for increasing spatial resolution. It literally swells the brain so as to make the smallest features more resolvable than they would be at their original scale. While electron microscopy can achieve nanometer resolution, it cannot penetrate deeply into tissue, nor can it benefit from various optical imaging advantages, such as color labeling. Alternatively, optical imaging (classical microscope imaging) penetrates deeply and can utilize color, but cannot achieve the same resolution as electron microscopy. Expansion combines the best of both, bringing small features within reach of conventional optical microscopes such that DNA barcoding can be utilized. Another application of DNA barcoding is to assist the error-correction stage of neurite tracing, in which a neuropil volume is slice and scanned, and neurite structures are reconstructed by tracing through the scanned layers, classically with electron microscopy. This practice suffers in regions where neurite details get too small or neurites from multiple neurons become excessively intertwined. Appending such a practice with barcoding could greatly assist in resolving the errors that occur in such regions.</p> <p>Prof. Theodore Berger, from the University of Southern California, gave a wonderful presentation of the current state of the art in neural prosthetics. Berger\u2019s work focuses on the hippocampus, a deviously challenging region since it resides near the center of the brain, inside and beneath other regions. The hippocampus mediates the conversion of short term memories into long term memories, and damage here is implicated in some of our most problematic brain maladies, such as Alzheimer\u2019s, dementia, blunt force trauma, and stroke. Recent work has implicated depression in hippocampus defects as well. Affected patients have functional short term memories and retain earlier long term memories, but are weakened or prevented from forming new long term memories. Berger\u2019s prosthesis applies electrodes to two regions of the hippocampus, loosely labeled as the input and output areas. It learns the neural spatio-temporal firing code from which it is possible to learn the transformation function performed by these regions of the hippocampus and can actually take over or strengthen this transformation for a damaged hippocampus. In this way, the prosthesis revitalizes a patient\u2019s ability to form new long term memories. The work is still in the research stages, but has proceeded with great promise. Further advancements are expected, as is eventual standardization of a medical application. The implications are profound to say the least. This is precisely the sort of work that gives us a glimpse into the possible future of neural prostheses. One needs only a decent imagination to extrapolate such to the wilder possibilities. Namely, taking this concept to completion by replacing every brain region with an equivalent prosthesis is, in fact, whole brain emulation.</p> <p>Dr. Shawn Mikula, from the National Institute for Physiological Sciences in Okazaki, Japan,presented his work on taking serial section EM further than its historical applications. EM is generally limited to volumes on the order of one millimeter cubed, but Mikula has extended the technique to rodent brain scales with impressive results. Using a machine based on Hayworth\u2019s design, he has sliced and image a whole mouse brain using EM techniques. Mikula hopes to be able to image macroscale whole brains in a matter of weeks, which represents orders of magnitude speed up over the current estimates of years.</p> <p>The impressive work these researchers have done gives a good survey of the most advanced techniques currently available. It was a great pleasure not only to see presentations on what is possible today, but to hear these experts speak on the likely paths of advancement over the coming decades. The expectations are universally optimistic; we should expect to see these methods expand in capability, accessibility, and generality throughout the twenty-first century. The conclusion is clear. Preserving, scanning, imaging, mapping, and functionally reproducing the brain, better summarized as whole brain emulation, is a technology that is practically destined to come to fruition given sufficient interest and funding, and commitment.</p> <p>Keith wiley serves on the board of Carboncopies as director of communications. His book, A Taxonomy and Metaphysics of Mind-Uploading, is available on Amazon.</p> <p>The workshop\u2019s archived URL is https://www.carboncopies.org/workshop-2018-jan and includes links to the videos. The same URLs are offered below in chronological order:</p> <ul> <li>Dr. Randal Koene \u2014 https://youtu.be/HdADrlY_MLk</li> <li>Dr. Kenneth Hayworth \u2014 https://www.youtube.com/watch?v=yD1mivVKRrs</li> <li>Prof. Tony Zador \u2014 https://youtu.be/z_yhpj9LYQA</li> <li>Dr. Adam Marblestone \u2014 https://youtu.be/gjYif3OSOkU</li> <li>Dr. Shawn Mikula \u2014 https://youtu.be/Zb0d-YdG3u0</li> </ul>"},{"location":"Events/Workshops/Topic/UpdatingRoadmap/OxfordRoadmapReview/","title":"Roadmap part 1","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/OxfordRoadmapReview/#updating-the-roadmap-to-whole-brain-emulation-part-1","title":"Updating the Roadmap to Whole Brain Emulation: Part 1","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/OxfordRoadmapReview/#carboncopies-workshop-review-of-the-oxford-roadmap-on-whole-brain-emulation","title":"Carboncopies Workshop: Review of the Oxford Roadmap on Whole Brain Emulation","text":"<p>The entire workshop ( Updating the Roadmap to Whole Brain Emulation Part 1 ) is available on our YouTube channel.</p> <p>The workshop included audience participation. Many thanks to all who RSVPed!</p> <p>In 2008, the Future of Humanity Institute at Oxford University published a manuscript titled \u201cWhole Brain Emulation: A roadmap\u201d, as the edited output of their first workshop on the science and technology of whole brain emulation that took place in 2007. The manuscript describes many of the scientific and technical challenges to data acquisition, modeling and real-time emulation of a whole human brain, and it attempted to estimate a development timeline.</p> <p>A lot has changed between 2008 and 2019. Many new insights, a better understanding of the challenges, and some new technological avenues necessitate an updated and corrected roadmap. In preparation for such an update that is planned in collaboration with the Future of Humanity Institute, the Carboncopies Foundation is launching a critical review. Our June 1 online workshop is the kick-off event for that review process, where we will reconvene a subset of the original participants of the 2007 workshop, and include pioneers who have emerged at the forefront of the field.</p>"},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part2/","title":"Roadmap part 2","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part2/#updating-the-roadmap-to-whole-brain-emulation-part-2","title":"Updating the Roadmap to Whole Brain Emulation Part 2:","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part2/#where-we-go-from-here","title":"Where We Go From Here","text":"<p>The entire workshop is available on our YouTube Channel.</p> <p>The workshop included audience participation. Many thanks to all who RSVPed!</p> <p>In continuation of our event series toward updating the Oxford University manuscript, \"Whole Brain Emulation: A Roadmap,\" we are advancing our discussion on what to do with the progress that has been made since 2008. In our previous event, \"Review of the Oxford Roadmap to Whole Brain Emulation,\" we shared advancements in Whole Brain Emulation (WBE) made since 2008.</p> <p>For this upcoming Summer Event, we will be exploring the next challenges and posing new questions based on what has been recently accomplished. Considering the progress that has been made, we will be mapping the next steps toward the completion of emulating an entire human brain. For our interviews we will ask our guests how they would proceed constructing an emulation given all the technologies expected to be available within the next decade. The discussion will aim to bridge the gap between a completed imaging of a sample and the emulation of that sample.</p> <p>The next steps in WBE are still not well defined. Because of the advancements toward WBE since 2008 there needs to be a new course of action leading from the progress that has been made to reaching the next step. Our September 21 online workshop will explore these newest challenges and set objectives to reach to continue advancing toward a realized emulation.</p> <p>Read our complete Summer Event Introduction by Dr. Randal Koene</p>"},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part3/","title":"Roadmap part 3","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part3/#updating-the-roadmap-to-whole-brain-emulation","title":"Updating the Roadmap to Whole Brain Emulation","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part3/#part-3-consciousness","title":"Part 3: Consciousness","text":"<p>The entire workshop is available on our YouTube Channel.</p> <p>The workshop included audience participation. Many thanks to all who RSVPed!</p> <p>We are continuing our workshop event series in updating the 2008 Oxford University manuscript, \"Whole Brain Emulation: A Roadmap.\" In our previous event, \"Updating the Roadmap to Whole Brain Emulation Part 2: Where We Go From Here,\" we had a great discussion on the current challenges facing the development of WBE. In the discussion, the issue of defining consciousness was presented as a major component.</p> <p>For this upcoming Fall Event, we will be discussing the definition of consciousness, how to measure it, where does consciousness reside in the human brain, and how can an emulated brain generate consciousness. Important questions will be covered in guest interviews which will be presented as recorded videos. Following the interviews we will have our live panel discussion responding to the interviews and additional questions prepared for the panel.</p> <p>Understanding consciousness and its emergence in an artificial brain it is an important aspect for developing a complete emulation of the human brain. With a clear understanding of the neural correlates of consciousness, the Oxford Roadmap to Whole Brain Emulation can be given a new key component. This live workshop event will be held Saturday, December 14, 2019 8AM PST / 11AM EST / 4PM GMT presented on the Carboncopies Foundation YouTube Channel.</p>"},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part4/","title":"Roadmap part 4","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part4/#updating-the-roadmap-to-whole-brain-emulation-part-4","title":"Updating the Roadmap to Whole Brain Emulation Part 4:","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part4/#successful-mind-uploading","title":"SUCCESSFUL MIND UPLOADING","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part4/#what-is-personal-identity-and-how-can-it-survive-mind-uploading","title":"What is Personal Identity and how can it Survive Mind Uploading","text":"<p>THIS WORKSHOP HAS CONCLUDED \u2013 MANY THANKS TO ALL OF OUR PARTICIPANTS!</p> <p>The entire workshop is available on our YouTube Channel.</p> <p>The workshop included audience participation. Many thanks to all who RSVPed!</p> <p>The Carboncopies Foundation is continuing the workshop series around updating the 2008 Oxford University manuscript, \"Whole Brain Emulation: A Roadmap.\" In our previous event, \"Updating the Roadmap to Whole Brain Emulation Part 3: Consciousness,\" we discussed how consciousness may be defined or measured, both from a 3<sup>rd</sup> person and 1<sup>st</sup> person perspective.</p> <p>While consciousness is a critical property of a successful whole brain emulation, the property that raises the most questions, debate and controversy in the context of achieving a successful outcome for mind uploading through whole brain emulation is personal identity. What is personal identity? How can you confirm a person\u2019s identity, taking into consideration both 1<sup>st</sup> and 3<sup>rd</sup> person perspectives? How is personal identity affected by proposed physical processes to achieve mind uploading through whole brain emulation?</p> <p>In this upcoming Winter 2020 Workshop Event, we will examine these questions with the help of domain experts. As previously, we will present recorded interviews that are followed by a live panel discussion. Our moderator will include questions from the general public directly in the live discussion. This is your opportunity to ask about surviving mind uploading and to hone in on the details that matter.</p> <p>The live workshop event will be held on Sunday, March 15, 2020 8AM PST / 11AM EST / 3PM GMT, presented globally through the Carboncopies Foundation YouTube Channel https://carboncopies.org/livestream. We hope to see you there!</p>"},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part6/","title":"Roadmap part 6","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part6/#updating-the-roadmap-to-whole-brain-emulation-part-6","title":"Updating the Roadmap to Whole Brain Emulation Part 6:","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part6/#neural-modeling","title":"NEURAL MODELING","text":""},{"location":"Events/Workshops/Topic/UpdatingRoadmap/Part6/#patient-specific-selection-fitting-and-validation","title":"Patient Specific Selection, Fitting and Validation","text":"<p>The Carboncopies Foundation is continuing the workshop series around updating the Roadmap to Whole Brain Emulation, the first version of which was published in 2008 as the Oxford University manuscript, \"Whole Brain Emulation: A Roadmap.\"</p> <p>This upcoming workshop will focus on the practical problems of model selection and model fitting. Modeling brain function is currently done using software simulations that include representations of the dynamic processes in neurons and synapses that transform signal data obtained from experimental recordings or generated by software. The ultimate goal for Whole Brain Emulation (WBE) continues to be to achieve animal-specific or patient-specific emulation of brain activity that is needed for cognitive function and subjective cognitive experience. In other words, we can assume that a successful model will operate on spatio-temporal patterns of neural activity, and will include the ability to adapt and learn that is generally referred to as brain plasticity.</p> <p>We will discuss scenarios such as the following:</p> <p>#1 All the Data: We set aside the problem of data acquisition and assume that we can map the connections of every neuron, and can record the activity of each neuron for as long as we wish in any setting. While this is currently only possible with preparations in extremely constrained laboratory settings, it is an interesting idealized baseline. With all the data we could possibly want, what is the process to build a satisfactory brain emulation? What hurdles remain? How might we best choose the right model and model fitting process?</p> <p>#2 Ephys Data: For the brain region (or the whole brain) we want to emulate, we know the basic structure for those neural circuits, but not for any specific brain. What we do have are extensive recorded samples of the activity of neurons, obtained by an appropriate method, such as two-photon imaging or electrophysiology. What might we hope to achieve in this case?</p> <p>#3 Ultrastructure: Considering the same brain region (or the whole brain), this time we have a good generic understanding of system and circuit theory, of dynamic modes, and of typical response profiles associated with the components involved. We do not have large-scale high resolution electrode recordings for the specific sample, but we do have its complete 3D reconstructed ultrastructure, as obtained by electron microscopy. How does this become a sample-specific functional model? What might we achieve now, and what presently stands in the way?</p> <p>For an emulation to work there needs to be an effective procedure for modeling that which you want emulated. This means modeling neuronal population and circuit function to a point where the resulting operations on signals meet practical success criteria for brain emulation. Not only must the model effectively achieve the desired signal processing within a satisfactory envelope of neurobiologically plausible outcomes, but the model building process must be realistically feasible in time and resource consumption. The time taken, and the amount of data needed, to estimate model parameters (i.e. fitting / training) tends to increase exponentially with the number of parameters (the curse of dimensionality). Any model of a whole brain will have an extraordinarily large number of parameters. What is the best way to break down the modeling process so that the process can be completed for each part in reasonable time?</p> <p>In this workshop we will discuss these challenges, the current advancements being made, effective constraint setting, and we will attempt to outline the next crucial steps toward computational modeling in the pursuit of brain emulation.</p> <p>This live workshop event will be held on Sunday, December 20, 2020 8AM PST / 11AM EST / 3PM GMT, presented globally through the Carboncopies Foundation YouTube Channel https://carboncopies.org/livestream. We hope to see you there!</p>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/","title":"Welcome to the Brain Emulation Challenge: Functionalizing Brain Data, Ground-Truthing, and the Role of Artificial Data in Advancing Neuroscience","text":""},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#reserve-your-seat-today","title":"Reserve Your Seat Today","text":""},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#this-will-be-a-virtual-event","title":"This will be a virtual event.","text":""},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#need-financial-assistance-request-a-fee-waiver","title":"Need Financial Assistance? Request a Fee Waiver","text":""},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#workshop-announcement","title":"Workshop Announcement","text":"<p>Functionalizing Brain Data, Ground-Truthing, and the Role of Artificial Data in Advancing Neuroscience. Join us for an exciting workshop exploring the challenges and opportunities in functionalizing brain data to emulate neural circuits. This event will tackle cutting-edge topics such as ground-truthing for validation, leveraging artificial datasets generated from virtual brain tissue, and the transformative potential of virtual brain platforms, such as applied to the forthcoming Brain Emulation Challenge.</p>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#workshop-structure","title":"Workshop Structure","text":"Minutes US PACIFIC (PST)  AGENDA ITEM 10 8:00 am Workshop welcome 20 8:10 am Randal Koene (Intro mini-talk) 45 8:30 am Philip Shiu (Drosophila functionalization): Dr. Philip Shiu is an accomplished neuroscientist whose work focuses on dynamic neural modeling, data analysis, and the computational understanding of brain function. With a strong interdisciplinary approach, Dr. Shiu explores how neural circuits process information and how these processes can be modeled and emulated. His research bridges the fields of neuroscience, engineering, and artificial intelligence, driving innovation in the study of brain dynamics and connectivity. 30 9:15 am Q&amp;A / brainstorming (Drosophila functionalization topics presented by Philip Shiu) 45 9:45 am Janne Lappalainen (Drosophila functionalization): Janne Lappalainen is a dedicated doctoral candidate specializing in neuroscience, with a particular focus on virtual brain platforms and computational modeling. With a strong passion for bridging the gap between theoretical neuroscience and applied technologies, Janne\u2019s research centers on developing and leveraging virtual brain platforms to better understand neural circuits and brain function. His work is at the intersection of computational neuroscience, artificial intelligence, and data science, making significant contributions to the advancement of brain emulation technologies. 30 10:30 am Q&amp;A / brainstorming (Drosophila functionalization topics presented by Janne Lappalainen) 45 11:00 am Randal Koene (Inverse problem, System Identification): Dr. Koene is the co-founder and science director of Carboncopies, a non-profit organization dedicated to advancing the science and ethics of whole brain emulation. His interdisciplinary expertise spans neuroscience, artificial intelligence, neuroprosthetics, and cognitive modeling, making him a thought leader in exploring the potential of uploading and preserving human consciousness through advanced technologies. 30 11:45 am Q&amp;A / brainstorming (Inverse problem, System Identification) 30 12:15 pm Break 45 12:45 pm Konrad Kording (C.Elegans, ground-truthing): Professor Kording\u2019s research focuses on understanding how the brain processes information and how computational models can be used to study neural systems. His interdisciplinary work spans topics such as motor control, decision-making, and the development of machine learning tools to analyze complex neural data. A pioneer in the field of neuroinformatics, Dr. Kording has made significant contributions to advancing our understanding of the brain\u2019s mechanisms and how they inform behavior. 30 1:30 pm Q&amp;A / brainstorming (C.Elegans, ground-truthing) 45 2:00 pm Razvan Marinescu (Synthetic data, (f)MRI):  Dr. Marinescu's research focuses on machine learning and its applications in healthcare and biomolecular systems. He has developed generative models for medical imaging, including chest X-rays and brain images, utilizing Bayesian inference for image reconstruction tasks. His work has significantly contributed to predicting the progression of neurodegenerative diseases, such as Alzheimer's, through advanced statistical modeling. Additionally, Dr. Marinescu co-founded GiwoTech Inc., a startup dedicated to innovative drug screening solutions. His academic journey includes a Ph.D. from University College London and a postdoctoral tenure at MIT's Computer Science and Artificial Intelligence Laboratory. 30 2:45 pm Q&amp;A / brainstorming (Synthetic data, (f)MRI topics) 45 3:15 pm Brain emulation challenge platform introduction: An introduction to the upcoming Brain Emulation Challenge, an open-science initiative designed to accelerate progress in whole-brain emulation. It includes virtual brain platform, outlining its goals, structure, evaluation metrics, and impact on computational neuroscience research. Learn how researchers (academic and independent), funders, and enthusiasts can engage with this challenge, contribute to advancing the field, and connect with a growing community. 30 4:00 pm Open discussion 5 4:40 pm Workshop closing"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#technical-focus-areas","title":"Technical Focus Areas","text":"Potential Speakers Expertise Koene, Randal System identification, functionalization, and insufficient availability of fully-known ground-truth for validation method development Kording, Konrad C.Elegans - State of the art in brain emulation, via connectome functionalization (and other significant examples), accomplishments and limitations Lappalainen, Janne Drosophila - State of the art in brain emulation, via connectome functionalization (and other significant examples), accomplishments and limitations Shiu, Philip Drosophila - State of the art in brain emulation, via connectome functionalization (and other significant examples), accomplishments and limitations Marinescu, Razvan fMRI - Application of artificial data sets, successful examples in other fields, ground-truthing in-silico, C.Elegans, cell-culture, proper application and awareness of risks"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#workshop-highlights","title":"Workshop Highlights","text":"<ul> <li> <p>Presentations from leading experts on efforts to emulate neural circuits and the formidable challenges of functionalizing brain data</p> </li> <li> <p>Insights into the current limitations of neural circuit emulation and neural prostheses derived from dynamic data or static connectomes</p> </li> <li> <p>Discussion on the critical need for fully known ground-truth datasets to advance the field</p> </li> <li> <p>Exploration of how artificial data, inspired by fields like AI, can accelerate method development</p> </li> <li> <p>Broad applicability, from high-throughput electron microscopy and connectomics to fMRI datasets</p> </li> <li> <p>Introduction to our open-source, open-science virtual brain platform and its application in the Brain Emulation Challenge, including its structure, evaluation metrics, and intended impact</p> </li> <li> <p>Ways for researchers inside and outside of academia, and funders to engage with these initiatives</p> </li> </ul>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#workshop-objectives","title":"Workshop Objectives","text":"<p>Participants will:</p> <ul> <li> <p>Gain a clear understanding of the state of brain emulation, including its possibilities and challenges</p> </li> <li> <p>Develop insight into current research efforts, limitations, and areas of potential breakthrough</p> </li> <li> <p>Learn how artificial datasets, carefully used, can enhance method validation, closing a learning and innovation loop to accelerate progress</p> </li> <li> <p>Become familiar with the Brain Emulation Challenge, its purpose and collaborative approach, and the platform behind it</p> </li> <li> <p>Discover opportunities to contribute, from participating in challenges to supporting the initiative's growth</p> </li> </ul>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#workshop-incentives","title":"Workshop Incentives","text":"<p>Student Discounts &amp; Financial Aid</p> <ul> <li>Special student rates available with valid student email</li> <li>Fee waiver applications accepted through filling out our Google Form</li> </ul> <p>Professional Development</p> <ul> <li>Digital Certificate of Participation upon workshop completion</li> </ul> <p>Networking Opportunities</p> <ul> <li>Dedicated break-out sessions with industry experts and speakers</li> <li>Virtual networking lounges during breaks</li> <li>Interactive Q&amp;A sessions after each presentation</li> <li>Small group discussions facilitated through themed break-out rooms</li> </ul>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#a-two-part-series-of-workshops","title":"A Two-Part Series of Workshops","text":"<p>This workshop is the first in a two-part series designed to result in hands-on experience for a community of innovators driving progress in brain emulation. While this session focuses on knowledge-sharing, it also serves as an invitation to join a pioneering movement. Attendees will connect with peers and experts, engage in discussions on emerging research, and explore ways to collaborate and support this transformative work.</p> <p>Join us as we lay the foundation for a rigorous, standardized, and open approach to brain emulation and related goals.</p> <p>Secure Your Spot - Complete Registration</p>"},{"location":"Events/Workshops/UpcomingEvents/FebruaryWorkshop2025LandingPage/Page/#all-proceeds-from-the-event-are-marked-as-general-operating-funds-to-further-the-mission-of-the-carboncopies-foundation-a-501c3-non-profit-research-and-education-organization","title":"All proceeds from the event are marked as general operating funds to further the mission of the Carboncopies Foundation, a 501(c)(3) non-profit research and education organization.","text":""},{"location":"Internships/","title":"Internships","text":"<p>Fall internships are now open.</p> <p>Also:</p> <ul> <li>We are always open to potential internships for exceptional candidates with a strong interest in our projects and mission. If this is you, then please email us at onboarding@carboncopies.org. In your email, please a) include your resume/CV, b) indicate the field of your proposed internship (e.g. neural modeling, data science, machine learning, neuroscience, educational outreach, grant writing, fund raising, graphic design or media).</li> <li>Join our community Discord for platform updates: https://discord.gg/quqzV4P4Z4</li> </ul>"},{"location":"Internships/#interested-in-joining-carboncopies","title":"Interested In Joining Carboncopies?","text":"<p>The volunteers who donate their time are the driving force of the Carboncopies Foundation. We are always looking for more people to join our team \u2013 and you don't need to have an advanced degree to make an important contribution.</p> <p>There are plenty of ways that anyone can pitch in, so if you want to be involved in helping to make Whole Brain Emulation a reality, let us know at onboarding@carboncopies.org.</p>"},{"location":"Internships/#thank-you-to-our-past-interns","title":"Thank you to our past interns:","text":""},{"location":"Internships/#syed-islam-ive-made-the-braingenix-python-client-easier-to-use-by-combining-an-older-part-of-the-code-into-the-main-program-this-means-all-the-scripts-still-work-and-its-simpler-for-developers-i-also-built-a-new-feature-that-lets-researchers-get-a-detailed-map-of-the-brains-connections-showing-exactly-where-each-neuron-and-its-connections-are-locatedi-am-a-recent-cs-graduate-from-ucr-and-am-continuing-my-education-at-ut-austin-in-ai-i-plan-to-do-more-research-into-machine-learning-focusing-on-deep-networks","title":"Syed Islam   I've made the\u00a0BrainGenix Python client\u00a0easier to use by combining an older part of the code into the main program. This means all the scripts still work, and it's simpler for developers. I also built a new feature that lets researchers get a detailed map of the brain's connections, showing exactly where each neuron and its connections are located.I am a recent CS graduate from UCR and am continuing my education at UT Austin in AI. I plan to do more Research into Machine Learning focusing on Deep Networks.","text":""},{"location":"Internships/#trisha-mendoza-my-name-is-trisha-mendoza-and-i-served-as-a-lead-for-the-carboncopies-data-science-intern-group-during-my-time-at-carboncopies-i-conducted-an-in-depth-literature-review-on-common-methods-for-testing-and-validating-neuronal-models-to-support-the-whole-brain-emulation-challenge-as-part-of-this-work-i-researched-and-developed-a-metrics-library-designed-to-evaluate-the-performance-of-user-models-against-ground-truth-datai-am-now-entering-my-final-year-of-graduate-school-at-the-university-of-california-irvine-where-my-research-focuses-on-computational-neuroscience-specifically-i-study-and-identify-biomarkers-of-seizure-generating-regions-in-patients-with-refractory-epilepsy-after-graduating-in-june-2026-i-hope-to-continue-advancing-research-in-computational-neuroscience","title":"Trisha Mendoza   My name is Trisha Mendoza, and I served as a lead for the Carboncopies data science intern group. During my time at Carboncopies, I conducted an in-depth literature review on common methods for testing and validating neuronal models to support the Whole Brain Emulation Challenge. As part of this work, I researched and developed a metrics library designed to evaluate the performance of user models against ground truth data.I am now entering my final year of graduate school at the University of California, Irvine, where my research focuses on computational neuroscience. Specifically, I study and identify biomarkers of seizure-generating regions in patients with refractory epilepsy. After graduating in June 2026, I hope to continue advancing research in computational neuroscience.","text":""},{"location":"Internships/#vilohith-gokarakonda-my-internship-work-is-about-finding-the-inverse-problem-for-whole-brain-emulation-which-is-about-challenges-neuroscientist-might-face-when-trying-to-emulate-brain-activities-in-a-mathematical-sense-this-deals-with-concepts-like-regulaization-methods-numerical-stability-mathematical-modeling-scale-seperation-etc-the-research-i-worked-the-most-on-was-creating-emulations-of-a-neuron-model-with-different-conditions-and-parameters-and-comparing-them-to-the-ground-truthmy-name-is-vilohith-gokarakonda-and-i-am-a-3rd-year-undergraduate-at-georgia-tech-majoring-in-computer-science-and-minoring-in-mathematics-my-interests-lie-in-mathematical-modeling-and-scientific-machine-learning-i-love-to-play-sports-like-badminton-tennis-and-chess","title":"Vilohith Gokarakonda   My internship work is about finding the inverse problem for whole brain emulation, which is about challenges neuroscientist might face when trying to emulate brain activities in a mathematical sense. This deals with concepts like regulaization methods, numerical stability, mathematical modeling, scale seperation, etc. The research I worked the most on was creating emulations of a neuron model with different conditions and parameters and comparing them to the ground truth.My name is Vilohith Gokarakonda and I am a 3<sup>rd</sup> Year Undergraduate at Georgia Tech, majoring in Computer Science and Minoring in Mathematics. My interests lie in mathematical modeling and scientific machine learning. I love to play sports like badminton, tennis, and chess.","text":""},{"location":"Internships/#soyeon-kim-i-developed-a-full-adder-model-using-the-lifc-model-by-carefully-timing-and-adjusting-the-weights-of-each-neuronal-connection-during-this-process-i-implemented-a-simplified-version-of-xor-gate-logic-hence-reducing-the-total-number-of-neurons-i-also-modified-the-structure-of-the-lifc-model-in-my-implementation-of-full-adder-circuit-to-make-adding-neurons-easiermy-name-is-soyeon-kim-and-im-currently-studying-computer-science-with-a-minor-of-art-design-at-the-university-of-michigan-ann-arbor-i-love-exploring-arvr-and-anything-visual-within-the-field-of-computer-science-im-also-a-freelance-photographer-on-campus","title":"Soyeon Kim   I developed a full-adder model using the LIFC model by carefully timing and adjusting the weights of each neuronal connection. During this process, I implemented a simplified version of XOR gate logic (hence reducing the total number of neurons). I also modified the structure of the LIFC model in my implementation of full-adder circuit to make adding neurons easier.My name is Soyeon Kim and I\u2019m currently studying Computer Science with a minor of Art &amp; Design at The University of Michigan, Ann Arbor. I love exploring AR/VR and anything visual within the field of computer science. I\u2019m also a freelance photographer on campus!","text":""},{"location":"Internships/#aiden-behler-during-the-internship-we-developed-an-integrate-and-fire-neuron-network-interface-to-collect-simulated-data-we-created-a-list-of-statistical-metrics-that-can-be-used-as-a-grading-criterion-for-the-whole-brain-emulation-challenge-and-we-created-a-test-suite-using-the-metrics-to-generate-a-user-report-based-on-the-comparison-of-two-simulated-neuron-network-modelsi-am-a-student-in-college-studying-computer-science-i-have-a-strong-interest-in-computational-neuroscience-and-brain-computer-interface-technology-my-goal-is-to-help-work-on-technologies-that-will-change-the-world-some-day","title":"Aiden Behler   During the internship, we developed an integrate and fire neuron network interface to collect simulated data. We created a list of statistical metrics that can be used as a grading criterion for the Whole Brain Emulation challenge. And, we created a test suite using the metrics to generate a user report based on the comparison of two simulated neuron network models.I am a student in college studying computer science. I have a strong interest in computational neuroscience and brain computer interface technology. My goal is to help work on technologies that will change the world some day.","text":""},{"location":"Internships/control-systems-intern-2025/","title":"Index","text":""},{"location":"Internships/control-systems-intern-2025/#return-to-internships-page","title":"Return to Internships page","text":""},{"location":"Internships/control-systems-intern-2025/#control-systems-research-intern-summer-2025","title":"Control Systems Research Intern Summer 2025","text":"<p>Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>We are looking for a volunteer researcher with a strong background in complex systems, system identification, inverse problems, and/or applied mathematics to support our ongoing research initiatives. This role is ideal for someone with a rigorous quantitative background who is passionate about solving real-world challenges through interdisciplinary collaboration\u2014particularly in neuroscience and related emerging fields.</p> <p>Key Responsibilities:</p> <ul> <li>Develop and analyze mathematical models for complex systems aligned with our research goals</li> <li>Apply system identification techniques to uncover patterns and infer system behavior from empirical data</li> <li>Tackle inverse problems by estimating hidden parameters from observational datasets</li> <li>Collaborate closely with researchers across disciplines to contribute to active projects</li> <li>Clearly document research methodologies and results for both internal review and potential academic publication</li> </ul> <p>Qualifications:</p> <ul> <li>Currently pursuing or holding an advanced degree (or equivalent experience) in applied mathematics, physics, engineering, computer science, or a related field</li> <li>Solid foundation in complex systems theory, system identification, and/or inverse problems</li> <li>Familiarity with control theory and its applications</li> <li>Experience with mathematical modeling, data simulation, and computational analysis</li> <li>Proficiency in relevant programming languages and tools (e.g., Python, MATLAB, Julia)</li> <li>Strong ability to communicate complex technical ideas clearly to interdisciplinary audiences</li> <li>Self-directed and capable of working both independently and as part of a team</li> <li>Interest in neuroscience, neural engineering, or whole brain emulation is highly desirable</li> </ul> <p>Time Commitment Approximately 20 -40  hours per week, with flexibility on scheduling.</p> <p>Benefits:</p> <ul> <li>We are able to coordinate with university programs on carrying out a PhD in association with the Carboncopies Foundation.  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Contribute to cutting-edge research in an emerging field  </li> <li>Collaborate with other researchers and technical experts  </li> <li>Potential for co-authorship on publications  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service</li> </ul> <p>To apply for Control Systems Research Internship:</p>      Apply for internship    <ul> <li>Alternative option: Email resume and statement to <code>onboarding@carboncopies.org</code> with \"Control Systems Research internship\" in subject line</li> </ul>"},{"location":"Internships/control-systems-intern-2025/#return-to-internships-page_1","title":"Return to Internships page","text":""},{"location":"Internships/data-engineer-summer-intern-2025/","title":"Index","text":""},{"location":"Internships/data-engineer-summer-intern-2025/#return-to-internships-page","title":"Return to Internships page","text":""},{"location":"Internships/data-engineer-summer-intern-2025/#datascience-engineering-summer-2025-internship-carboncopies-foundation","title":"DataScience  Engineering Summer 2025 Internship  Carboncopies Foundation","text":"<p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>We are seeking a highly motivated, self-directed Data Science Intern to join our research team. This role will focus on analyzing electrophysiology data from neurons and developing quantitative metrics to evaluate and compare signal processing performance between a ground-truth system and its reconstructed counterpart. The ideal candidate has a passion for data-driven research and an interest in neuroscience and neural technologies. </p> <p>Key Responsibilities:</p> <ul> <li>Analyze and interpret electrophysiological data to identify patterns and insights</li> <li>Design and implement metrics for comparing ground-truth neural signals with reconstructed data</li> <li>Build and maintain data pipelines for handling complex and large-scale datasets</li> <li>Contribute to feature development and functionality based on evolving project needs</li> <li>Document code and maintain high-quality technical documentation</li> <li>Collaborate with researchers and technical volunteers to align on goals and implementation</li> <li>Participate in code reviews and assist with testing</li> <li>Contribute to academic papers and potentially serve as a co-author</li> </ul> <p>Qualifications:</p> <ul> <li>Currently pursuing a degree in Computer Science, Data Science, Statistics, Mathematics, Neuroscience, or a related quantitative field</li> <li>Strong proficiency in Python and experience with data science libraries (e.g., pandas, scikit-learn); familiarity with R and/or SQL is a plus</li> <li>Experience working with version control tools such as Git</li> <li>Demonstrated ability to analyze, manipulate, and model complex datasets</li> <li>Understanding of statistical models and comfort working in data-rich environments</li> <li>Excellent communication skills for presenting findings to both technical and non-technical audiences</li> <li>Strong problem-solving skills and attention to detail</li> <li>Ability to work independently with minimal supervision</li> <li>Interest in neuroscience, brain-machine interfaces, or whole brain emulation is highly desirable</li> </ul> <p>Time Commitment Approximately 20 - 40  hours per week, with flexibility on scheduling.</p> <p>Benefits:</p> <ul> <li>Build a portfolio of work in a collaborative environment  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Contribute to cutting-edge research in an emerging field  </li> <li>Collaborate with other developers and researchers  </li> <li>Potential for co-authorship on publications  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost</li> </ul> <p>To apply for Data Science Engineering Internship:</p>      Apply for internship    <ul> <li>Alternative option: Email resume and statement to <code>onboarding@carboncopies.org</code> with \"Data Science Engineering internship\" in subject line</li> </ul>"},{"location":"Internships/data-engineer-summer-intern-2025/#return-to-internships-page_1","title":"Return to Internships page","text":""},{"location":"Internships/software-engineer-summer-intern-2025/","title":"Index","text":""},{"location":"Internships/software-engineer-summer-intern-2025/#return-to-internships-page","title":"Return to Internships page","text":""},{"location":"Internships/software-engineer-summer-intern-2025/#c-software-engineering-summer-2025-internship-carboncopies-foundation","title":"C++ Software Engineering Summer 2025 Internship  Carboncopies Foundation","text":"<p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>We are seeking a C++ Programming Intern to support the development and maintenance of our software systems and research infrastructure. This remote position offers flexible hours and the opportunity to contribute to meaningful, real-world projects at the intersection of neuroscience and technology.</p> <p>Key Responsibilities:</p> <ul> <li>Write clean, efficient, and maintainable C++ code for various foundation projects</li> <li>Debug, troubleshoot, and resolve issues in existing software systems</li> <li>Implement new features and enhance functionality based on evolving project requirements</li> <li>Contribute to maintaining comprehensive technical documentation</li> <li>Collaborate with other developers, technical volunteers, and researchers</li> <li>Participate in code reviews and assist with testing to ensure software quality</li> </ul> <p>Qualifications:</p> <ul> <li>Proficiency in C++ programming, with a solid grasp of object-oriented principles</li> <li>Experience with version control systems such as Git</li> <li>Familiarity with software development best practices and agile workflows</li> <li>Strong problem-solving skills and meticulous attention to detail</li> <li>Ability to work independently and manage time effectively in a remote setting</li> <li>Interest in brain science, neural technologies, or whole brain emulation is a strong plus  </li> </ul> <p>Time Commitment Approximately 20 - 40  hours per week, with flexibility on scheduling.</p> <p>Benefits:</p> <ul> <li>Apply programming skills to meaningful projects  </li> <li>Build a portfolio of work in a collaborative environment  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Contribute to cutting-edge research in an emerging field  </li> <li>Collaborate with other developers and researchers  </li> <li>Potential for co-authorship on publications  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost</li> </ul> <p>To apply for our C++ Software Engineering Internship: </p>      Apply for internship    <ul> <li>Alternative option: Email resume and statement to <code>onboarding@carboncopies.org</code> with \"C++/Python programmer internship\" in subject line   </li> </ul> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Internships/software-engineer-summer-intern-2025/#return-to-internships-page_1","title":"Return to Internships page","text":""},{"location":"Join/","title":"Join","text":""},{"location":"Join/#open-roles","title":"Open roles","text":"<ul> <li>PR &amp; Donor Relations Volunteer: We're seeking a motivated PR volunteer to help establish and maintain relationships with corporate donors, focusing on securing IT resource donations and managing donor communications.  View the full description here to apply</li> <li>Google Ads Volunteer: We are seeking a skilled volunteer to manage our Google Ads campaigns to increase awareness of our foundation, grow our community, and promote our events. This is an excellent opportunity for someone passionate about cutting-edge neuroscience and technology who wants to contribute their digital marketing skills to help advance our mission.  View the full description here to apply</li> <li>Complex Systems Specialist: We're seeking a volunteer with expertise in complex systems, system identification, inverse problems, and/or applied mathematics to contribute to our research initiatives and technical projects.  View the full description here to apply</li> </ul> <ul> <li>Social Media Manager: We're looking for a creative and organized volunteer to manage our social media accounts, create engaging content, and help grow our online community to increase awareness of our mission and activities.  View the full description here to apply</li> <li>Social Media Content Creator: We are looking for a Social Media Content Creator to help us create original and engaging content for our social media accounts.  View the full description here to apply</li> <li>Technical Onboarding Specialist: We are seeking a technically proficient volunteer to manage the onboarding of new technical volunteers, ensuring they have the necessary resources and support.  View the full description here to apply</li> </ul> <ul> <li>Creative Consultant: We are seeking a Creative Consultant to generate imaginative, compelling ideas for videos, campaigns, storytelling, and other content that communicates our mission and inspires our audiences.  View the full description here to apply</li> <li>General Research Assistant: The General Research Assistant / Intern (GRA/GRI) has a strong interest in the technological achievement of whole brain emulation and wishes to participate in its development.  View the full description here to apply</li> </ul>"},{"location":"Join/#interested-in-joining-carboncopies","title":"Interested In Joining Carboncopies?","text":"<p>The volunteers who donate their time are the driving force of the Carboncopies Foundation.  We are always looking for more people to join our team \u2013 and you don\u2019t need to have an advanced degree to make an important contribution.</p> <p>There are plenty of ways that anyone can pitch in, so if you want to be involved in helping to make Whole Brain Emulation a reality, let us know at onboarding@carboncopies.org. Alternatively, fill out the form below!</p> Loading\u2026"},{"location":"Join/#success-stories","title":"Success Stories:","text":""},{"location":"Join/#thomas-liao-im-particularly-interested-in-computational-neuroscience-and-distributed-systems-so-i-started-the-braingenix-project-at-the-carboncopies-foundation-at-braingenix-were-trying-to-develop-a-platform-that-will-eventually-lead-to-whole-brain-emulation-i-love-technology-from-code-and-servers-to-trains-and-urban-planning-if-any-of-that-sounds-interesting-to-you-head-on-over-to-check-out-some-of-my-projects","title":"Thomas Liao   I'm particularly interested in computational neuroscience and distributed systems, so I started the BrainGenix project at the Carboncopies Foundation. At BrainGenix, we're trying to develop a platform that will eventually lead to Whole Brain Emulation. I love technology - from code and servers to trains and urban planning. If any of that sounds interesting to you, head on over to check out some of my projects!","text":""},{"location":"Join/#angela-thornton-in-2018-i-fulfilled-a-long-held-dream-of-returning-to-academia-and-completed-a-msc-in-psychological-research-methods-at-the-university-of-nottingham-uon-where-i-gained-a-distinction-i-chose-this-course-as-a-stepping-stone-to-a-fully-funded-phd-at-horizon-centre-of-doctoral-training-also-based-at-the-uon-and-started-my-phd-journey-in-2019-my-thesis-looks-to-explore-the-personal-and-public-narrative-around-the-hypothetical-journey-to-whole-brain-emulation-and-the-ultimate-creation-of-a-substrate-independent-mind","title":"Angela Thornton   In 2018 I fulfilled a long-held dream of returning to academia and completed a MSc in Psychological Research Methods at the University of Nottingham (UoN) where I gained a distinction. I chose this course as a stepping stone to a fully funded PhD at Horizon Centre of Doctoral Training \u2013 also based at the UoN \u2013 and started my PhD journey in 2019. My thesis looks to explore the personal and public narrative around the hypothetical journey to Whole Brain Emulation and the ultimate creation of a Substrate Independent Mind.","text":""},{"location":"Join/#poonam-shokeen-working-at-carboncopies-foundation-has-been-transformative-as-a-program-manager-i-gained-leadership-skills-adaptability-and-invaluable-growth-dr-randal-and-the-supportive-team-pushed-me-to-excel-collaborating-with-brilliant-minds-and-cutting-edge-technology-shaped-my-career-and-perspective-grateful-for-this-incredible-journey","title":"Poonam Shokeen   Working at Carboncopies Foundation has been transformative. As a Program Manager, I gained leadership skills, adaptability, and invaluable growth. Dr. Randal and the supportive team pushed me to excel. Collaborating with brilliant minds and cutting-edge technology shaped my career and perspective. Grateful for this incredible journey!","text":""},{"location":"Join/#richard-gatchalian-im-a-recent-software-engineering-graduate-from-ut-dallas-bringing-a-sharp-focus-on-modern-web-technologies-and-ai-driven-solutions-to-the-carboncopies-foundation-specializing-in-large-language-models-and-seo-optimized-tech-stacks-like-nextjs-and-mkdocs-im-adept-at-architecting-scalable-web-applications-and-streamlining-development-workflows-my-passion-lies-in-leveraging-cutting-edge-tools-to-build-efficient-user-friendly-systems-contributing-to-the-foundations-mission-of-advancing-research-in-mind-uploading-and-related-fields","title":"Richard Gatchalian   I'm a recent Software Engineering graduate from UT Dallas, bringing a sharp focus on modern web technologies and AI-driven solutions to the Carboncopies Foundation. Specializing in large language models and SEO-optimized tech stacks like NextJS and mkdocs, I'm adept at architecting scalable web applications and streamlining development workflows. My passion lies in leveraging cutting-edge tools to build efficient, user-friendly systems, contributing to the foundation's mission of advancing research in mind uploading and related fields.","text":""},{"location":"Join/#adding-everyone-soon-internal-members-let-us-know-if-youd-like-a-spot-here-with-picture-and-your-story-a-description-of-a-past-success","title":"Adding everyone soon (internal members let us know if you'd like a spot here with picture and your story!)   A description of a past success.","text":""},{"location":"Join/assistant-pm/","title":"Index","text":""},{"location":"Join/assistant-pm/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/assistant-pm/#assistant-project-manager","title":"Assistant Project Manager","text":"<p>Assistant Project Manager \u00a0 Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation\u2014the process of transferring the structure and functions of a brain from its original biological substrate to an engineered computational one. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our initiatives span disciplines including neuroscience, computer science, neuroengineering, artificial intelligence, and philosophy. Through workshops, webinars, publications, and community coordination, we bring together researchers, students, and visionaries who share our mission. We believe that whole brain emulation is not only a grand scientific challenge, but a transformative opportunity for the future of human experience and identity.</p> <p>With over 15 years of history in the field, our team continues to foster innovative research and interdisciplinary collaboration. Our projects are powered by a dedicated community of volunteers\u2014over 100 have contributed to date, with more than 30 actively engaged today.</p> <p>Position Overview</p> <p>We are seeking a proactive and detail-oriented Assistant Project Manager to help coordinate and support the execution of research, engineering, and outreach projects across the Foundation. This role involves working closely with project leads and team members to keep initiatives on track, maintain clear documentation, manage communications, and ensure deadlines and deliverables are met.</p> <p>The ideal candidate is an organized self-starter who thrives in a dynamic, interdisciplinary environment and has a passion for future-facing technologies such as brain emulation, neural engineering, and cognitive science.</p> <p>Key Responsibilities:</p> <ul> <li>Track project goals, timelines, deliverables, and milestones \u00a0</li> <li>Maintain and update project documentation, including task lists, meeting notes, and reports \u00a0</li> <li>Coordinate between technical teams, research collaborators, and volunteers \u00a0</li> <li>Support planning and facilitation of meetings, workshops, and events \u00a0</li> <li>Monitor task progress and help identify roadblocks or resource needs \u00a0</li> <li>Contribute to internal communications, status updates, and planning materials \u00a0</li> <li>Assist with preparation of public-facing content such as progress reports or updates \u00a0</li> <li>Support outreach efforts to engage stakeholders, partners, and volunteers</li> </ul> <p>Qualifications:</p> <ul> <li>Strong organizational and time management skills \u00a0</li> <li>Familiarity with project management tools (e.g., Trello, Asana, Notion, or similar) \u00a0</li> <li>Excellent written and verbal communication skills \u00a0</li> <li>Comfortable working in a remote, distributed team environment \u00a0</li> <li>Ability to work independently and handle multiple priorities \u00a0</li> <li>Interest in neuroscience, neurotechnology, or brain emulation is highly desirable \u00a0</li> <li>Prior experience in project coordination, nonprofit work, or interdisciplinary teams is a plus</li> </ul> <p>Time Commitment \u00a0 Flexible, approximately 5\u201315 hours per week This is a volunteer remote position</p> <p>Benefits:</p> <ul> <li>Gain experience managing complex, multidisciplinary research and technology initiatives \u00a0</li> <li>Collaborate with leading scientists, engineers, and innovators in brain emulation \u00a0</li> <li>Build a professional portfolio in project coordination and scientific collaboration \u00a0</li> <li>Connect with professionals in neuroscience, AI, and advanced technologies \u00a0</li> <li>Attend Foundation-hosted events and webinars at no cost</li> </ul> <p>How to Apply \u00a0 If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Assistant Project Manager\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/assistant-pm/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/complex-systems-role/","title":"Index","text":""},{"location":"Join/complex-systems-role/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/complex-systems-role/#complex-systems","title":"Complex systems","text":"<p>Complex Systems Research Volunteer Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>We're seeking a volunteer with expertise in complex systems, system identification, inverse problems, and/or applied mathematics to contribute to our research initiatives and technical projects.</p> <p>Key Responsibilities:</p> <ul> <li>Analyze complex systems and develop mathematical models relevant to our research goals  </li> <li>Apply system identification techniques to extract patterns and relationships from data  </li> <li>Work on inverse problems to determine underlying parameters from observational data  </li> <li>Collaborate with our interdisciplinary team on research projects  </li> <li>Document methodologies and findings for both internal use and potential publication</li> </ul> <p>Qualifications:</p> <ul> <li>(Working towards an) advanced degree (or equivalent experience) in applied mathematics, engineering, physics, computer science, or related field  </li> <li>Strong background in complex systems theory, system identification, and/or inverse problems  </li> <li>Experience with mathematical modeling and simulation  </li> <li>Proficiency in relevant computational tools and programming languages  </li> <li>Ability to explain complex technical concepts to diverse audiences  </li> <li>Self-motivated with ability to work independently and collaboratively  </li> <li>Interest in brain science, neural technologies, or whole brain emulation is a plus</li> </ul> <p>Time Commitment Approximately 5-10 hours per week, with flexibility on scheduling.</p> <p>Benefits:</p> <ul> <li>We are able to coordinate with university programs on carrying out a PhD in association with the Carboncopies Foundation.  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Contribute to cutting-edge research in an emerging field  </li> <li>Collaborate with other researchers and technical experts  </li> <li>Potential for co-authorship on publications  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service</li> </ul> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Complex Systems Research Volunteer\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/complex-systems-role/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/creative-consultant/","title":"Index","text":""},{"location":"Join/creative-consultant/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/creative-consultant/#creative-consultant","title":"Creative Consultant","text":"<p>Creative Consultant \u00a0 Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation\u2014the process of transferring the structure and functions of a brain from its original biological substrate to an engineered computational one. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our initiatives span disciplines including neuroscience, computer science, neuroengineering, artificial intelligence, and philosophy. Through workshops, webinars, publications, and community coordination, we bring together researchers, students, and visionaries who share our mission. We believe that whole brain emulation is not only a grand scientific challenge, but a transformative opportunity for the future of human experience and identity.</p> <p>With over 15 years of history in the field, our team continues to foster innovative research and interdisciplinary collaboration. Our projects are powered by a dedicated community of volunteers\u2014over 100 have contributed to date, with more than 30 actively engaged today.</p> <p>Position Overview</p> <p>We are seeking a Creative Consultant to generate imaginative, compelling ideas for videos, campaigns, storytelling, and other content that communicates our mission and inspires our audiences. This is a concept-driven role: you will develop the creative \u201cseed\u201d that sparks new initiatives and guides our writers, designers, and media producers.</p> <p>The ideal candidate is a strategic thinker with a talent for storytelling and messaging. You should be able to brainstorm strong ideas for how we present ourselves to the world\u2014whether that\u2019s the framing of a public campaign, the hook for a video explainer, or the core message of a fundraising effort.</p> <p>Key Responsibilities:</p> <ul> <li>Develop high-level ideas and creative direction for video scripts, campaigns, and communications \u00a0</li> <li>Brainstorm and pitch content formats, themes, metaphors, and narratives \u00a0</li> <li>Contribute to public-facing messaging and outreach materials \u00a0</li> <li>Collaborate with internal teams to refine ideas and shape execution \u00a0</li> <li>Offer strategic input on audience engagement and tone \u00a0</li> <li>Provide guidance on structure, emotional resonance, and conceptual clarity</li> </ul> <p>Qualifications:</p> <ul> <li>Strong conceptual and storytelling skills \u00a0</li> <li>Ability to generate ideas that are innovative, mission-aligned, and audience-focused \u00a0</li> <li>Clear communicator with the ability to express ideas in writing or visual outlines \u00a0</li> <li>Comfortable collaborating with design, video, and communications teams \u00a0</li> <li>Familiarity with science communication, nonprofit outreach, or public education is a plus \u00a0</li> <li>Interest in neuroscience, consciousness, or future-oriented technologies is welcome</li> </ul> <p>Time Commitment \u00a0 Flexible, approximately 5\u201315 hours per week This is a volunteer position</p> <p>Benefits:</p> <ul> <li>Shape the creative voice of a pioneering nonprofit in neurotechnology \u00a0</li> <li>Collaborate with scientists, engineers, and creatives at the frontier of brain emulation \u00a0</li> <li>Build a strong portfolio of creative work for a meaningful mission \u00a0</li> <li>Connect with a dynamic interdisciplinary community \u00a0</li> <li>Attend Foundation-hosted events and webinars at no cost</li> </ul> <p>How to Apply \u00a0 If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Creative Consultant\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/creative-consultant/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/general-research-assistant/","title":"Index","text":""},{"location":"Join/general-research-assistant/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/general-research-assistant/#general-research-assistant","title":"General Research Assistant","text":"<p>Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is a 501(c)(3) non-profit organization that provides support to scientists working on challenges critical to whole brain emulation (WBE).</p> <p>We believe that the possibilities and opportunities afforded by WBE represent the most promising technological path to overcoming our fundamental limitations as a species and as individuals.</p> <p>The volunteers who donate their time are the driving force of the Carboncopies Foundation. We are always looking for more people to join our team - and you don\u2019t need to have an advanced degree to make an important contribution.</p> <p>Position Overview</p> <p>This is a REMOTE Volunteer position</p> <p>The General Research Assistant / Intern (GRA/GRI) has a strong interest in the technological achievement of whole brain emulation and wishes to participate in its development. Through mentorship, the GRA/GRI will acquire requisite skills on the job and will support the practical instantiation of multiple R&amp;D workstreams in the Office of Research.</p> <p>The workstreams in question are:</p> <ul> <li>The Translation Study Group (focused on translation from data to model parameters)</li> <li>WBE roadmapping: justification</li> <li>WBE roadmapping: success criteria</li> <li>WBE roadmapping: methodologies</li> <li>WBE ethical framework</li> </ul> <p>Responsibilities / Duties:</p> <ul> <li>Literature research and compiling reference lists</li> <li>Proofreading / editing preprints for publication</li> <li>Preparing documents or slides for meetings and workshops</li> <li>Participating in R&amp;D events, publications, and other R&amp;D activities</li> <li>Preparatory work for R&amp;D events such as workshops, conferences, retreats</li> <li>Vetting candidate team members</li> </ul> <p>Qualifications</p> <p>(The following qualifications and/or experience aren't required but would be helpful for you in taking this role):</p> <ul> <li>Participation in early-stage work of a new startup</li> <li>Designing, documenting, setting up experiments</li> <li>Management or internship work in a research lab</li> </ul> <p>Time Commitment:</p> <ul> <li>1 hour weekly team meeting</li> <li>5 hours / week</li> <li>At least 4 months</li> </ul> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"General Research Assistant\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/general-research-assistant/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/google-ads-role/","title":"Index","text":""},{"location":"Join/google-ads-role/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/google-ads-role/#google-ads-volunteer","title":"Google Ads Volunteer","text":"<p>Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview We are seeking a skilled volunteer to manage our Google Ads campaigns to increase awareness of our foundation, grow our community, and promote our events. This is an excellent opportunity for someone passionate about cutting-edge neuroscience and technology who wants to contribute their digital marketing skills to help advance our mission.</p> <p>Responsibilities - Create and optimize Google Ads campaigns to promote the foundation and our events - Develop compelling ad copy and select appropriate keywords to maximize reach and engagement - Monitor campaign performance and make data-driven adjustments to improve results - Implement conversion tracking to measure campaign effectiveness - Work within our nonprofit Google Ad Grant parameters ($10,000/month in-kind advertising) - Provide monthly reports on campaign performance and recommendations - Collaborate with our communications team to ensure messaging alignment</p> <p>Qualifications - Experience managing Google Ads campaigns (Google Ads certification a plus) - Understanding of digital marketing principles and best practices - Strong analytical skills and familiarity with Google Analytics - Excellent written communication skills - Self-motivated with ability to work independently - Interest in neuroscience, brain-computer interfaces, or consciousness studies (preferred) - Available to volunteer 3-5 hours per week</p> <p>Benefits - Gain valuable nonprofit marketing experience - We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation. - Expand your professional network in the neuroscience and technology communities - Attend our events and webinars at no cost - Letter of recommendation upon successful completion of 6 months of service - Satisfaction of contributing to cutting-edge scientific advancement</p> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Google Ads Volunteer\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/google-ads-role/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/pr-role/","title":"Index","text":""},{"location":"Join/pr-role/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/pr-role/#pr-donor-relations-volunteer","title":"PR &amp; Donor Relations Volunteer","text":"<p>Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview We're seeking a motivated PR volunteer to help establish and maintain relationships with corporate donors, focusing on securing IT resource donations and managing donor communications.</p> <p>Key Responsibilities:</p> <ul> <li>Draft and send professional emails to potential corporate donors requesting IT resource donations  </li> <li>Maintain regular communication with existing and prospective donors  </li> <li>Track outreach efforts and donor responses  </li> <li>Assist with crafting compelling donation appeals  </li> <li>Support additional PR initiatives as needed</li> </ul> <p>Qualifications:</p> <ul> <li>Excellent written and verbal communication skills  </li> <li>Experience in PR, marketing, or donor relations preferred but not required  </li> <li>Self-motivated with ability to work independently  </li> <li>Strong organizational skills and attention to detail  </li> <li>Interest in neuroscience, brain-computer interfaces, or consciousness studies (preferred)  </li> <li>Available to volunteer 3-5 hours per week</li> </ul> <p>Benefits:</p> <ul> <li>Gain valuable experience in non-profit PR and donor relations  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service  </li> <li>Satisfaction of contributing to cutting-edge scientific advancement</li> </ul> <p>To Apply:</p> <p>If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"PR &amp; Donor Relations Volunteer\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/pr-role/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/programmer-role/","title":"Index","text":""},{"location":"Join/social-media-content-creator-role/","title":"Index","text":""},{"location":"Join/social-media-content-creator-role/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/social-media-content-creator-role/#social-media-content-creator","title":"Social Media Content Creator","text":"<p>Social Media Content Creator Volunteer Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>This is a REMOTE Volunteer position</p> <p>We are looking for a Social Media Content Creator to help us create original and engaging content for our social media accounts. In this role, you will be responsible for researching and turning content ideas into videos, images, infographics, and text captions. You will also help the Social Media Manager to create and execute a content calendar. A deep interest in current social media trends is required to be successful in this role.</p> <p>Key Responsibilities:</p> <ul> <li>Develop, design, and produce engaging social media content including text captions, images, videos and infographics tailored to each platform (Facebook, Instagram, LinkedIn, Twitter/X, Discord etc.).</li> <li>Maintain a consistent brand voice and identity across all social media channels to enhance brand presence and loyalty.</li> <li>Plan and maintain a content calendar to ensure regular and timely posts that align with marketing goals and campaigns.</li> <li>Monitor and respond to audience interactions in a timely manner to foster engagement and community growth.</li> <li>Track the performance of social media content using analytics tools, and adjust strategies based on insights to improve engagement, reach, and follower growth.</li> <li>Work closely with other departments to align content with company goals and campaigns.</li> <li>Interact with followers and manage online communities to foster engagement and brand loyalty.</li> </ul> <p>Qualifications:</p> <p>The following qualifications and/or experience aren't required but would be helpful for you in taking this role:</p> <ul> <li>1 - 2 years of experience in social media management, content creation, digital marketing, or related roles</li> <li>Strong understanding of key social media platforms and their content formats</li> <li>Deep knowledge of social media trends, hashtags, and engagement strategy</li> <li>Proficiency in tools like Adobe Creative Suite, Canva, CapCut, or equivalent editing software</li> <li>Proven experience in creating engaging content on different social media platforms\u2014Twitter, Facebook, Instagram, and YouTube etc.</li> <li>Ability to turn a concept into compelling content</li> <li>Ability to incorporate our brand voice and identity in digital content</li> <li>Excellent writing, editing, and communication skills.</li> <li>Creative thinker with attention to detail and a strong visual eye</li> <li>Ability to manage multiple projects and meet deadlines</li> </ul> <p>Time Commitment</p> <ul> <li>1 hour weekly organization meeting</li> <li>1 hour weekly team meeting</li> <li>1 hour daily co-working sessions</li> <li>Approximately 5 \u2013 10  hours / week</li> <li>At least 5 months</li> </ul> <p>Benefits:</p> <ul> <li>Build a professional portfolio of social media management work  </li> <li>Develop skills in digital marketing and community engagement  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Contribute to raising awareness about important scientific research.  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service</li> </ul> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Social Media Content Creator\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p> <ul> <li>Website: https://carboncopies.org/</li> <li>LinkedIn: https://www.linkedin.com/company/carbon-copies</li> <li>Instagram: https://www.instagram.com/carboncopies_foundation/</li> <li>Facebook: https://www.facebook.com/groups/carboncopies/</li> <li>Twitter: https://twitter.com/carboncopiesorg</li> <li>YouTube: https://www.youtube.com/channel/UCuNZLgW-6Xcp6wfyb2Y_Thw</li> </ul>"},{"location":"Join/social-media-content-creator-role/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/social-media-role/","title":"Index","text":""},{"location":"Join/social-media-role/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/social-media-role/#social-media-manager","title":"Social Media Manager","text":"<p>Social Media Manager Volunteer Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>We're looking for a creative and organized volunteer to manage our social media accounts, create engaging content, and help grow our online community to increase awareness of our mission and activities.</p> <p>Key Responsibilities:</p> <ul> <li>Develop and implement a cohesive social media strategy across platforms  </li> <li>Create and schedule regular posts for Twitter/X, Facebook, LinkedIn, and Instagram  </li> <li>Design visually appealing graphics and multimedia content  </li> <li>Monitor engagement and respond to comments and messages  </li> <li>Track analytics and provide insights on social media performance  </li> <li>Collaborate with team members to promote events, research updates, and fundraising campaigns  </li> <li>Stay current on social media trends and best practices</li> </ul> <p>Qualifications:</p> <ul> <li>Experience managing social media accounts (personal or professional)  </li> <li>Strong writing and communication skills  </li> <li>Basic graphic design abilities and familiarity with design tools  </li> <li>Understanding of social media analytics and metrics  </li> <li>Organizational skills and ability to maintain a consistent posting schedule  </li> <li>Creativity and enthusiasm for translating complex concepts into engaging content  </li> <li>Interest in [your foundation's specific focus area]</li> </ul> <p>Time Commitment Approximately 5-10 hours per week, with flexibility on scheduling.</p> <p>Benefits:</p> <ul> <li>Build a professional portfolio of social media management work  </li> <li>Develop skills in digital marketing and community engagement  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Contribute to raising awareness about important scientific research.  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service</li> </ul> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Social Media Manager\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/social-media-role/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/technical-onboarding-specialist/","title":"Index","text":""},{"location":"Join/technical-onboarding-specialist/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/technical-onboarding-specialist/#technical-onboarding-specialist","title":"Technical Onboarding Specialist","text":"<p>Carboncopies Foundation</p> <p>About Carboncopies Foundation</p> <p>The Carboncopies Foundation is an international nonprofit organization dedicated to advancing the science and technology of whole brain emulation - the process of transferring the structure and functions of a brain from its original substrate to another computational substrate of a neural prosthesis. Founded by neuroscientists and technologists, we serve as a nexus for research collaboration, education, and public discourse on the path toward preserving and extending human cognition.</p> <p>Our work spans multiple disciplines including neuroscience, computer science, nanotechnology, and philosophy. Through workshops, webinars, publications, and community building, we bring together researchers, students, and enthusiasts who share our vision of developing technologies that may one day allow for the precise mapping and functional recreation of neural architectures. We believe that whole brain emulation represents not only a profound scientific challenge but also a potential pathway to extending human experience, knowledge, and consciousness beyond current biological limitations.</p> <p>For over 15 years, we have been at the forefront of research and development in this field, fostering collaboration between leading neuroscientists, technologists, and visionaries who share our mission. Our efforts have been powered by a dedicated community\u2014over 100 volunteers have contributed to our initiatives over the years, with 30+ actively driving our programs forward today.</p> <p>Position Overview</p> <p>As a Technical Onboarding Specialist at the Carboncopies Foundation, you will be instrumental in ensuring our new technical team members are equipped with the necessary tools and knowledge to contribute effectively to our mission. You will guide technical volunteers and interns through the process of setting up accounts, gaining access to platforms, and developing familiarity with our collaborative tools. This role provides an opportunity to bridge the gap between our HR processes and technical operations while supporting the growth of our diverse team of researchers and developers advancing whole brain emulation technology.</p> <p>Responsibilities</p> <ul> <li>Create and manage technical accounts for new team members across various platforms and systems  </li> <li>Develop and maintain documentation for technical onboarding procedures  </li> <li>Guide new technical volunteers through initial software setup and configuration  </li> <li>Provide basic training on organizational tools and collaborative platforms  </li> <li>Troubleshoot access issues and resolve technical onboarding challenges  </li> <li>Coordinate with project leads to ensure appropriate permission levels and access rights  </li> <li>Conduct follow-up sessions to verify successful integration of technical team members  </li> <li>Identify opportunities to streamline and improve the technical onboarding process  </li> <li>Maintain records of software licenses, access credentials, and system configurations</li> </ul> <p>Qualifications</p> <ul> <li>Strong technical aptitude with experience in account management and software setup  </li> <li>Familiarity with collaboration tools, version control systems, and cloud-based platforms  </li> <li>Excellent communication skills with ability to explain technical concepts clearly  </li> <li>Patient and methodical approach to training and troubleshooting  </li> <li>Detail-oriented with strong organizational abilities  </li> <li>Experience with documentation creation and maintenance  </li> <li>Interest in neuroscience, technology, and the mission of the Carboncopies Foundation  </li> <li>Background in IT support, systems administration, or technical training is beneficial  </li> <li>Ability to work independently while coordinating effectively with technical and HR teams</li> </ul> <p>Commitment of 5-10 hours per week for at least 6 months</p> <p>Benefits</p> <ul> <li>Gain valuable nonprofit marketing experience  </li> <li>We are able to coordinate with university programs on carrying out credit-earning student internships in association with the Carboncopies Foundation.  </li> <li>Expand your professional network in the neuroscience and technology communities  </li> <li>Attend our events and webinars at no cost  </li> <li>Letter of recommendation upon successful completion of 6 months of service  </li> <li>Satisfaction of contributing to cutting-edge scientific advancement</li> </ul> <p>How to Apply If our mission resonates with you, we encourage you to get involved. To apply for a volunteer position, please send your resume and a brief statement outlining your interest to onboarding@carboncopies.org with \"Technical Onboarding Specialist\" in the subject line.</p> <p>Alternatively, apply through our form at: https://carboncopies.org/apply</p> <p>The Carboncopies Foundation is committed to diversity and welcomes applications from all qualified individuals regardless of race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status.</p>"},{"location":"Join/technical-onboarding-specialist/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Join/volunteer-onboarding-specialist/","title":"Index","text":""},{"location":"Join/volunteer-onboarding-specialist/#return-to-join-page","title":"Return to Join page","text":""},{"location":"Join/volunteer-onboarding-specialist/#return-to-join-page_1","title":"Return to Join page","text":""},{"location":"Newsletter/JulyAugust2024/","title":"Carboncopies Foundation Newsletter: July-August, 2024","text":"<p>Read Length 4~ minutes</p> <p>Welcome to the second edition of the CarbonCopies Newsletter! For this edition we would like to highlight our progress made towards the Virtual Brain Platform Challenge and also our Micro-Workshop held on 8/4/2024.</p>"},{"location":"Newsletter/JulyAugust2024/#braingenix-vbp-updates","title":"BrainGenix / VBP updates:","text":"<p>In the past two months our developers have focused on integrating the Netmorph Platform (Netmorph is a software that stimulates neuronal growth, to generate biologically plausible neurons) into the Virtual Brain Platform challenge. We focused on integrating Netmorph because it is one of key checkboxes leading up to the launch of the challenge. You will be pleased to know that progress is moving at a swift pace.</p> <p> Small Excerpt of Three Neural Populations from Netmorph via (neuronal emulation system) NES</p>"},{"location":"Newsletter/JulyAugust2024/#micro-workshop-on-842024","title":"Micro-Workshop on 8/4/2024","text":"<p>We would like to thank all of the attendees of our \"Micro-Workshop\". During the workshop Dr. Koene discussed in detail the Virtual Brain Platform Challange, and held an insightful Q&amp;A session at the end. If you would like to view a recording of the micro-workshop Click Here!</p>"},{"location":"Newsletter/JulyAugust2024/#creation-of-the-carboncopies-foundation-discord-server","title":"Creation of the CarbonCopies Foundation Discord Server!","text":"<p>Just this month we revitalized our server and it is now an area of discussion for all things neuroscience and whole brain emulation! Everyone is completely free to join and we you all Here, We hope to see you there! </p>"},{"location":"Newsletter/JulyAugust2024/#recent-blogs","title":"Recent Blogs","text":"<p>How Could Whole Brain Emulation Affect Us? Hannah Price, August 2024</p> <p>What is Whole Brain Emulation Hannah Price August, 2024</p>"},{"location":"Newsletter/JulyAugust2024/#featured-scientific-publications","title":"Featured Scientific Publications","text":"<p>Software in science is ubiquitous yet overlooked, Hocquet Alexandre, et al.</p> <p>The NeuroML ecosystem for standardized multi-scale modeling in neuroscience, Sinha Ankur, et al.</p> <p>Tools for connectomic reconstruction and analysis of a female Drosophila ventral nerve cord, Averzado Anthony, et al.</p> <p>Circuit analysis of the Drosophila brain using connectivity-based neuronal classification reveals organization of key communication pathways, Mehta Ketan, et al.</p> <p>Nanoscale volumetric fluorescence imaging via photochemical sectioning, Wang Wei, et al. April 28, 2024</p> <p>Reconstruction of motor control circuits in adult Drosophila using automated transmission electron microscopy, Jasper S. Phelps, et al.</p> <p></p>"},{"location":"Newsletter/JulyAugust2024/#stay-connected-with-the-carboncopies-foundation","title":"Stay Connected With the Carboncopies Foundation","text":"<p>Subscribe to our Newsletter</p> <p>Check out our social media here: X/Twitter, Facebook, Linkedin, Youtube, Discord.</p> <p>If you want to support the work being done at the CarbonCopies Foundation please consider Donating.</p>"},{"location":"Newsletter/MayJuly2024/","title":"Carboncopies Foundation Newsletter: May - June, 2024","text":"<p>Read Length ~6 minutes</p> <p>We are very pleased to announce the revival of our newsletter. For this edition we would like to highlight our introduction of the Brain Emulation Challange, alongside our president Dr. Koene who presented at the 2024 Forsight Whole Brain Emulation Conference.</p>"},{"location":"Newsletter/MayJuly2024/#braingenix-virtual-brain-platform-updates","title":"BrainGenix / Virtual Brain Platform Updates","text":""},{"location":"Newsletter/MayJuly2024/#introducing-the-brain-emulation-challange","title":"Introducing the Brain Emulation Challange","text":"<p>The Brain Emulation Challenge is one of the principal research projects currently ongoing at the Carboncopies Foundation. The Challenge aims to address the principal remaining hurdle to whole brain emulation: How to translate collected brain data to a working model that is a verifiably correct emulation of the biological source. Our Challenge offers a way for every lab or researcher working on methods of such Translation to compete and test their performance.</p> <p>Neuroscientists need ways to test methods using well understood data sets and concrete validation metrics, just like computer vision methods in AI that are tested on artificial data (e.g. ImageNet) before being tested in the real world.</p> <p>For our Challenge:</p> <ol> <li>We generate neural circuits that carry out specific cognitive I/O functions, such as autoassociative memory or visual feature composition. We generate the detailed morphology of such a circuit using Netmorph, a neural outgrowth modeling platform developed by Randal Koene ((Netmorph, 2009)[https://pubmed.ncbi.nlm.nih.gov/19672726/]).</li> <li>We then embed the meaningful cognitive circuit within further detailing of artificial neural tissue (e.g. add glia, vasculature, etc).</li> <li>Using the BrainGenix Neural Emulation System (NES), we construct the completed artificial neural tissue model in 3D and carry out virtual data acquisition. We produce electron microscopy image data sets, calcium imaging data sets, and electrode recordings. These data sets are similar to the ones that researchers expect to obtain form biological samples.</li> <li>A challenge taker receives the virtual data, but not the underlying model. It is their task to reconstruct neural circuits within the data as they would in the case of a natural data set. We expect from them a proposed emulated neural system and the methods they used to derive it.</li> <li>We then evaluate the submission by comparing the structure of the proposed system with that of the original, and by comparing the I/O function of the emulation with that of the cognitively meaningful circuit that was hidden in the virtual tissue data. The best score is received if the underlying function is fully recovered. Challenge takers receive an error report with which to improve their methods.</li> </ol> <p>The process is described with more context in the video that introduces our challenge:</p> <p>Development of the Brain Emulation Challenge has proceeded at a good clip over the past year. We are still a few months shy of a proper launch, and we we're hoping to secure funding for challenge prizes. At this time, we are able to generate meaningful circuits with Netmorph and are about to test data generation from virtual tissue containing those circuits.</p> <p>For an example of a small autoassociative neural circuit generated with Netmorph for use in the Challenge, see here:</p> <p>To learn more about the challange please see our website and Gitlab.</p>"},{"location":"Newsletter/MayJuly2024/#2024-whole-brain-emulation-workshop","title":"2024 Whole Brain Emulation Workshop","text":"<p> Dr. Randal A. Koene speaking at the Whole Brain Emulation conference hosted by the Foresight Institute in Berkeley, California. To view Dr. Koene's Presentation Click here - https://foresight.org/summary/randall-a-koene-an-mvp-of-the-wbe-challenge-whole-brain-emulation-workshop-2024/</p>"},{"location":"Newsletter/MayJuly2024/#carboncopies-website-update","title":"Carboncopies Website Update","text":"<p>The Carboncopies website was recently overhauled to improve the user experience and to provide a more streamlined interface. Formerly the website was run through WordPress, but now relies on MkDocs, an open source website framework  hosted through our own servers. We updated our website with the intention to be modern, functional, and extremely fast.</p> <p>Interested in checking it out? Click here - https://Carboncopies.org</p>"},{"location":"Newsletter/MayJuly2024/#braingenix-website-update","title":"BrainGenix Website Update","text":"<p> With the updating of the Carboncopies website, we decided that it was time to give the BrainGenix website a shiny polish. Using the same framework, MkDocs, we remodeled BrainGenix.org. For the update we prioritized clear communication about what BrainGenix offers and designed our website to ensure easy navigation of our software.</p> <p>Interested in checking it out? Click here - https://BrainGenix.org</p>"},{"location":"Newsletter/MayJuly2024/#video-streaming-platform","title":"Video Streaming Platform","text":"<p>Through the usage of MediaCMS, an open source video streaming platform that we run locally we have been able to create a Youtube-like platform run completely by us.</p> <p>Interested in checking it out? Click here - https://videos.carboncopies.org</p>"},{"location":"Newsletter/MayJuly2024/#recent-blogs","title":"Recent Blogs","text":"<p>A reason to hedge on whole-brain emulation for AGI Randal Koene, June 18, 2024</p> <p>Why Whole Brain Emulation isn't a threat to humanity Jason Wong, June 6, 2024</p>"},{"location":"Newsletter/MayJuly2024/#volunteers-needed","title":"Volunteers Needed","text":""},{"location":"Newsletter/MayJuly2024/#featured-scientific-publications","title":"Featured Scientific Publications","text":"<p>Comparative prospects of imaging methods for whole-brain mammalian connectomics, Logan Thrasher Collins, Randal Koene</p> <p>Light-microscopy based dense connectomic reconstruction of mammalian brain tissue, Tavakoli, et al.</p>"},{"location":"Newsletter/MayJuly2024/#ccf-board-member-keith-wileys-recent-book-release","title":"CCF Board Member Keith Wiley's Recent Book Release","text":"<p> After 10 months of much anticipated release Contemplating Oblivion, by Dr. Keith Wiley, has finally been released and is available for read! The book follows Lysandra a million year old person who seeks new conscious experiences, she eventually discovers something about consciousness that might change everything...</p> <p>Click here to find out more</p>"},{"location":"Newsletter/MayJuly2024/#stay-connected-with-the-carboncopies-foundation","title":"Stay Connected With the Carboncopies Foundation","text":"<p>Subscribe to our Newsletter</p> <p>Check out our social media here: X/Twitter, Facebook, Linkedin, Youtube.</p> <p>If you want to support the work being done at the CarbonCopies Foundation please consider donating.</p>"},{"location":"Research/","title":"Carboncopies Research","text":"<p>At Carboncopies, we're conducting various types of research. Please see the list below and feel free to get involved!</p>"},{"location":"Research/#brain-emulation-challenge","title":"Brain Emulation Challenge","text":""},{"location":"Research/#about","title":"About","text":"<p>The Brain Emulation Challenge will rapidly accelerate progress towards WBE through a series of challenges and prizes designed to focus, quantify, and grow the  structure-to-function field. Through rigorous validation metrics and performance scores, we can determine what methods work best and provide debugging feedback where they go wrong. </p>"},{"location":"Research/#impact","title":"Impact","text":"<p>Conversion of brain data to working emulations (operational models that satisfy WBE criteria) is almost non-existent. This \u2018Translation\u2019 from data to model parameters is the final step to end-to-end examples of brain emulation. End-to-end examples will cause explosive growth in the field, as more people see the real and immense potential of the technology. Unfortunately, Translation is very hard, because evaluating how well a Translation method works is very difficult without a known correct result, i.e. without fully known ground-truth.</p> <p>Therefore, we propose the WBE challenge - directly addressing these issues. Challenge data sets with fully understood images (e.g. ImageNet) were critical to the rapid development of computer vision. Our generated virtual brain samples containing a fully understood functional neuronal network allow us to apply validation metrics based on rigorous success criteria. With that, we can score the performance of an attempted translation from virtual brain data to a running emulation, and provide precise feedback about errors made.</p> <p>Our challenge will encourage friendly standardized academic competition within the field, driving innovation by setting clearly defined goals and rewards. With each iteration of the challenge, we create more-realistic and complex datasets that build participants up to the real-deal. This step-wise approach would allow participants to systematically debug and improve their methods, further accelerating their development.</p>"},{"location":"Research/#braingenix-platform","title":"BrainGenix Platform","text":""},{"location":"Research/#about_1","title":"About","text":"<p>The BrainGenix initiative exists to create and maintain a comprehensive software platform specifically designed to enable and accelerate WBE research.</p>"},{"location":"Research/#impact_1","title":"Impact","text":"<p>Currently there are no existing platforms designed to address the interdisciplinary challenges presented by Whole Brain Emulation research. The BrainGenix platform seeks to change that by providing extensive libraries, tools, and other software needed to rapidly test and develop different aspects of WBE research.</p> <p>In our BrainGenix group, software of the Generative Meta-Analysis platform is being developed to support the WBE Challenge, which requires both high-performance simulation of large-scale compartmental neuronal networks and a highly-realistic virtual brain data acquisition system. Many of these tasks are computationally non-trivial, which only adds to the difficulty in conducting WBE research.</p> <p>We seek to change that by taking the computational complexity out of the equation - our platform focuses on being fast and reliable, removing the need for researchers to worry about making code scale.</p>"},{"location":"Research/#ethics-framework","title":"Ethics Framework","text":"<p>Whole Brain Emulation (WBE) is the theoretical process of scanning, modeling, and reproducing the entire functional organization of a human brain in a computational substrate, allowing for the recreation of cognition, memory, and potentially consciousness. If realized, WBE would represent a historic leap in neuroscience, artificial intelligence, and human self-understanding. However, such potential comes with profound ethical questions. The development and application of WBE involves intimate engagement with the human mind \u2014 raising urgent concerns about identity, consent, consciousness, suffering, personhood, and social justice.</p> <p>The Ethics Framework project exists to ensure that the advancement of WBE technology is aligned with human dignity, scientific integrity, and global justice. It provides a structured set of principles and guidelines for ethical research, responsible deployment, and inclusive governance of WBE systems.</p> <p>Early insights from work on an Ethics Framework have shown that the presuppositions upon which such a framework rests are based in fundamental core questions about whole brain emulation of a metaphysical nature. Questions such as:</p> <ul> <li>What is consciousness, and what sorts of intelligent structures can manifest consciousness?</li> <li>How is it that subjective experience comes about, that there can be an inner world of awareness?</li> <li>What is the nature of personal identity? How is that affected by strange new possibilities that whole brain emulation can bring about?</li> </ul> <p>These questions are not at all trivial, especially, from the point of view of the ethical consequences and impacts of specific choices in the development of whole brain emulation. Of course these questions are relevant in many ways beyond WBE, for example, in artificial intelligence, where - as in the case of non-human animals - we must understand when one should presume that conscious experience, and an accompanying sense of well being vs suffering can and may exist. Furthermore, when whole brain emulatin technologies are applied medically, offering future patients a procedure that results in living with non-biological (possibly digital) brain, one seeks high confidence that a neuroprosthetic brain provides not only consciousness, but also the inner experience of subjective awareness that defines what it is to be human.</p> <p>For this reason, the Ethics Framework project group is partnering with our Consciousness &amp; Subjective Experience journal club collaboration to carefully explore leading and most parsimonious theoretical explorations in these fields.</p>"},{"location":"Research/#whole-brain-emulation-roadmap","title":"Whole Brain Emulation Roadmap","text":"<p>Our Whole Brain Emulation (WBE) Roadmap update group is a collaborative partnership between the Carboncopies Foundation and experts at universities in the US and Europe, and is working on an update of a forward-looking roadmap towards whole brain emulation. The first WBE roadmap manuscript was published in 2008 by the Future of Humanity Institute, Oxford University, edited by Dr. Anders Sandberg and Prof. Nick Bostrom. It was a compilation of articles contributed in a follow-up report to the First Whole Brain Emulation Workshop at Oxford University, by workshop participants John Fiala, Robin Hanson, Kenneth Jeffrey Hayworth, Todd Huffman, Eugene Leitl, Bruce McCormick, Ralph Merkle, Toby Ord, Peter Passaro, Nick Shackel, Randal A. Koene, Robert A. Freitas Jr and Rebecca Roache. You can download the 2008 manuscript here: https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf</p> <p>Many technical developments and advances in understanding have come along in the years since the 2008 publication. The WBE Roadmap update group aims to publish a significantly revised, updated, and for some topics, extended roadmap. This update requires input from leading experts in numerous fields, insights gathered through a series of workshops, and the selective publication of individual sections in peer reviewed academic journals. During this process, the WBE Roadmap update group will make available on our affiliate site wholebrainemulation.org the pre-print manuscripts of roadmap sections seeking public comment, as well as finalized and/or published sections.</p>"},{"location":"Research/EthicsFramework/","title":"EthicsFramework","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Resources/","title":"Education","text":"<ul> <li> <p>Learn</p> <p> Learn about Neuroscience and WBE</p> </li> <li> <p>Media</p> <p> Watch our many recorded videos</p> </li> <li> <p>Lectures</p> <p> Find lectures about WBE</p> </li> <li> <p>Writing</p> <p> Books and posts about WBE</p> </li> <li> <p>Podcast</p> <p> Listen to podcasts</p> </li> </ul>"},{"location":"Resources/BoGitLaboks/","title":"BoGitLaboks","text":"<p>Our GitLab:</p> <p>https://gitlab.braingenix.org/</p>"},{"location":"Resources/Books/","title":"Books","text":""},{"location":"Resources/Books/#intelligence-unbound","title":"INTELLIGENCE UNBOUND","text":""},{"location":"Resources/Books/#the-future-of-uploaded-and-machine-minds-by-russell-blackford","title":"THE FUTURE OF UPLOADED AND MACHINE MINDS BY RUSSELL BLACKFORD","text":"<p>2014</p> <p>Intelligence Unbound explores the prospects, promises, and potential dangers of machine intelligence and uploaded minds in a collection of state-of-the-art essays from internationally recognized philosophers, AI researchers, science fiction authors, and theorists. Compelling and intellectually sophisticated exploration of the latest thinking on Artificial Intelligence and machine minds Features contributions from an international cast of philosophers, Artificial Intelligence researchers, science fiction authors, and more Offers current, diverse perspectives on machine intelligence and uploaded minds, emerging topics of tremendous interest Illuminates the nature and ethics of tomorrow\u2019s machine minds\u2014and of the convergence of humans and machines\u2014to consider the pros and cons of a variety of intriguing possibilities Considers classic philosophical puzzles as well as the latest topics debated by scholars. Covers a wide range of viewpoints and arguments regarding the prospects of uploading and machine intelligence, including proponents and skeptics, pros and cons.</p> <p></p>"},{"location":"Resources/Books/#a-taxonomy-and-ethics-of-mind-uploading","title":"A TAXONOMY AND ETHICS OF MIND-UPLOADING","text":""},{"location":"Resources/Books/#by-keith-wiley","title":"BY KEITH WILEY","text":"<p>2014</p> <p>Mind Uploading: The process of transferring one's mind from the brain to a new substrate, generally a computer. It is the stuff of science fiction, immediately recognizable in contemporary literature and cinema. However, it has also become increasingly respectable--or at least approachable--within technological, neurological, and philosophical circles. This book begins with a rich taxonomy of hypothetical procedures by which mind-uploading might be achieved, even if only in the realm of thought experiment. This is likely the most thorough collection of such procedures yet compiled and should form the basis of any reader's personal philosophy of mind and mind-uploading. It then offers one such philosophy of mind, along with an analysis and interpretation of the scenarios in the taxonomy through the lens of this philosophy. This book will be an important component of any curious reader's developing philosophy of mind and mind-uploading.</p>"},{"location":"Resources/FacebookGroup/","title":"FacebookGroup","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Resources/Learn/","title":"Learn","text":"<p>For many people, the best way to learn something is while interacting with an experienced and attentive mentor. University courses, whether on campus or online are the \"go-to\" for that opportunity. Not everyone can afford the time or the expense to manage a class schedule. Here are some recommended alternatives.</p>"},{"location":"Resources/Learn/#do-you-want-to-teach-yourself-neuroscience","title":"Do you want to teach yourself neuroscience?","text":"<p>The following resources are all completely free and available online.</p> <p>Mini-Course on Whole-Brain Emulation </p> <p>Science of the Brain: An Introduction for Young Students (BNA)</p> <p>Neuroscience Online, an Open-Access Neuroscience Electronic Textbook</p> <p>The Brain Facts Book by the Society for Neuroscience</p> <p>The free online course by Harvard University: Fundamentals of Neuroscience course</p> <p>More free online courses in the edX series: https://www.edx.org/learn/neuroscience</p>"},{"location":"Resources/Lectures/","title":"LECTURES","text":""},{"location":"Resources/Lectures/#advances-towards-substrate-independent-minds","title":"ADVANCES TOWARDS SUBSTRATE-INDEPENDENT MINDS","text":""},{"location":"Resources/Lectures/#methodology-at-carboncopies","title":"METHODOLOGY AT CARBONCOPIES","text":"<p>Neural interfaces, Neural Prostheses and Whole Brain Emulation</p>"},{"location":"Resources/Lectures/#a-new-strategy-for-human-evolution-congress-proceedings","title":"A NEW STRATEGY FOR HUMAN EVOLUTION, CONGRESS PROCEEDINGS","text":""},{"location":"Resources/Lectures/#2045-strategic-social-initiative","title":"2045 STRATEGIC SOCIAL INITIATIVE","text":"<p>This is the Advance Release version (0.71a) of the Congress Proceedings &amp; Transcripts for Global Future 2045: Towards a New Strategy for Human Evolution. The Advance Release version contains some \u2013 but not all \u2013 transcripts of talks given at the Congress.</p>"},{"location":"Resources/Lectures/#humanity-plus-youtube-videos","title":"HUMANITY PLUS YOUTUBE VIDEOS","text":""},{"location":"Resources/Lectures/#humanity-hong-kong","title":"HUMANITY HONG KONG","text":"<p>Videos of conference presentations, interviews with interesting people, montages of ideas, attempts at short documentaries, and other amazing collections.</p>"},{"location":"Resources/Lectures/#randal-koene-substrate-independent-minds","title":"RANDAL KOENE - SUBSTRATE-INDEPENDENT MINDS","text":""},{"location":"Resources/Lectures/#singularity-summit","title":"SINGULARITY SUMMIT","text":"<p>Dr. Koene presents the concept of substrate-independent minds (SIM) and gives an outline of a feasible approach to SIM by means of whole brain emulation.</p>"},{"location":"Resources/Lectures/#aig-and-neuroscience","title":"AIG AND NEUROSCIENCE","text":""},{"location":"Resources/Lectures/#agi-2011-google-techtalks","title":"AGI 2011 Google TechTalks","text":"<p>AGI conference at Google.</p>"},{"location":"Resources/Lectures/#towards-tractable-agi-challenges-for-system-identifiction-in-neural-circuitry","title":"TOWARDS TRACTABLE AGI: Challenges for System Identifiction in Neural Circuitry","text":""},{"location":"Resources/Lectures/#httpwwwwinterintelligenceorg-winter-intelligence-2012-oxford-university","title":"http://www.winterintelligence.org/ Winter Intelligence 2012 Oxford University","text":"<p>The AGI conferences are the only major conference series devoted wholly and specifically to the creation of AI systems possessing general intelligence at the human level and ultimately beyond. By gathering together active researchers in the field, for presentation of results and discussion of ideas, we accelerate our progress toward our common goal.</p>"},{"location":"Resources/Lectures/#the-neuroscientist-who-wants-to-upload-humanity-to-a-computer","title":"THE NEUROSCIENTIST WHO WANTS TO UPLOAD HUMANITY TO A COMPUTER","text":""},{"location":"Resources/Lectures/#popular-science","title":"Popular Science","text":"<p>Interview write-up by Adam Piore.</p>"},{"location":"Resources/Media/","title":"Media","text":"<p>Please enjoy our video collection on whole-brain emulation and many related topics.</p> <p>Visit our media server at https://videos.carboncopies.org.</p> <p></p> <p>Or visit our Youtube channel.</p> <p></p> <p>A few videos from our old Youtube channel have not yet been moved to the new one.</p> <p>Note</p> <p>Links to featured media listed below will be restored shortly.</p> <p>FUTURE SCIENCE PROJECT | An Interview with Randal Koene 2018</p> <p>The above video was created by Mika Mautner, a student and researcher for Carboncopies. It features an interview with Randal Koene who describes the current state of neuroscience as it relates to Whole Brain Emulation or mind uploading. YOUR ANIMAL LIFE IS OVER MACHINE LIFE HAS BEGUN. THE ROAD TO IMMORTALITY THE GUARDIAN 2017</p> <p>In California, radical scientists and billionaire backers think the technology to extend life \u2013 by uploading minds to exist separately from the body \u2013 is only a few years away. THE FALLACY OF FAVORING GRADUAL REPLACEMENT MIND UPLOADING OVER SCAN AND COPY INSTITUTE OF ETHICS AND EMERGING TECHNOLOGIES 2015</p> <p>This paper demonstrates a chain of reasoning that establishes metaphysical equivalence between these two methods in terms of preserving personal identity. The Neuroscientist Who Wants To Upload Humanity To A Computer Popular science 2014</p> <p>Read about Dr. Randal Koene recruiting top neuroscientists to help him make humans live forever. Breakthrough philanthropy Thiel foundation 2014</p> <p>Watch the entire program of this innovative event, featuring the most visionary non-profits innovating in service of humanity. Randal Koene on whole brain emulation Machine learning research institute 2014</p> <p>An interview with the Machine Learning Research Institute and Dr. Randal Koene on Whole Brain Emulation. EXPERIMENTAL ENHANCEMENT OF NEUROPHYSIOLOGICAL FUNCTION FRONTIERS IN SYSTEM NEUROSCIENCE 2014</p> <p>Enhancing brain function entails controlling neuronal function. There are several methods available for this which led to some relevant experimental data. Read about them here. WINTER INTELLIGENCE CONFERENCE FUTURE OF HUMANITY INSTITUTE 2013</p> <p>Watch Dr. Koene discuss Substrate Independent Minds. SUBSTRATE-INDEPENDENT MINDS ISSUES MAGAZINE 2012</p> <p>In pursuing a Utopian world of perfect post-humans, we may irrevocably undermine what makes us human in the first place. Our lives are a composite of actions and experiences, and our minds depend on our bodies and the environment - but do they have to? RANDAL KOENE ON SUBSTRATE INDEPENDENT MINDS HUMANITY MEDIA 2011</p> <p>In this interview, Dr. Randal Koene gives a wonderful overview of the current state and future prospects of R&amp;D regarding substrate-independent minds. CARBONCOPIES-REALISTIC ROUTES TO SUBSTRATE-INDEPENDENT MINDS KURZWEIL ACCELERATING INTELLIGENCE 2010</p> <p>What might brains and minds look like in the future? Read how Carboncopies is offering a networking platform and hub around which experts in the individual fields relevant to ASIM can gather and exchange ideas. WHOLE BRAIN EMULATION, A ROADMAP THE FUTURE OF HUMANITY INSTITUTE AND OXFORD UNIVERSITY 2008</p> <p>Whole brain emulation (WBE), the possible future one\u2010to\u2010one modelling of the function of the human brain, is academically interesting and important for several reasons. Read about why in this roadmap WBE roadmap.</p>"},{"location":"Resources/NewsletterArchive/","title":"NewsletterArchive","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Resources/Twitter/","title":"Twitter","text":"<p>Note</p> <p>Due to a hosting provider mishap, this website is under re-construction. This page is pending.</p>"},{"location":"Resources/Writing/","title":"Nondestructive Mind Uploading and the Stream of Consciousness","text":"<p>2023 by Keith Wiley</p> <p>A common interpretation of wakeful, nondestructive mind uploading is that the person with the postoperative original body exclusively persists the preoperative identity and that the person with the upload\u2019s body is some sort of identity copy. A frequent argument supporting this claim is that the preoperative person\u2019s stream of consciousness attaches exclusively to the postoperative person with the original body. This paper revisits this argument to show its weaknesses, and offers a more consistent interpretation via an alternative identity model: branching psychological identity.</p>"},{"location":"Resources/Writing/#the-stream-of-consciousness-and-personal-identity","title":"The Stream of Consciousness and Personal Identity","text":"<p>2019 by Keith Wiley</p> <p>This paper marks the five-year anniversary of the publication of Wiley\u2019s book, A Taxonomy and Metaphysics of Mind-Uploading, and further explores the concept of a stream of consciousness and its implications for various forms of mind uploading.</p>"},{"location":"Resources/Writing/#transcending-biology-reverse-engineering-the-brain","title":"Transcending Biology: Reverse Engineering the Brain","text":"<p>2018 by Keith Wiley</p> <p>Summary of the Roadmap session of the first 2018 Carboncopies workshop on whole brain emulation.</p>"},{"location":"Resources/Writing/#response-to-j-bonillas-your-mind-will-never-be-uploaded-to-a-computer","title":"Response to J. Bonilla\u2019s \u2018Your mind will never be uploaded to a computer\u2019","text":"<p>2018 by Keith Wiley</p> <p>A response to Bonilla\u2019s 2017 article questioning the technical plausibility of mind uploading</p>"},{"location":"Resources/Podcast/Index/","title":"Carboncopies Podcast","text":""},{"location":"Resources/Podcast/Index/#carboncopies-podcast","title":"Carboncopies Podcast","text":"<p>You can now access our workshops and the continuing conversation on whole brain emulation on Spotify.</p> <p>Starting with Episode 10 of the Carboncopies Podcast, our music is Little Idea by Scott Holmes Music, licensed under an Attribution-NonCommercial 4.0 International License.</p> <p>Listen on Spotify</p>"},{"location":"Resources/Podcast/Episodes/10_FromBrainPreservation/Post/","title":"10 - Introduction from Brain Preservation to Reconstruction","text":"<p>In this new episode of the Carboncopies Podcast, Dr. Randal Koene, founder of the Carboncopies Foundation, will explain the technical process of achieving whole brain emulation from a preserved brain.</p> <p></p>"},{"location":"Resources/Podcast/Episodes/11_WhyWBEFromYourBrainIsProbablyYou/Post/","title":"11 - Why WBE From Your Preserved Brain is Probably You","text":"<p>In this new episode of the Carboncopies Podcast, Dr. Keith Wiley discusses why a Brain Emulation from your preserved brain is probably you.</p> <p></p>"},{"location":"Resources/Podcast/Episodes/9_/Post/","title":"Post","text":"<p>In this new episode of the Carboncopies Podcast, Dr. Randal Koene, founder of the Carboncopies Foundation, will explain the technical process of achieving whole brain emulation from a preserved brain.</p> <p></p>"},{"location":"Resources/Writing/2018_Response/Post/","title":"Response to J. Bonilla\u2019s \u2018Your mind will never be uploaded to a computer\u2019","text":"<p>Keith Wiley, Nov. 2018</p> <p>In September, 2017, professor of philosophy of science Jes\u00fas Zamora Bonilla published an article on the Mapping Ignorance website titled \u2018Your mind will never be uploaded to a computer\u2019 [Bonilla 2017]. The counterpoint to many of Bonilla\u2019s claims has already been offered in existing literature. Nevertheless, I provide the following response in an effort to move the ongoing metaphysical philosophy forward, if possible. In fact, this response is longer than the original article, but I feel it offers a good opportunity to introduce and present these topics to a broader audience.</p> <p>The first claim in Bonilla\u2019s article is that the mind is not necessarily tantamount to information because certain biological functions, such as digestion, are not information, nor would an electronic copy of a person be capable of true digestion. Searle had used the same example of digestion before [Searle 1990], while variants such as the wet status of simulated water, the windy status of simulated tornadoes, the hot status of simulated fire, and the photochemical status of simulated photosynthesis have all been similarly raised [Azarian 2016, Berger &amp; Koch 2014, Gennaro 2017]. Admittedly, Bonilla appears to be less concerned with the reality status of simulations and more with the purported equivalency between physical processes and information (or presumably information processing). I will connect these two concepts in the next paragraph. My response to the claim of incomplete reality status of simulations is that otherwise physical processes within a given reality can be conceived as information-driven simulations in another reality. A simulated virtual creature in a virtual world, modeled on its own consistent physical laws, simultaneously simulates digestion as viewed by us from the outside and also has a true experience of digestion from its own internal point of view. Both interpretations are valid at the same time. Consider that there is a lively ongoing debate as to whether our own reality is some form of simulation within an outer reality [Moskowitz 2016]. I have always found this distinction and the associated question specious since any reality is real from the inside. It means nothing to say we live in a simulation from our own point of view; reality is what we experience it to be. Our phenomenal experience lies beyond the reach of anyone else\u2019s denial, as Descartes\u2019 famous dictum settled centuries ago: I experience digestion, therefore I digest.</p> <p>To Bonilla\u2019s claim that the mind is not information (or information processing) because digestion is not information, the reader can now see how I state the contrary position. Digestion is, in fact, information processing after all. Any physical process or phenomenon can simultaneously be real from an internal frame of reference and be a simulated information process from an external frame of reference. The mind is an informational process precisely because its transfer functions can be achieved computationally.</p> <p>The next claim is that it would require quantum computers to reproduce neural processes. This claim was first brought to broad awareness by Penrose and Hameroff [Penrose 1994], and has been thoroughly considered in the passing years. Much of the discussion has disagreed with Penrose and Hameroff, concluding that quantum mechanics plays no crucial role in how the brain processes sensory information, stores and retrieves memory, or generates behavior. Its role in the phenomenon of consciousness remains similarly dubious. At best, we certainly needn\u2019t conclusively presume the necessity of a quantum mechanical prosthetic brain as Bonilla decisively phrases it. Rather, we may interpret the question as unresolved. Furthermore, even if quantum computers are required for a successful prosthetic brain, we will simply utilize such technology as deemed appropriate. Such confidence may seem blusterous at current technological levels, but blind, unintentional evolution\u2019s capability to produce the brain, quantum mechanical or otherwise, proves the plausibility of an engineered equivalent by reason of prototype. Whatever already exists must be possible to exist.</p> <p>The next claim perplexingly argues that mind uploading is a large undertaking and therefore is apparently unachievable. While it is true that inventing the prosthetic brain will involve tremendous complexity, it is nevertheless an unhelpful observation with regard to likely outcomes. At any point in history, the current technology would appear essentially unachievable to residents of earlier eras. Arthur C. Clarke gave this observation its most famous adage when he drew an equivalency between futuristic technology and magic [Clarke 1973]. Yet Bonilla argues that the challenge of building computers on par with the brain\u2019s scale is reason in itself to judge the near-impossibility of the task. To the contrary, there is no apparent evidence that engineering projects of the scale of the brain exceed the reach of technological advancement.</p> <p>This argument about the technical difficulty of the task occurs in a different form later in the article, where it presents the challenge of cloning a human body and copying a brain scan into some sort of empty brain vessel. Of course, most speculations about mind uploading do not involve biologically grown or cloned bodies and brains, preferring depictions of computerized brains and robotic bodies. Consequently, Bonilla\u2019s biological scenario seems out of place with regard to popular mind uploading speculation. This is not an inconsequential distinction since it may be considerably easier to engineer artificial systems from scratch than to attempt to recreate and maintain the chaotic biological results of billions of years of blind natural selection, which were never overseen with any attention to direct manufacture or maintenance.</p> <p>Bonilla\u2019s next objection to the plausibility of mind uploading is that we can never understand how the brain processes information because we lack a neural code Rosetta stone. Consequently, any endeavour to solve this problem is fundamentally flawed. By analogy, he suggests that decoding a music CD would be impossible without already having a CD player\u2019s software, and similarly that translating audio recordings of ancient spoken conversation is impossible without additional information about the speakers\u2019 language. To begin, the analogies are flawed. The brain involves no additional missing hardware, or otherwise helpful information, as in the CD-vs-player dichotomy. More accurately, given both a CD and a CD player, sufficiently advanced investigative technology could quite likely decipher how the assemblage operates. Ancient languages similarly involve additional, unrecoverable information in the unwritten, transient, societal agreement on the semantic meaning of arbitrary vocalizations. Much of the information crucial to deciphering ancient vocal recordings is simply missing from the recordings; it was encoded in the long-lost brains of the original speakers. I have previously discussed this information written across the population of brains comprising a society\u2019s knowledge in my book [Wiley 2014]. Studying how the brain works faces no corresponding challenge of missing information. Everything about the brain lies there before us to scrutinize to our heart\u2019s content.</p> <p>Furthermore, to say we know nothing about how the brain processes information, and furthermore never could, is an astonishing statement. The principal goal of modern neuroscience is to solve precisely this problem and we have made great progress toward unweaving the connectionist algorithms by which numerous regions of the brain transform information from one representation into another, with ever deeper levels of the cortical processing system representing increasingly abstract cognitive concepts. There are many techniques and tools available for analyzing and comprehending neural function. In the worst case, even the most opaque information processing system can still be modeled in terms of its input/output functions. This approach closely mirrors behavioral psychology, but can just as easily be applied to raw mathematical functions, especially in terms of system identification, in which all inner details are abstracted away, leaving only their input and output data and the inferred transfer functions.</p> <p>Some readers may counter that knowledge of input/output datastreams is insufficient to a complete neuroscience, that some critical aspect of the mind is not captured by such analysis, and rather that a complete neuroscience requires additional knowledge of the internal processing mechanism by which an input/output function is achieved. First, as just stated, the brain is not remotely a black box. We scan, dissect, stimulate, observe, and measure neural function at all levels, from the whole brain down to individual neurons, and even synapses, neurotransmitters, and ion channels. We already have an excellent understanding of how neurons operate chemically and electrically, and this knowledge is constantly improving. So we don\u2019t have to treat neural components as black boxes; we can actually learn how they work.</p> <p>Second, internal knowledge always drops you to the next level of abstraction. Once we know how the brain is wired, we still wonder how neurons work. Then we still wonder how molecules work. Then atoms, then quarks. Detractors of the you-know-nothing-if-don\u2019t-know-everything persuasion can always move this goal post down one level. It is therefore a lost cause to engage this claim with much earnest. Eventually we must determine a limiting level below which we admit we have lost sight of the forest for the trees. At whatever level we draw that line, we are black-boxing the underlying mechanisms from that point on. Thankfully, the determination of the correct level of abstraction needn\u2019t be ad hoc; it can be achieved experimentally. If we set our limiting level at the neural code level, then build models on that theory, and the models fail to reproduce the functions and behaviors observed in biological brains, we will know we have set our limit too high. If we set our level at the absurd quark level, model accordingly, and produce corresponding models that are indistinguishable from brains, we will know we have chosen a level at or below the necessary level. At that point, we can even explore back up the abstraction hierarchy to see if we can get similar results for less effort.</p> <p>Third, it is not clear what additional information should be required, metaphysically speaking, to claim a sufficient understanding of how the brain works. Tononi has suggested that a concept of integrated information must be measured and that certain internal mechanisms will reveal higher degrees of integrated information than others, despite performing identical functions [Tononi 2004]. In other words, Tononi would judge two systems that perform identical input/output functions as having different levels of consciousness, and associated success in mind uploading\u2019s purported goals, based on the internal differences of how the two systems perform the transfer functions. Searle has similarly described with his Chinese Room argument how a black box system, or certain partial components of such a system, such as the person inside of the room, might be interpreted as lacking nuanced metaphysical properties that we would prefer our prosthetic brains to preserve [Searle 1980]. Tononi\u2019s and Searle\u2019s arguments have been debated at length in the literature and are not remotely settled in their favor yet. At the current time, it is reasonable to consider that the functional aspects of the brain, and even the metaphysics of consciousness, at least might be fully represented with input/output information processing terminology, if for no better reason than that that is how the brain appears to actually operate.</p> <p>The next claim is that a brain requires complex interaction with its environment in order to matter in some way that mind uploading would fail to capture. This is the argument of embodied cognition, the claim that brains, and by extension minds, only operate properly in the context of an associated body and its sensory-motor interactions with the physical world [Lakoff 1980]. At first glance, it is not clear how this claim challenges mind uploading since an obvious scenario involves equipping a mind upload with a prosthetic brain in a robotic body. However, it is an interesting metaphysical question whether such a physical system should an absolute requirement for successful mind uploading. An obvious alternative, likely the one that inspired Bonilla\u2019s challenge, is to process an uploaded mind\u2019s neural functions on a computer that is not necessarily attached to any robotic body. There is the follow-up question of whether such a mind would nevertheless require at least a simulated virtual body in a virtual 3D world, or whether such a mind could simply float around in the intangible nonspatiality of abstract thought space. This last possibility impinges on the medical state of locked-in syndrome, which in the most extreme cases can leave a healthy mind completely disconnected from sensory and motor access.</p> <p>There are a few places along this spectrum where one may fall. Some people believe that real physical embodiment is required for successful mind uploading, that virtual embodiment in a virtual world is insufficient in some metaphysical sense. Others would interpret existence in a virtual 3D world as adequate for the metaphysical properties under consideration, but would still reject the further case of total sensorimotor disconnection as insufficient. However, as described above, we can brush all these deeper questions aside by confining our consideration of mind uploading to a fully embodied and physical robotic scenario. Whether the increasingly nonphysical or disembodied scenarios fail some fundamental metaphysical test, and whether such a test could ever be quantified in a falsifiable and detectable way, is a question we simply don\u2019t have to resolve today. Robotic brains and bodies will suffice in the meantime.</p> <p>The science, engineering, and philosophy of mind uploading are areas rich with speculation, prediction, and debate. Our knowledge of how the brain works is steadily advancing in the twenty-first century. One popular response is an Icarusian, Huxleyian, Shelleyian premonition that the brain either will, or morally should, remain an inscrutable domain of mystery. However, the actual progress coming out of neuroscience supports no such dire conclusion. The engineering to replicate natural systems is steadily progressing toward the eventual capability to engineer at the microscopic scale as well as achieve the macroscopic organizational complexity of vast neural systems. On the purely metaphysical questions, theories of consciousness, mind, and identity have continued to evolve over time. The writings on consciousness of the last half century have no comparison in antiquity. Concerns of substance dualism have been thoroughly jettisoned from respectable discourse, as shown in the treatises by Dennett, Chalmers, Koch, Searle, and others. Subtle questions, such as the thorny nature of epiphenomenalism, are barely a hundred years old. The careful presentation of the hard problem of consciousness, both Nagel\u2019s contribution in the 1970s and Chalmers\u2019 in the 1990s, are recent additions to the discussion. Penrose and Hameroff\u2019s proposal, and Tononi and Koch\u2019s proposal, regardless of whether one finds purchase in such ideas, nevertheless indicate vibrant ongoing exploration of the nature of the mind and consciousness. For those of a physicalist, functionalist, and patternist persuasion concerning the mind, not only is mind uploading possible, it is inevitable.</p> <p>Azarian, B. (2016) A neuroscientist explains why artificially intelligent robots will never have consciousness like humans. Raw Story.</p> <p>Berger, K. and Koch, C. (2014) Ingenious: Christof Koch. The neuroscientist tackles consciousness and the self. Nautilus (19). http://nautil.us/issue/19/illusions/ingenious-christof-koch</p> <p>Bonilla, J. Z. (2017) Your mind will never be uploaded to a computer. Mapping Ignorance. https://mappingignorance.org/2017/09/11/mind-will-never-uploaded-computer/</p> <p>Clarke, A. C. (1973) Hazards of prophecy. In Profiles of the Future: An Inquiry into the Limits of the Possible. Harper &amp; Row.</p> <p>Gennaro, R. J. (2017) Consciousness. Routledge, 173\u2013174.</p> <p>Lakoff, G. and Johnson, M. (1980) Metaphors we live by. Univ. Chicago Press.</p> <p>Moskowitz, C. (2016) Are we living in a computer simulation? Scientific American. https://www.scientificamerican.com/article/are-we-living-in-a-computer-simulation/</p> <p>Penrose, R. (1994) Shadows of the mind: A search for the missing science of consciousness. Oxford Univ. Press.</p> <p>Searle, J. (1990) Is the brain\u2019s mind a computer program? Scientific American (262):1, 25\u201331.</p> <p>Searle, J. (1980) Minds, brains, and programs. Behavioral and Brain Sciences (3), 417\u2013424.</p> <p>Tononi, G. (2004) An information integration theory of consciousness. BMC Neuroscience (5):42.</p> <p>Wiley, K. (2014) A Taxonomy and Metaphysics of Mind-Uploading. Humanity+ Press and Alautun Press.</p>"},{"location":"Resources/Writing/2018_TranscendingBiology/Post/","title":"Transcending Biology: Reverse Engineering the Brain","text":""},{"location":"Resources/Writing/2018_TranscendingBiology/Post/#summary-of-the-roadmap-session-of-the-first-2018-carboncopies-workshop-on-whole-brain-emulation","title":"Summary of the Roadmap session of the first 2018 Carboncopies workshop on whole brain emulation","text":""},{"location":"Resources/Writing/2018_TranscendingBiology/Post/#keith-wiley-2132018","title":"Keith Wiley, 2/13/2018","text":"<p>Will we one day be able to construct a computational model of an individual\u2019s brain such that we can say the working model re-instantiates that person\u2019s distinct mental functions? Will we be able to further interpret that model as a preservation of personal identity and even of life? These two concepts, known respectively as whole brain emulation (WBE) and mind uploading (MU), were the focus of the nonprofit organization Carboncopies\u2019 first workshop of 2018, held on January 28<sup>th</sup>, titled Transcending Biology: Reverse Engineering the Brain. Carboncopies\u2019 stated purpose is \u2018making whole brain emulation possible\u2019. The workshop was freely viewable online by the general public, as well as in person on site in the Bay area. URLs for videos of the individual talks are provided at the bottom of this article. An impressive group of professional scientists, all leaders in their respective fields, gathered on this day to present the state of the art in technologies that represent the nascent stages of eventual WBE.</p> <p>The workshop opened with an introduction by Dr. Randal Koene, founder and Chairman of Carboncopies. Koene began with a brief explanation of the feasibility of WBE, describing how it is the cognitive experience that matters when prioritizing aspects of the brain, not the underlying neural structure and function of which we are not directly aware. By analogy, internet browsers operate at the level of code and design patterns, not transistors and electrical properties. Brain emulation is, in this way, analogous to emulation of a web browser across varying computing architectures. As to why humanity should desire and pursue WBE and MU, Koene argues that in the future, humans are likely to play a decreasing role in the ongoings of society, government, and the overall range of mental experiences. For humanity to keep up with the inevitable advance of artificial intelligence, we must expand our own mental capacity to access further realms of experience. As to how to achieve WBE from a technical perspective, many of the other speakers addressed current work, but Koene gave an overview of the larger picture and how it may pan out as contemporary methods continue to evolve. It all comes down to structural, but more importantly, functional, modeling of the brain by means comparable to nascent neural prostheses. Such devices, both current and futuristic, operate by modeling, replicating, and ultimately replacing corresponding neural function, one brain region at a time, until in the limit none of the organic structure remains. Note that for the development of a neural prosthesis, functional recording alone may not be enough; an understanding of the underlying circuit structure may be essential to make the modeling process feasible. Structure scanning to discover such neural circuit layout was discussed by subsequent speakers, as presented below. Eventually, this expanding knowledge may reach the point where we can seriously consider emulations of large portions of the brain to be within grasp, and even emulations of the whole brain in the extent of such reasoning. Koene described the goals of Carboncopies as first seeking and proposing methods toward WBE, and second, enabling researchers to pursue projects toward those proposed methods. Finally, Koene announced that Carboncopies was launching, as part of the workshop, a tech review project with the goal of maintaining a living roadmap of projects and progress. This tech review will seek peer-reviewed research into the technical aspects of WBE. Koene and Carboncopies hope that this workshop will be a call to arms for researchers to take up WBE research in earnest in the years to come.</p> <p>Following Koene\u2019s introduction, the first session of the workshop brought in external speakers to present on various aspects of neuroscience relevant to WBE. The session began with Dr. Kenneth Hayworth from Howard Hughes Medical Institute at Janelia. Hayworth runs the Brain Preservation Foundation (BPF), whose goal is to promote and advance long-term whole brain preservation. The BPF aims for the eventual establishment of brain preservation as a standard medical practice offered in hospitals for life-preserving (or life-stasis) purposes. The BPF is motivated by the likelihood that brain preservation might be achievable sooner than mind uploading, and can therefore be used to bridge the intervening timespan until mind uploading is possible. Early success toward the BPF\u2019s goals has been encouraging, the most noteworthy event being that, in 2016, the BPF awarded its first cash prize for achieving new milestones in brain preservation. This prize was won by Robert McIntyre\u2019s team at 21<sup>st</sup> Century Medicine for the electron-microscopy-verified (EM) preservation of a whole rabbit brain. Such a feat of peer-reviewed and verified, high-quality preservation of macro-scale neurophil (a whole brain in fact) had never been achieved previously. Not only does the BPF motivate research by others through its cash prizes, but Hayworth has himself pioneered the technological development of slicing and imaging machines for the subsequent scanning of preserved brains. Such imaging is an obvious critical step in one of the more likely mind uploading procedures, a procedure in which a stasis-preserved brain\u2019s structural scan is used as the basis for a subsequent WBE.</p> <p>Prof. Tony Zador of Cold Spring Harbor Laboratory then presented work using the most recent advances in DNA barcoding to map a brain\u2019s projectome. The projectome differs from the more widely recognized connectome in that the former traces the brain\u2019s general neurite extent, while the latter explicitly captures the individual synaptic connections that underlie the brain\u2019s interconnected network. Zador\u2019s work with DNA barcoding injects randomly generated DNA snippets from a vast library of possible base-pair combinations into localized populations of neurons. The DNA is replicated with a virus so as to fill a given neuron wherever that neuron\u2019s dendrites and axons may stretch, including far across the brain. The brain is then imaged such that each barcode is uniquely exposed via color or direct sequencing, thereby revealing the entire projected structure throughout the brain of the population of neurons hosted locally around the injection site. This technique has already been utilized by the well known Allen Brain Atlas. Zador further presented a nascent extension of this work that offers the possibility of using the same basic technique to map connectomes.</p> <p>Dr. Adam Marblestone, of MIT and Kernel, presented optical methods for molecular connectomics. This technique combines expansion microscopy, DNA barcoding, and in-situ fluorescent sequencing for the Rosetta Brain Project. Expansion microscopy is a clever method for increasing spatial resolution. It literally swells the brain so as to make the smallest features more resolvable than they would be at their original scale. While electron microscopy can achieve nanometer resolution, it cannot penetrate deeply into tissue, nor can it benefit from various optical imaging advantages, such as color labeling. Alternatively, optical imaging (classical microscope imaging) penetrates deeply and can utilize color, but cannot achieve the same resolution as electron microscopy. Expansion combines the best of both, bringing small features within reach of conventional optical microscopes such that DNA barcoding can be utilized. Another application of DNA barcoding is to assist the error-correction stage of neurite tracing, in which a neuropil volume is slice and scanned, and neurite structures are reconstructed by tracing through the scanned layers, classically with electron microscopy. This practice suffers in regions where neurite details get too small or neurites from multiple neurons become excessively intertwined. Appending such a practice with barcoding could greatly assist in resolving the errors that occur in such regions.</p> <p>Prof. Theodore Berger, from the University of Southern California, gave a wonderful presentation of the current state of the art in neural prosthetics. Berger\u2019s work focuses on the hippocampus, a deviously challenging region since it resides near the center of the brain, inside and beneath other regions. The hippocampus mediates the conversion of short term memories into long term memories, and damage here is implicated in some of our most problematic brain maladies, such as Alzheimer\u2019s, dementia, blunt force trauma, and stroke. Recent work has implicated depression in hippocampus defects as well. Affected patients have functional short term memories and retain earlier long term memories, but are weakened or prevented from forming new long term memories. Berger\u2019s prosthesis applies electrodes to two regions of the hippocampus, loosely labeled as the input and output areas. It learns the neural spatio-temporal firing code from which it is possible to learn the transformation function performed by these regions of the hippocampus and can actually take over or strengthen this transformation for a damaged hippocampus. In this way, the prosthesis revitalizes a patient\u2019s ability to form new long term memories. The work is still in the research stages, but has proceeded with great promise. Further advancements are expected, as is eventual standardization of a medical application. The implications are profound to say the least. This is precisely the sort of work that gives us a glimpse into the possible future of neural prostheses. One needs only a decent imagination to extrapolate such to the wilder possibilities. Namely, taking this concept to completion by replacing every brain region with an equivalent prosthesis is, in fact, whole brain emulation.</p> <p>Dr. Shawn Mikula, from the National Institute for Physiological Sciences in Okazaki, Japan,presented his work on taking serial section EM further than its historical applications. EM is generally limited to volumes on the order of one millimeter cubed, but Mikula has extended the technique to rodent brain scales with impressive results. Using a machine based on Hayworth\u2019s design, he has sliced and image a whole mouse brain using EM techniques. Mikula hopes to be able to image macroscale whole brains in a matter of weeks, which represents orders of magnitude speed up over the current estimates of years.</p> <p>The impressive work these researchers have done gives a good survey of the most advanced techniques currently available. It was a great pleasure not only to see presentations on what is possible today, but to hear these experts speak on the likely paths of advancement over the coming decades. The expectations are universally optimistic; we should expect to see these methods expand in capability, accessibility, and generality throughout the twenty-first century. The conclusion is clear. Preserving, scanning, imaging, mapping, and functionally reproducing the brain, better summarized as whole brain emulation, is a technology that is practically destined to come to fruition given sufficient interest and funding, and commitment.</p> <p>Keith wiley serves on the board of Carboncopies as director of communications. His book, A Taxonomy and Metaphysics of Mind-Uploading, is available on Amazon.</p> <p>The workshop\u2019s archived URL is https://www.carboncopies.org/workshop-2018-jan and includes links to the videos. The same URLs are offered below in chronological order:</p> <ul> <li>Dr. Randal Koene \u2014 https://youtu.be/HdADrlY_MLk</li> <li>Dr. Kenneth Hayworth \u2014 https://www.youtube.com/watch?v=yD1mivVKRrs</li> <li>Prof. Tony Zador \u2014 https://youtu.be/z_yhpj9LYQA</li> <li>Dr. Adam Marblestone \u2014 https://youtu.be/gjYif3OSOkU</li> <li>Dr. Shawn Mikula \u2014 https://youtu.be/Zb0d-YdG3u0</li> </ul>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/","title":"The Stream of Consciousness and Personal Identity","text":"<p>Keith Wiley Board, Carboncopies.org; Fellow, The Brain Preservation Foundation kwiley@keithwiley.com Aug. 10, 2019  </p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#abstract","title":"Abstract","text":"<p>This article marks the five-year anniversary of the publication of my book, A Taxonomy and Metaphysics of Mind-Uploading, and is loosely a celebration of the past five years. I first discuss the challenges of discovering and debating metaphysical truths. I then tackle an argument against discontinuous mind uploading, such as via scan-and-copy, based on the claim that it fails to preserve a purported temporal stream of consciousness, thereby losing the original metaphysical personal identity and invoking a replacement identity in the upload. This article investigates the stream of consciousness claim from several angles and concludes that it is not only unsubstantiated in theory, but also incompatible with real-world accounts of how people treat one another in existing medical cases that should, by all accounts, destroy the stream of consciousness. As an alternative, this article suggests that personal identity is better characterized by a person\u2019s memories in the synchronic specious present, with no requirement of diachronic psychological or phenomenal properties.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#introduction","title":"Introduction","text":"<p>This article loosely coincides with the five-year anniversary of the publication of my book, A Taxonomy and Metaphysics of Mind-Uploading, in which I present a wide range of thought experiments about mind uploading and then convey my preferred model of identity, commonly known as branching identity. After publication of the book, I published a paper in the Journal of Consciousness Studies [Wiley &amp; Koene 2016], coauthored with my long-time colleague, the neuroscientist Randal Koene. Dr. Koene is the founder of Carboncopies.org, which promotes philosophy and neuroscience of mind uploading. Randal further introduced me to Kenneth Hayworth, co-founder and president of The Brain Preservation Foundation, where I have written about next generation techniques for preserving brains that go far beyond the cryogenic and plastinated methods developed in the twentieth century [McIntyre and Fahy 2015]. I have greatly enjoyed presenting my ideas about the nature of metaphysical personal identity, with emphasis on its application to mind uploading and the underappreciated theory of branching identity [Cerullo 2015, Wiley 2014]. Regardless of if or when mind uploading ever becomes practical, it nevertheless provides an excellent sandbox for testing concepts of consciousness and identity.</p> <p>Personal identity is a challenging topic to tackle with any intent of objective truth discovery. Metaphysical truths (if there are such things) are more difficult to pin down than physical truths because much of metaphysics is not amenable to empirical physical experimentation. Karl Popper initially gave us our nearly universal reliance on falsifiability as the demarcation criterion separating science from metaphysics\u2014and from supernatural or religious beliefs for that matter [Popper 1962]. If a theory offers the notion of its own falsification by empirical experiment, even if that falsification has not yet been produced, then the theory is scientific, so explained Popper. Otherwise, the theory resides in philosophy, metaphysics or faith. Thomas Kuhn, however, questioned whether empirical methods can offer us objective tools of reality discovery, since we can\u2019t help but interpret observations from the vantage point of our preexisting models of reality. If two people hold different models to begin with, then even unvarnished reality laid bare before their very eyes may not convince them who is right. Kuhn called this problem incommensurability [Kuhn 1962]. Not to jump too far ahead, but people often fail to convince one another of their preferred models of personal identity with respect to mind uploading because all conclusions are interpreted as supporting each person\u2019s preexisting model.</p> <p>Assuming Kuhn left us any hope of forward progress, then once in the realm of metaphysics, Popper\u2019s falsification demarcation leaves us initially rudderless in weighing philosophical and metaphysical theories; it merely demarcates the scientific questions from the nonscientific ones. This is the question of metaphysical epistemology: how should we separate good metaphysical theories from bad ones to determine metaphysical truth? Popper believed that philosophy proceeds by the production of conjectures which are subjected to as many refutations as may be conceived. Conjectures that withstand this gauntlet become canon. We see this practice regularly in philosophical debates in the form of thought experiments, in which philosophical proposals are subjected to whatever criticism the proponent or broader community can devise. I personally proceed by seeking and driving out paradoxes and circular arguments in my metaphysical ponderings. Given my strong leaning toward honoring first person perspectives regarding consciousness, I see immediate paradoxes in proposals where people or uploads are regarded in ways that contradict their first-person points of view, or in scenarios in which multiple people with essentially identical points of view are nevertheless externally assigned differing identity labels. We will see another example in this article in which the neurological underpinnings of any identity threshold to a stream of consciousness are incompatible with real world medical cases. Discovered paradoxes are, to me, one of the strongest warnings of a poor metaphysical theory, and this approach has led me to some stark disagreements with others concerning the nature of metaphysical identity, primarily in my advocacy for branching identity. Consequently, explaining this theory of identity has become the bulk of my contribution to mind uploading philosophy, if there is such a thing.</p> <p>Given metaphysics\u2019 lack of empirical experiments, as the physical sciences offer us, we are often led by our intuitions to locations on the philosophical landscape which we subsequently perceive as rather obvious conclusions, even as others are drawn by their own intuitions to different hills on the same landscape. Philosophers, both professional and otherwise, often come across in their writing as positively confounded\u2014practically incredulous\u2014that anyone could disagree with their concluded model of reality. I\u2019m likely similarly guilty, as this article may bear out. It is perplexing that the following three statements should seemingly all be true:</p> <ul> <li>Metaphysics is unsolvable with the same rigor as the physical sciences, as Popper specifically demarcated.</li> <li>Most of us hold strong convictions concerning our positions on metaphysical questions.</li> <li>Our convictions are frequently incompatible with the convictions of others.</li> </ul> <p>From these three observations, we may conclude that either some people are right and others are profoundly wrong on matters of metaphysics, or alternatively, we are all wrong about the very nature of metaphysics to feel that it contains genuine truths\u2014or falsehoods\u2014in the first place. Others have noted this problem about metaphysics before, namely that we each hold prior assumptions about reality that influence where our intuition ultimately leads us [Dainton &amp; Bayne 2005]. Richard H. Wiley emphasizes the role of noise at every step along the way in matters of both personal truth discovery and conveyance of one\u2019s understanding of truth to others [Wiley, R. 2015]. Such pervasive noise not only confounds our search, but renders it essentially impossible for two people to ever truly perfectly understand one another. One possible explanation for how the three incompatible circumstances above come into being is indicated by Kuhn\u2019s incommensurability: we are all constantly judging one another\u2019s hypotheses from different vantage points that are not as objective as we would hope. Another explanation is that our conviction about our individual philosophies originates not from methodical and logical induction, which both Hume and Popper rejected anyway, but from evolutionary forces, which produce methods of mental world modeling under no requirement to align with external truths, only with survival and reproduction.</p> <p>Despite the recognized challenges in discovering\u2014or arguably in choosing\u2014metaphysical truths, we engage in it anyway. We all build mental models of the world, including those aspects of the world that are not physical and not empirically approachable, such as our own and others\u2019 minds (aka theory of mind). Starting with my book, I have spent the last five years attempting to sharpen the exposition of my particular bag of ideas on the nature of the mind and personal identity, namely concerning branching identity. This article is, to some extent, a celebration of the effects of the book\u2019s acceptance on my life over the last five years, of the intellectual colleagues I have met, and of any small public recognition that I or my ideas may have gained.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#the-stream-of-consciousness","title":"The stream of consciousness","text":"<p>In this article, I discuss a common argument against spatially and/or temporally discontinuous procedures for mind uploading based on their apparent failure to preserve a proposed metaphysical phenomenon frequently described as a stream of consciousness (SoC). If a mind uploading procedure is deemed to lose track of this diachronic (aka across time) stream, then this theory judges the outcome as a death of the original identity with some new identity invoked as a replacement. This new identity is often referred to as a copy in popular vernacular, and in a disparaging way: to be a copy is judged an undesirable fate and indicates a failure to survive the procedure.</p> <p>At first glance, we might assume that the SoC refers to the stream of waking thoughts of which we are specifically aware, if for no better reason than that that is precisely how the term was originally introduced by William James [James 1890]. It is his term after all, so he should get first call as to its meaning. But forbidding a breakage in that sort of stream, out of concern for loss of identity, is immediately confounded by examples such as sleep, fainting, general anesthesia, etc., sometimes known as the bridge problem. Clearly, that stream breaks on a regular basis without concern that identity is constantly lost and invoked anew, or at least without concern that such a model of identity is in any way disturbing.</p> <p>Despite the term\u2019s unambiguous original intent, stream of consciousness proponents (SCPs) generally respond to counterexamples such as sleep by either seeking a bridging criterion to handle gaps or by redefining the SoC to represent a different concept deemed likely to persist across gaps in waking consciousness: any and all psychological traits, no matter how deeply subconscious or indirect in their causal influence upon our aware experiences. Furthermore, such an abstract stream is widely admitted to arise from some basal neural activity such that we may focus our examination not on intangible mental streams but on physical neural activity. The recast claim is that, should we break this foundational stream of neural activity, obviously breaking its associated mental features as a result, then the purported SoC will also break (which is not a particularly contentious observation), and that the apparent consequence is that metaphysical identity vanishes for good (this is the contentious claim). Similarly, should the neural activity restart at a later time, with all its previous mental features reestablished, the argument claims that the original identity does not reappear or continue, as would otherwise occur after presumably weaker gaps, such as sleep. Rather, the original identity remains permanently lost, while a new identity is invoked in its place. This is the bridge problem again, which I discuss below. Since this outcome is often characterized as a form of death with replacement by a different person, such mind uploading procedures are generally judged as a lack of survival and consequently as an undesirable outcome. Dainton and Bayne solve the bridge problem by focusing on the potential for a persistent stream of conscious experience, even if unrealized in actuality [Dainton &amp; Bayne 2005]. On the other hand, I conceive of identity in a radically different way than Dainton and Bayne, focusing not on a diachronic experiential stream, potential or otherwise, but rather on a speciously present (aka synchronic) memory of oneself as a person with a cohesive identity.</p> <p>Although SCPs frequently argue against discontinuous mind uploading, they often accept the notion of mind uploading in principle, but insist upon a procedure that on some analysis is entrusted to preserve this stream. For example, consider the two classic mind uploading procedures known as scan-and-copy and gradual in-place replacement. In scan-and-copy, a statically preserved brain (cryogenic or plastinated) is sectioned into two dimensional slices, with each slice independently imaged, the overall three dimensional structure (aka the connectome) inferred from those slice images, the brain recreated either in simulation or as a physical artifact, and finally restarted. We are making impressive inroads on every aspect of this procedure and it may evolve from hypothetical thought experiment to practical viability within some foreseeable future. As described, scan-and-copy is discontinuous in four ways:</p> <ul> <li>Spatially: the upload is constructed in a new location relative to the brain.</li> <li>Materially: the upload is fully constructed from new matter before neural processing resumes.</li> <li>Temporally: neural activity enters stasis for some time period before later restarting in the upload.</li> <li>Functionally: neural activity comes to a global cessation and then restarts from scratch.</li> </ul> <p>SCPs generally reject scan-and-copy for apparently breaking the diachronic conscious stream due to one or more of the four discontinuities listed above, thereby destroying the original identity and somehow invoking a new identity in the upload. On the other hand, gradual in-place replacement mind uploading, in which each neuron is steadily replaced within the head by a microscopic artificial neural prosthetic (a procedure that is essentially impossible by even the dreamiest technology at the current time), is often proposed as a method that successfully preserves one\u2019s SoC and associated personal identity. Gradual in-place replacement exhibits none of the four discontinuities described above. Although the upload\u2019s substrate is not the same as the brain, and therefore spatial translation and material replacement occur, these changes are not discontinuous. Likewise, although at an earlier time processing occurs in the brain and at a later time it occurs in the upload, the change is not discontinuous but rather piecemeal, for whatever benefit that may ostensibly offer.</p> <p>Other hypothetical procedures are discontinuous on some subset of the four discontinuities listed. For example, cryonics is temporally and functionally discontinuous but spatially and materially continuous, since it involves reviving the original brain, while instantaneous teleportation involving only transmitted pattern information, but utilizing new matter, is the opposite of cryonics: temporally and functionally continuous but spatially and materially discontinuous. Teleportation involving a matter beam of some sort is only spatially discontinuous. The whole point of my JoCS paper with Koene, unambiguously titled The Fallacy of Favoring Gradual Replacement Mind Uploading Over Scan-and-Copy, is to thoroughly dispel the popular position that gradual replacement should be seen metaphysically favorably from the ongoing debate about mind uploading, i.e., to show that it is an irrational preference upon careful analysis. I urge critical readers to read it in full of course.</p> <p>This article considers the SoC claim against discontinuous mind uploading from two approaches. First, I discuss the related proposal that spatial continuity is of importance on the claim that successful preservation of the purported SoC should hinge on body (or at least brain) spatial continuity. I then explore the popular feature of the SoC characterized as its apparent reliance on a never-ending dynamic metaphysical process (cognition) that arises from an underlying never-ending dynamic neurological process (neural firing activity).</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#spatial-continuity","title":"Spatial continuity","text":"<p>One argument that appeals to a certain intuition for why personal identity fails to preserve in a discontinuous mind uploading scenario involves a violation of spatial continuity. How does identity undergo a discontinuous transfer through space from inside a person\u2019s head to the upload\u2019s new brain or computer [Corabi &amp; Schneider 2012]? It is as though some people visualize their identity as a literal homunculus, physically residing inside their head, that must travel across the room the way a physical bird flies through the air, ultimately landing in whatever physical system will instantiate the uploaded brain scan data so as to preserve (aka transfer) the person\u2019s identity from one location to another. Since it is unclear how such literal spatial travel of this identity object could be accomplished in a discontinuous procedure, the procedure is rejected as a failure to preserve identity. I don\u2019t intend this description to sound sarcastic. It is a genuine attempt on my part to comprehend the proposed claim. Contrarily, I don\u2019t believe metaphysical identities have physical properties in the first place, including the property of spatial location, so the entire concept of transferring identity from a brain to an upload\u2019s new substrate feels like a category error to me. My book goes into great detail on this issue.</p> <p>Below, I address this concern of spatial transfer via an argument I have not considered before, based on discrepancies between our visual experience of our location and our true location. But first, both my book and my JoCS paper with Koene have already challenged the spatial-continuity argument based on the flawed expectation that gradual in-place replacement mind uploading (which, recall, SCPs often accept to preserve identity) would not itself involve discontinuous spatial translation of these same psychological traits. Gradual replacement absolutely does involve discontinuous spatial translation, despite widespread misunderstanding to the contrary. The error is in overlooking the fact that if we replace each neuron with a microscopic prosthetic device that resides nearby, then when the prosthetic eventually disconnects the neuron, leaving it to die, and attaches itself in the neuron\u2019s place to take over the neuron\u2019s role, the neuron\u2019s nonphysical functional operation (and all its metaphysical attachments) will\u2014if one buys the spatial properties of abstractions in the first place\u2014suddenly discontinuously jump over to the prosthetic. The prosthetic does not cohabitate with the neuron after all, as no two physical entities ever can, of course. The prosthetic is generally assumed to reside next to its host neuron, a distance on the order of tens to hundreds of microns. Astoundingly, over the span of a procedure involving a hundred billion neurons, this discontinuous spatial translation of neural function accumulates tens to hundreds of kilometers of discontinuous translation of neurological, psychological and metaphysical traits\u2014it\u2019s just math, as they say. This is still in reference to a fully-awake, gradual in-place replacement uploading procedure, widely touted by its proponents for its solution to some imposed need to maintain spatial continuity between a brain and its upload infrastructure. Yet it utterly fails to achieve that very goal.</p> <p>One response to this clarification that gradual in-place replacement uploading also involves spatial discontinuities could be to simply dismiss distances of a few microns as unimportant and somehow capable of preserving identity, but what rationale would justify such an exception? What feature of metaphysics would suggest dismissing small physical distances as metaphysically unimportant but maintain that larger distances have profound effects? As I have argued elsewhere, it is suspiciously convenient to prescribe that we should overlook translations short enough to escape our daily awareness (microns), yet that we should assign great metaphysical significance to translations on the scale of our daily experience, such as from a brain to a computer across a room. Would aliens considerably smaller or larger than us assign such an arbitrary threshold differently?</p> <p>Another response to in-place uploading\u2019s inherent spatial discontinuities is to simply abandon the terminology of, and requirement for, continuous spatial translation entirely and pivot to a completely different concept: a requirement for piecemeal replacement as opposed to whole parcel replacement, in the vein of the infamous Ship of Theseus or Grandfather\u2019s Axe thought experiments. But Koene and I already argued that it is fallacious to believe that gradual replacement is more identity-preserving than scan-and-copy in our paper. With that argument thoroughly addressed (and we believe adequately refuted), the most likely next response is to require the preservation of a dynamic neurological process that is not permitted to cease. Note the significant change in topic here, as we now focus entirely on pure function and no longer on form or matter or space. Perhaps metaphysics should handle function differently than it handles form. This feels like unfair goal-post moving, but I will persist. The claim is that continuous neural activity preserves a continuous cognitive experience along with its continuous SoC and persistent identity. That claim is not too contentious actually, for surely anyone will agree that ceasing neural function also ceases cognitive experiences and metaphysical phenomena. The contention concerns the proper metaphysical interpretation should the physical process be restarted at a later time, either in the original substrate or in a new system that implements the same function. Should the restarted neural process be considered the same process from before, or a new process? Should the cognitive experience and SoC be labeled a continued prior experience, or a brand new one? Should the identity of the person in question be labeled an awakened survivor, or a de novo replacement? These questions are where disagreement occurs.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#identity-relative-to-visual-and-spatial-continuity","title":"Identity relative to visual and spatial continuity","text":"<p>One point of evidence of our identity\u2019s resilience to apparent spatial dislocations comes from our capacity to maintain our identity when experiencing seemingly discontinuous, if perhaps discombobulating, experiences of change in location, such as when awakening after being moved while asleep, or when donning virtual reality goggles and experiencing a spontaneous relocation to a virtual location. Both examples yield the experience of discontinuous relocation, yet are never labeled as identity-erasure risks. Furthermore, we don\u2019t have to be aware of relocations to maintain our identity since we could be moved while asleep to an identical room. So our evolving mental states need never incorporate the fact of a dormant relocation. Likewise, we are never accused of vanishing forever and suddenly being replaced just because we put on VR goggles and experience illusory discontinuous relocation.</p> <p>So identity has no dependence on awareness (sleep) or experience (VR) of continuous location. While these examples don\u2019t necessarily disprove a dependence of identity on spatial continuity, they do suggest that identity may preserve across discontinuous physical relocations. At the very least, our identity can\u2019t possibly rely on our awareness of our spatial continuity since our identity is clearly permitted to survive the experience of discontinuous spatial translation. Consequently, even if there is an underlying physical-to-metaphysical connection that renders identity dependent on spatial continuity, that connection must operate independent of our awareness. Although our awareness of purported properties of our identity need not be a requirement, we should be careful about the risk of introducing superfluous, unfalsifiable, unverifiable metaphysical traits. If a proposed feature of identity, such as spatial continuity, is claimed to hold true despite a complete lack of any causal effect it could have upon our intimate personal experiences, then how is that claim any different from a total absence of the proposed extraneous feature in the first place? Occam\u2019s Razor urges us to jettison claims of this sort in the interests of parsimony. The only stream that appears to be relevant to our identity is our phenomenological sense of ourselves as we consume environmental stimuli in combination with our memories (and all related cognitive aspects).</p> <p>The likely response to our visual experience is that the critical dependency is not on our visual stream but rather on the physical and spatial continuity of our bodies regardless of our awareness of that continuity (sleep) or any illusory experience to the contrary (VR). So an experience of discontinuous location (awakening after being moved or entering VR) is dismissed as noncritical to identity, while our physical location, which may not have any effect whatsoever on our experience when asleep, as explained above, is somehow deemed critical. It is frustrating that a form of continuity with direct impact on our conscious experience, such as our visual sense of location, is demonstrably irrelevant to our identity, while another form of continuity, such as spatial continuity, which does not necessarily have a causal relation to our experience, and therefore seems definitively superfluous, is frequently assigned grandiose preeminence to our identity. This reasoning seems precisely backwards to me.</p> <p>The proposal, then, is that identity has nothing to do with visual stimuli (surely to the relief of blind people), but is utterly dependent on the spatial continuity of the body, a continuity of which we need not even be aware. Let us call this theory the awareness-independent-spatial-continuity-dependence property (AISCD or \u201cacid\u201d for ease) of metaphysical personal identity. This proposed AISCD feature of identity is then taken to be of paramount importance despite the lack of a tight connection between physical continuity and our conscious visual experience. What is the justification for AISCD? Why not simply discard it?</p> <p>How should we tie metaphysical identity to AISCD? The examples above suggest that conscious awareness of our spatial continuity is totally unimportant to our identity; our identity survives breakages in that experience, both if we move but have no knowledge of it (sleep) and if we only seem to move but don\u2019t (VR). Consequently, it is unclear why AISCD should be a reasonable proposal. AISCD requires assigning an as-yet completely undiscovered physical property of the universe that seemingly ties our brain\u2019s location, and its smooth continuous movement, to continuous mental function, and then on to unbroken metaphysical identity, and furthermore in ways seemingly totally disconnected from our experiences and awareness. If one is going to propose that identity has dependencies far beyond our conscious experience, then the nature of such a metaphysical property must be established. What aspect of mental function requires physical continuity? What physical law precludes pausing an information-processing function for a while and resuming it at a later time, or even resuming it in some other substrate in another location? Remember, gradual in-place replacement suffers precisely the same continuity problems. It just does so at the microscopic level of neurons, escaping our ordinary experience, instead of at the level of the entire brain where we can immediately perceive the spatial disconnect involved. It is a mere oversight that this fact of spatial discontinuity in gradual replacement has been completely missed by most people in the past. Yet many people are comfortable assigning gradual replacement an identity preservation status.</p> <p>I have argued that the dependence of identity on spatial continuity is weaker than generally assumed, but is there any particular reason to favor either position: requiring or dismissing spatial continuity, or is it even odds? Occam\u2019s Razor gives us the reason. Extraneous, superfluous features of a model of reality, whose presence, even if true, would have no causal implications and would be empirically undetectable and unfalsifiable, are best jettisoned from our model entirely. At the least, surely the burden of proof lies with the proponent of such acausal superfluous traits.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#the-memory-basis-for-identity","title":"The memory basis for identity","text":"<p>Consider the following question: How are you confident of your identity relative to past \u201cversions of yourself\u201d, such as yourself from:</p> <ul> <li>five minutes ago.</li> <li>before you went to sleep.</li> <li>before you fainted.</li> <li>before you suffered a concussion, grand mal seizure, stroke, or other neurological trauma.</li> <li>before you underwent general anesthesia.</li> <li>before you underwent medically induced hypothermia to protect your brain during a cardiac emergency.</li> <li>before you suffered rapid frigid drowning in which you fell in a freezing cold lake, drowned, remained submerged for an hour, were taken to the hospital, confirmed to have essentially no pulse and absolutely no brain activity, and then finally revived.</li> <li>before undergoing some as-yet-speculative long-term preservation or stasis, such as hibernation or cryonics.</li> </ul> <p>The situations shown above are known as the bridge problem: If our identity depends on a continuous SoC, then how does it bridge gaps in that stream? Clearly, the original terminology of requiring preservation of the SoC to preserve identity was imprecise from the beginning, on the realization that even SCPs generally acknowledge that it is their own persistent identity that awakens each morning. Dainton and Bayne solve the bridge problem by disposing of psychological continuity (memories and other cognitive traits) in favor of what they call phenomenal continuity, a stream of experience [Dainton &amp; Bayne 2005]. They then solve bridging by naming an identity as that which has the capability for continuous experience even if, in actuality, gaps occur. I disagree with aspects of Dainton and Bayne\u2019s thesis in that I characterize identity as our experience of our memories and other cognitive aspects in the specious present amalgamated with any new sensory stimuli. They propose hypothetical scenarios in which a SoC is separated from a stream of psychological memories and then they conclude that it is blatantly obvious that identity follows the stream of phenomenal experience. But to me it is equally clear in their scenarios that identity goes with the memories instead! Somehow, they did not foresee such disagreement in their original writing since they present their conclusion as practically beyond dispute. I discussed this phenomenon of philosophers talking past one another in the introduction. Nevertheless, I find their bridging solution to be reasonable: identity consists of a persistent potential across a gap even if not fully realized. Where we disagree is the nature of that potential: a stream of conscious experience versus a speciously present experience of memories spanning the gap.</p> <p>Assuming we continue to pursue the more popular SoC claim, consisting of a never-ending stream of experience, not Dainton and Bayne\u2019s recast potential for such experience, then we will see below that such a claim is highly problematic. SCPs usually handle this challenge by leaving the SoC claim behind and moving on to other arguments, such as spatial continuity or continuous neural activity. But then why not open on those terms and abandon the SoC claim once and for all?</p> <p>One response to the questions shown above is that we exclusively identify ourselves by the phenomenological experience (i.e., experience in the moment) of our memories of our lives. Namely, there is explicitly not any significance to some never-ending SoC, only to our awareness and experience of our memories at any instant in time. Obviously, such awareness and experience can wax and wane without loss of identity, as illustrated by the fact that we generally judge identity to be preserved across gaps (e.g., sleep). There is a similar thought experiment put forward by Philip Gosse in the nineteenth century, and then again by Bertrund Russell in the twentieth, asking how we know God did not create the universe a few seconds ago with our memories artificially created de novo (Russell\u2019s version doesn\u2019t involve God, but the proposal is the same). The answer is that we cannot know that, precisely because our memories are the sole indicator of our confidence in reality, including our confidence in our own identity. It would seem that our momentary memories\u2014our instantaneous experience of ourselves and the world\u2014are the exclusive indicator of our phenomenological consciousness and identity for all intents and purposes. It just isn\u2019t clear why we should bother adding any additional features beyond our speciously-present (synchronic) conscious experience of our memories.</p> <p>Ironically, the patients most susceptible to claims of unpreserved identity are not futuristic science-fiction mind uploads or clones, but rather real-world patients for whom neurological damage has unwoven the contiguous memories that would underlie their lifelong identity, such as from stroke or dementia, or damage that prevents the formation of new memories, i.e., anterograde amnesia (thereby wrecking the connective experience between the present and past), or damage that obliterates existing memories that would lay the bedrock of their deeper identity, i.e., retrograde amnesia. These are the people, if anyone, best argued as having lost their metaphysical personal identity, despite preserving their original brains and bodies.</p> <p>It is worth briefly remarking that SCPs must presumably reject cryonics, not necessarily in terms of any practical plausibility (a grave question I don\u2019t address in abundance here), but in terms of any hope of metaphysical preservation of identity. If a viable form of cryonic preservation and revival were ever developed, the SoC community should brand revived patients as dead originals replaced with newly invoked identities. After all, cryonic preservation surely satisfies their criteria of a broken SoC since no dynamic neurological process persists during stasis. Yet in virtually every way imaginable, a revived cryonics patient has undergone a physical process and mental experience almost indistinguishable from general anesthesia or medically induced hypothermia. Why should we hold such a strange dissonance between these procedures instead of bringing them into alignment, either by rejecting the identity of millions of actual surgical patients, or by accepting the identity of ostensible cryonics patients? But to accept the identity of revived cryonics patients undermines the claim that never-ending process is important. Dainton and Bayne\u2019s solution to cryonics is obvious and reasonable: cryonics patients maintain the capability for consciousness and experience, and in so doing, bridge their identity across stasis. But proponents of a true persistent stream face a conundrum in cryonics.</p> <p>Certain medical cases actually do appear to involve a reduction in a patient\u2019s identity, in that to external observers such patients appear altered in personal aspect. It can seem like some or all of the original person has been lost, while at least a little bit of some newly invoked person has taken residence in their place. Examples include strokes, dementia, and some specific examples from the medical literature in which neurological damage radically alters personality, such as the famous Phineas Gage, and a few patients whose brain tumors produce strange personality changes. However, in these real-world cases, no one is ever truly regarded as a doppelg\u00e4nger. We just don\u2019t treat people that way. That said, a committed SCP might argue that identity loss in such cases results from metaphysical damage (whatever that would entail) to their SoC, but it is just as easily argued that any alteration to identity in such cases results from the loss of connective cognitive traits (memories) that would have otherwise tied their phenomenological consciousness in the present to their memories of their past.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#the-neural-threshold-of-the-stream-of-consciousness","title":"The neural threshold of the stream of consciousness","text":"<p>Another common response to the scenarios presented in the list above is that in none of those scenarios does neural activity truly cease. During a fainting spell, or while under general anesthesia, underlying neural activity and associated SoC are argued to have been maintained above some apparent minimum threshold capable of preserving identity. This response comes up repeatedly in debates, so scrutinizing it is central to this article. We are clearly not considering Willam James\u2019 original coinage of the SoC, as explained at the beginning, but rather this other concept involving some never-ending dynamic neurological process. This counterclaim that some basal dynamic process is preserved is problematic however, in two different ways.</p> <p>The first response is to simply understand rapid frigid drowning in greater detail [Hilmo et. al. 2014]. People offering the counterargument of basal neural activity must simply not understand what rapid frigid drowning actually involves, or else they would realize the suspension of disbelief that they are proposing. On one hand, some people actually take their expectation of rapid frigid drowning too far, mistakenly believing that these medical cases are real-world proofs-of-concept of cryonics, on the assumption that these patients have frozen solid and later revived. That is not true. A human body submerged in freezing water contains too much thermal mass, starting from far too high a temperature of 37C degrees, to freeze solid in an hour. In the most extreme cases to date, rapid frigid drowning victims have survived descents to body temperatures around 13.0 to 13.7C degrees [Gilbert et al. 2000, MSN 2014].</p> <p>At first glance, the acknowledgement of a warm body might seem like a concession to the claim that neural activity could survive. After all, these patients did not truly undergo cryogenic preservation or later revival. Perhaps cooled to only the balmy temperature of a chilly autumn day, one might initially assume that the brain continues enough interneural signal propagation to keep the hallowed SoC tenuously suspended above the chasm of annihilation. However, this conclusion is not supported by the medical facts. In such patients there truly is no measurable neural activity. Admittedly, at 13C degrees, metabolism still occurs at a molecular level. Nevertheless there is no neurological activity. Action potentials do not propagate along axons and dendrites at 13C degrees. Neurotransmitters do not meaningfully traverse synapses since such behavior is causally associated with action potentials, much less do such neurotransmitters trigger new action potentials in downstream neurons. There is no neural information processing, cognitive thought, or conscious experience. To the contrary, the temperature at which the brain effectively goes mute is much warmer, closer to 21C degrees [Lomber et. al. 1999]. This is well established by multiple experiments involving a medical procedure known as medically induced hypothermia, in which a patient\u2019s temperature is intentionally lowered, often following a cardiac emergency, specifically as a neuroprotective measure to prevent brain atrophy [Hemmen &amp; Lyden 2007, Mizrahi et. al. 1989, Percy et. al. 2009]. The fact that rapid frigid drowning indicates real-world cases in which patients have not been treated as doppelg\u00e4ngers following their ordeals clearly demonstrates that the SoC claim is incompatible with our general concept of reality. Dainton and Bayne are right to solve bridging with an unrealized potential that spans the gap as opposed to continuing to insist that at some inscrutable level, no gap occurs in the first place. I just think they built the wrong bridge in their reliance on experience instead of memories.</p> <p>Yet, admittedly, despite the medical facts of rapid frigid drowning, the SoC argument remains possible in the strictest logical sense, if nevertheless untenable in any reasonable sense. For example, it could be argued\u2014I am unsure how\u2014that the brain of a rapid frigid drowning patient is mysteriously preserving just barely enough neural activity and cognition to string the SoC along on a metaphysical spider\u2019s thread. Perhaps our brain scan equipment cannot detect such diminished neural activity at our current technological level. This proposal is all but implausible, but let\u2019s briefly explore it anyway.</p> <p>Let us assume that the proposed SoC does exist and is critical to identity. It must be underlied by some correlate of neurological activity, a point clearly not in dispute since SCPs are arguing that the brain\u2019s neurological function was not sufficiently diminished in any of the examples shown on the list. We are then faced with the following remarkable conclusion: there must be some physical threshold of neural activity, with its associated metaphysical threshold of SoC, below which a revived patient should be branded a doppelg\u00e4nger. It was explained above that existing medical cases of rapid frigid drowning have achieved approximately 13C degrees body temperature. Given that in such cases, it has never been seriously proposed that these patients awaken as identity replacements, we may conclude that 13C degrees has already been deemed metaphysically safe for our identity. Perhaps the temperature at which neural activity becomes so muted that the critical SoC suddenly breaks forever is 12C degrees. This extended argument strains credulity now that it has been demonstrated that real-world 13C degree patients exhibit no neural activity, but I will persevere.</p> <p>The claim then, is that if we were to revive a patient from 12C degrees (or whatever threshold is ultimately discovered) we should brand them a metaphysical copy. They need not display any outward cognitive deviation to earn this fate. Their memories and personality could survive. Everything about them could indicate to an observer that they survived, yet the claim is that we should label them as a mental duplicate merely for having dropped below the predetermined 12C degree mark and its apparent consciousness stream threshold.</p> <p>To be clear, we are not speculating on the possibility that a person undergoes genuine neurological damage at some colder temperature. We are allowed to assume healthy revival because that is precisely the scenario SCPs argue against. They claim that a seemingly cognitively successful, but discontinuously achieved, upload, with all his or her memories and personality intact, is nevertheless a metaphysical identity copy anyway.</p> <p>The question is, would we ever actually regard a patient in the described way? Given such a medical revival, would any SCP ever actually point at a patient and say, \u201cI saw her medical chart. She was below 12C degrees, so she\u2019s a copy.\u201d I am not talking about exploiting philosophical abstractions for arbitrary legal advantages. A greedy heir could ask a judge to legally label an upload as a copy to manipulate the laws of inheritance, but that is not a metaphysical question; that is just exploitation of the law for financial gain. The question is whether such an heir would really believe such an accusation. Real-world cases of rapid frigid drowning suggest that such beliefs are extremely rare. More to the point, what would a SCP conclude about their own identity were they the patient? Would they dismiss their own conviction about who they feel they are? What if they didn\u2019t know the facts of their circumstances and therefore couldn\u2019t formulate their identity on knowledge of how they came to be (this comes up again below)?</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#experimental-confirmation-of-the-stream-of-consciousness","title":"Experimental confirmation of the stream of consciousness","text":"<p>There is a remaining question: How will we ever determine the qualifying threshold of neural activity that indicates the invisible threshold of the SoC breakage toward the ultimate threshold of identity-loss-with-replacement-invocation? If we could do this, we could then use a neural activity monitor to assign identity judgments and labels to patients. This car accident victim is an original, but that flu patient is a copy, according to their brain scans. In theory, we should be able to determine the neural threshold of the SoC by associating it with one of two possible correlates:</p> <ol> <li>If we could detect the proposed SoC with some metaphysical SoC machine, and detect any breakage in that stream, then we could confirm a person as a metaphysical original or copy and determine the associated neural activity threshold from a brain scan.</li> <li>Alternatively, if we could detect that someone is a metaphysical copy via some sort of psychological test, then we would know there is a consciousness stream breakage somewhere in the person\u2019s brain scan data history and we could take the lowest recorded neural activity as our threshold.</li> </ol> <p>It is important to note that neither of these proposed approaches is even theoretically possible within physics (for the first approach above) or existing psychology (for the second approach). We have no concept of a machine that could, with regard to option one above, detect the maintenance or breakage of the hypothesized SoC (or measure its metaphysical strength, whatever that might mean), if for no better reason than that such a stream\u2019s very existence remains entirely speculative. Likewise, with regard to option two above, since the basis of the debate is that a person need not exhibit any psychological indications of their identity copy status, it is essentially defined away that any psychological test could ever reveal a person as a copy or confirm them as an original. Consequently, this entire task is totally unapproachable by science since it concerns exclusively metaphysical features which, by the SCPs\u2019 own description, are not physically discernible. This is the very definition of unfalsifiability.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#practical-application-of-stream-of-consciousness-identity","title":"Practical application of stream of consciousness identity","text":"<p>Assume that the threshold of neural activity associated with an identity status flip from preservation to loss-with-replacement is determined. Given that neural activity is easily correlated with temperature, we could conceivably use temperature to make identity determinations and judgments. Hospitals could include a stream-of-consciousness-verification test when unconscious patients are brought into the ER. Let\u2019s say it has been determined that 12C degrees is the critical threshold in question. Two rapid frigid drowning patients arrive at the hospital, Alice and Bob. Alice is revived, but from below 12C degrees. She is branded a copy for the rest of her life. Alice herself, being a strong believer in the SoC claim, accepts her fate as a copy and folds this realization into her sense of her own identity, believing that her memories from before the accident are actually fallaciously those of a completely different person and that she was born when she awoke after the accident. Bob, however, arrived at the hospital with a temperature of 13C degrees, much like real-world patients for whom no fictional speculation is required. Bob is clearly granted the status of preserved identity, consistent with contemporary medical cases. Alice and Bob proceed to live their lives for many decades, interacting with numerous people who regard Alice as a copy and Bob as a preserved identity. Only toward the end of their lives does someone investigate their old medical records and discover to their amazement that both measurements were wrong! Alice never actually descended to 12C degrees in the first place. There was an error in the original measurement and she only descended to 13C degrees. Meanwhile, Bob\u2019s temperature measurement was also wrong. He dipped to 12C degrees that fateful day. So Alice was never a copy in the first place, yet everyone believed she was, including herself! And Bob was a copy the whole time, yet not one person ever realized it or regarded him as a copy, including himself.</p> <p>I see two ways to handle the scenario above, and neither bodes well for the SoC claim. (1) We could still hold the SoC claim, believing that it indicates our true identity, or (2) we could conclude that the SoC is not necessarily real in the first place, or at least that a gap in that stream has no implications for our identity. Even if we choose the first option, we are left with the following troubling conclusion: as illustrated in the example of Alice and Bob, the SoC and its connection to identity, even if real in some abstract metaphysical sense, clearly has absolutely no objective impact on reality; it is utterly acausal. It is a completely arbitrary, unfalsifiable, and superfluous metaphysical property injected from the outside. It also has no external mental effects on our state of mind, only the circular effects we may choose to take aboard by believing the claim to begin with, mental effects just as easily obviated by simply choosing to break the circular reasoning and not believe the claim at the outset. If the claim only has any meaning by our choice to explicitly assign that meaning, then we can just as easily choose otherwise instead. I urge the second option, that the SoC claim is invalid to begin with.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#conclusion","title":"Conclusion","text":"<p>Note the gravity of the consequences if it turns out that SCPs are in error on the metaphysical question of identity. They reject the philosophical preservation of identity by the scan-and-copy procedure, which although currently theoretical, is likely to become technically feasible within some foreseeable future. At the same time, they accept the gradual in-place replacement procedure, which remains so technologically speculative as to be essentially impossible for all practical purposes. If gradual in-place replacement is even possible, it may take centuries longer to develop than scan-and-copy. Rejecting scan-and-copy destines anyone living during that interim period to death. Not to take such matters unnecessarily seriously, but misunderstanding this issue is a matter of life and death, other daily practical concerns notwithstanding [Hayworth 2010].</p> <p>It is my position that we should reject the SoC claim and any requirement such a purported metaphysical property would impose on mind uploading procedures. At the least, the onus rests on this claim\u2019s proponents to prove such a stream exists and to defend the claim that it would not survive certain mind uploading procedures.</p> <p>Lastly, there is the concern that this is all whimsically unimportant, or worse, an obtuse disregard for more prosaic societal concerns. Some people may find debates of this sort to be pedantic and even snobbish, given the justified concern that advanced futuristic technologies are likely to benefit wealthy elites long before they trickle down to the masses. Worse, some people may expect that such technologies are likely impossible and that such metaphysical navelgazing is an ivory tower distraction in a world of real problems and challenges. To that reaction I say the importance is not necessarily in determining the prospects of technological and medical marvels that reside far in the future, if ever. The more relevant issue, and the reason I have committed so much of my life to contemplating and writing about these questions, is that we profoundly desire the most accurate model possible of reality and understanding of the human condition. Ultimately, we want to understand ourselves as conscious beings in the universe and to understand the nature of our existence. That is the real issue here, at least for me.</p>"},{"location":"Resources/Writing/2019_StreamOfConsciousness/Post/#references","title":"References","text":"<p>Cerullo, M. A. (Feb 2015) Uploading and branching identity, Minds and Machines, Springer Netherlands, 25(1), pp. 17\u201336. doi: 10.1007/s1102. http://link.springer.com/article/10.1007%2Fs11023-014-9352-8</p> <p>Corabi, J. &amp; Schneider, S. (2012) The metaphysics of uploading, Journal of Consciousness Studies (JoCS), 19(7\u20138), pp. 26\u201344.</p> <p>Dainton B &amp; Bayne T. (2005) Consciousness as a guide to personal persistence, Australasian Journal of Philosophy, 83(4), pp. 549\u2013571.</p> <p>Gilbert M., Busund R., Skagseth A., Nilsen P. &amp; Solb\u00f8 J. (2000) Resuscitation from accidental hypothermia of 13.7\u00b0C with circulatory arrest, The Lancet, 355(9201), pp. 375\u2013376. doi:10.1016/S0140-6736(00)01021-7.</p> <p>Hayworth, K. (2010) Killed by Bad Philosophy, The Brain Preservation Foundation. http://www.brainpreservation.org/content-2/killed-bad-philosophy/</p> <p>Hemmen, T. &amp; Lyden P. (2007) Induced hypothermia for acute stroke, Stroke, 38(2), pp. 794\u2013799. doi: 10.1161/01.STR.0000247920.15708.fa</p> <p>Hilmo J., Naesheim, T. &amp; Gilbert M. (2014) \u201cNobody is dead until warm and dead\u201d: Prolonged resuscitation is warranted in arrested hypothermic victims also in remote areas \u2013 A retrospective study from northern Norway, Resuscitation, 85(9), pp. 1204\u20131211. doi: 10.1016/j.resuscitation.2014.04.029</p> <p>James, W. (1890) The Principles of Psychology, New York, NY: Henry Holt.</p> <p>Kuhn T. (1962) The Structure of Scientific Revolutions, Chicago: University of Chicago Press.</p> <p>McIntyre R. &amp; Fahy G. M. (2015) Aldehyde-stabilized cryopreservation, Cryobiology, 71, pp. 448\u2013458.</p> <p>Lomber. S, Payne B. &amp; Horel J. (1999) The cryoloop: an adaptable reversible cooling deactivation method for behavioral or electrophysiological assessment of neural function. Journal of Neuroscience Methods, 86(2), pp. 179\u201394.</p> <p>Mizrahi, E., Patel V., Crawford E., Coselli J. &amp; Hess K. (1989) Hypothermic-induced electrocerebral silence, prolonged circulatory arrest, and cerebral protection during cardiovascular surgery. Electroencephalography and clinical neurophysiology.</p> <p>MSN (2014), Girl survives 13 degree body temperature, MSN News. https://www.msn.com/en-gb/news/other/girl-survives-13-degree-body-temperature/ar-AAmSEW</p> <p>Percy, A., Widman S., Rizzo J., Tranquilli M. &amp; Elefteriades J. (2009) Deep hypothermic circulatory arrest in patients with high cognitive needs: full preservation of cognitive abilities, The Annals of thoracic surgery, 87(1), pp.117\u2013123. doi: 10.1016/j.athoracsur.2008.10.025</p> <p>Popper, K. (1962) Conjectures and Refutations, The Growth of Scientific Knowledge, Basic Books, New York.</p> <p>Wiley, K. B. (2014) A Taxonomy and Metaphysics of Mind-Uploading, Humanity+ Press and Alautun Press. https://www.amazon.com/dp/0692279849</p> <p>Wiley, K. B. &amp; Koene, R. A. (2016) The fallacy of favoring gradual replacement mind uploading over scan-and-copy, Journal of Consciousness Studies (JoCS), 23(3\u20134), pp. 212\u2013235. https://arxiv.org/abs/1504.06320</p> <p>Wiley R. H. (2015) Noise Matters: Evolution of Communication in Noise, Harvard University Press, Cambridge.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/","title":"Nondestructive Mind Uploading and the Stream of Consciousness","text":"<p>Keith Wiley Board, Carboncopies.org; Fellow, The Brain Preservation Foundation kwiley@keithwiley.com Sep. 4, 2023  </p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#abstract","title":"Abstract","text":"<p>A common interpretation of wakeful, nondestructive mind uploading is that the person with the postoperative original body exclusively persists the preoperative identity and that the person with the upload\u2019s body is some sort of identity copy. A frequent argument supporting this claim is that the preoperative person\u2019s stream of consciousness attaches exclusively to the postoperative person with the original body. By implication, the person with the upload\u2019s body spawns a new stream of consciousness, implying copy identity status. I argue that this is not the best metaphysical model of what happens in nondestructive uploading in the context of a stream of consciousness interpretation, and defend an alternative model which has generally received little attention in the existing literature: the branching identity model.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#introduction","title":"Introduction","text":"<p>A common interpretation of wakeful, nondestructive mind uploading (or cloning for that matter) is that the identity associated with the person prior to the procedure (the preoperative person) will persist exclusively in association with the original body following the procedure and that the identity associated with the upload will be that of a new person, commonly referred to as a copy, a pejorative term indicating a failure of the ostensible goal to enable the preoperative person to actually experience becoming an uploaded individual [Piccinini 2021]. One reasoning behind this interpretation is a presumed persistence of the preoperative stream of consciousness in its own brain and body, thereby failing to \u201ctransfer\u201d (scare quotes to be explained below) that stream to the upload\u2019s brain and body, thus with some other stream born anew in the upload, one with no particular experiential or identity relation to the original person [Shermer 2017]. This article argues that such an interpretation is not the most accurate one we can come up with, and advances an alternative interpretation, known as branching psychological identity, or just branching identity, as a more accurate metaphysical model of what happens to the stream of consciousness during wakeful, nondestructive mind uploading.</p> <p>I first present the claim being addressed, called the conjecture and defended by the general description. I then present the theory of identity it is predicated on, stream of consciousness identity. I then investigate whether such a theory of identity is a sensible foundation for analyzing thought experiments such as wakeful, nondestructive mind uploading. I do this by scrutinizing the stream of consciousness\u2019s external traits (primarily vision) and its internal traits (our diachronic stream of speciously experienced moments). I then consider another common defense of the stream of consciousness claim regarding mind uploading, namely the stream\u2019s purported continuity at various levels of diminution of neural activity, and show that such arguments are rarely well understood and stand at odds with contemporary medical practice and societal norms regarding real-world patients. I then present an alternative identity model, branching psychological identity, and show how it interprets wakeful, nondestructive mind uploading.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#the-conjecture","title":"The Conjecture","text":"<p>Let us begin by formally stating the conjecture under consideration:</p> <p>Conjecture: If I upload my mind in a wakeful and nondestructive manner, my preoperative personal identity will, in its eventual postoperative form, remain singularly associated with my original brain and body, while the upload will receive a newly spawned and unrelated postoperative identity. The upload\u2019s person will have no direct identity relation to my preoperative self, just a second set of my memories. In effect, it will be a new identity copy, not a preserved continuation of my original identity. Consequently, the procedure will fail to reassociate my preoperative identity with the upload\u2019s body, and most critically, will fail to enable my preoperative self to actually experience mind uploading with its implied postoperative perception of having a new body in a new location. Rather, I will simply continue to feel myself associated with the preoperative body throughout, and following, the procedure.</p> <p>The upload will emerge with his or her own convincing sense of self, and with an associated conscious experience of identity continuation. As such, they will feel that the procedure successfully achieved the goal of preserving the original identity as themselves and the goal of experiencing uploading. But none of that matters. They will simply be wrong, on the basis of third party judgments, namely that of the other postoperative person associated with the original body, who will of course be equally convinced of the procedure\u2019s failure. That other person\u2019s judgment will take precedence over the upload\u2019s judgment.</p> <p>Common phrasings of the conjecture often describe the goal of mind uploading as transferring a person\u2019s neurological, psychological, and metaphysical traits from a brain to an upload\u2019s physical receptacle [Corabi, J. &amp; Schneider 2012; Shermer 2017], some futuristic computer that implements neural functions, or perhaps an ostensible biological clone if the reader prefers such scenarios. I do not conceive of identity as a physical concept that subscribes to physical properties however, such as spatial location or movement. Abstract identity has various relations to physical objects, or is associated with, or instantiated by, physical objects, but is not physically contained inside those objects like a homunculus inside a box. I advocate that personal identity is more like a Platonic type than an occurrence or token [Wiley 2014; Walker 2014]. Types are nonspatial abstractions: patterns, information sequences, and in the case of identity, semantic labelings of other types, such as person patterns. We will see below that information is a type whereas physical instantiations of information are tokens, and that multiple tokens of a type don\u2019t imply multi-type existence (a violation of type properties), but merely multi-instantiation of a shared type. When identical tokens diverge in state, they then represent disparate types\u2014and the point of debate is whether the branching event itself affords an asymmetrical type-labeling to the tokens such that some carry subjective (or objective) priority over others (\u201coriginal\u201d vs. \u201ccopy\u201d). When identity is seen as a type, it then becomes a genuine category error to ponder how identity might be physically located somewhere (such as inside your head) or how it might fly through the air to a new physical location (such as an uploaded mind\u2019s computer or a clone\u2019s head). In this way, I don\u2019t ask whether or how mind uploading transfers a person\u2019s identity through space from a brain to an upload. Instead, I ask by what properties of identity and its relations to bodies it might become associated with, instantiated by, survived by, or preserved by an upload.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#general-description-of-the-conjecture","title":"General Description of the Conjecture","text":"<p>The conjecture is often defended in the following way, which I will call the general description:</p> <p>General Description: If you undergo wakeful, nondestructive mind uploading, you will not experience a shift in perspective over to the upload, i.e., your stream of consciousness will not \u201ctransfer\u201d to the upload. You will continue to view the world from the vantage point of your original location in your original body as if nothing happened. This implies that your preoperative identity will remain associated with your original body and the procedure has failed to grant you the experience (and the likely intended goal) of uploading. Likewise, whatever stream of conscious experience the upload might have is irrelevant to your preoperative experience, stuck in your original body from start to finish. As such, the upload is \u201cjust a copy\u201d and their perspective\u2014and opinion\u2014on the outcome can be dismissed as metaphysically irrelevant to your original goal of experiencing uploading.</p> <p>At the outset, this popular phrasing of the general description is problematic because it presupposes the conclusion of the question it purports to investigate, i.e., it is circular reasoning. The various applications of the word \u201cyou\u201d woven throughout the general description are the circular part. Such phrasing preassigns, by premise, the one bonafide identity to only one of the postoperative people (obviously to the original body and its associated identity, to the detriment of the upload). Not only is the word \u201cyou\u201d applied fallaciously to assign the identity to its destination in advance, it also a priori designates which person\u2019s experiential perspective will be introspected to interpret and judge the outcome of the procedure, namely the perspective associated with the original body and its visual experience via that body\u2019s eyes viewing into the world. The circular error is that if the entire point of objectively analyzing the conjecture is to seek an analytical conclusion, then we can\u2019t simply presuppose the very conclusion we are seeking; we can\u2019t assign \u201cyou\u201d and \u201cnew\u201d to the various postoperative people at the outset. And we can\u2019t use that presupposed labeling of \u201cyou\u201d and \u201cnew\u201d to cherry-pick whose perspective will serve as our evidence for analysis and whose we will dismiss as irrelevant \u201ccopy\u201d (the entire point of the philosophical inquiry). And we can\u2019t land at some conclusion implied by that evidence, which of course will comport with the conclusion we presupposed at the beginning, without having fully succumbed to circularity. And finally, we can\u2019t conclude from this entire (circular) line of reasoning that we have discovered or proven anything about the underlying truth of the matter. The entire thought experiment was a nonstarter based on the general description\u2019s ingrained biases and consequent circular phrasing. Here\u2019s what the general description might look like if we remove the circular logic but attempt to maintain its biased favoring of the original body over the upload:</p> <p>General Description: If you undergo wakeful, nondestructive mind uploading, you will not experience a shift in perspective over to the upload. The postoperative person experiencing a stream of consciousness from the perspective of the biological body (person B) will view the world from the vantage point of the original body in its original location, feeling that the procedure has failed, while the postoperative person experiencing a stream from the upload\u2019s body (person U) will view the world that way instead, feeling that the procedure has succeeded. We will grant priority to person B on the basis of his or her stream of conscious experience, while at the same time dismissing person U\u2019s stream of conscious experience as uninformative of the metaphysical fate of the preoperative person. Consequently, your preoperative identity will be judged to remain associated with the original body and we will conclude that the procedure has failed to grant your preoperative self the experience (and the likely intended goal) of uploading. Likewise, person U will be \u201cjust a copy\u201d and their perspective and opinion on the outcome can be dismissed as metaphysically irrelevant to the preoperative goal of experiencing uploading.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#why-might-the-conjecture-and-general-description-feel-intuitively-sensible","title":"Why might the conjecture and general description feel intuitively sensible?","text":"<p>The conjecture and the general description can feel initially tempting based on presumed properties of the stream of consciousness throughout the procedure. For example, one might assume that the person preceding a wakeful, nondestructive mind uploading procedure will surely have the experience of remaining stuck in their original body and that the procedure has failed to reassociate their identity with the upload. Imagining instead what it might feel like to emerge in the upload\u2019s body is frequently disregarded, and likewise, whatever conscious reflections the upload has about their experience are dismissed as those of an irrelevant copy. A copy of what exactly? Such details are rarely clarified in casual presentations of the topic, yet those details are critical to our analysis. For example, it is true that the physical instantiation of information patterns (the organization of neurons or computer components to implement a particular suite of neural pathways and firing patterns) has been recreated in a second physical instance, i.e., a second set of matter. We call this process and the result a physical copy (a new token), and there is nothing necessarily pejorative or judgmental in the usage of the term \u201ccopy\u201d to describe this physical process of producing a second token of the original pattern or type. But whether metaphysical features have been copied (aka duplicated) or merely doubly-instantiated in their Platonic type/token relationship is not immediately clear. One interpretation of Platonic realism is that no copying of the psychological person has occurred during the initial stage of physical double-instantiation; only a second tokenization has occurred. Admittedly, the double instantiation of the type will branch into two separate, singly instantiated types upon the subsequent divergence of any underlying physical (i.e., neurological) state, such as differing sensory stimuli from the two bodies\u2019 environments, which will propagate to psychological differences and then on to experiential and identity differences [Wiley 2014], but that branching event could be a metaphysical mitosis, i.e., a symmetrical division of a prior single entity into two subsequent entities of equivalent descent primacy from their progenitor. Mitosis is different from copying in that there is no original and no secondary, just two entities (persons in this case) where there was previously one. It isn\u2019t at all implicit that the metaphysical branching of one stream of consciousness into two has asymmetrical properties with regard to identity. This point is the thrust of this article. In the objections section at the end of this paper, I describe in greater detail how these properties of realism operate, both in the case of people and in some analogous information pattern examples.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#stream-of-consciousness-identity","title":"Stream of consciousness identity","text":"<p>Philosophy has produced several theories of identity and its relation to persons, minds, brains, and bodies. Major contenders include body identity [Parfit 1984] (identity is indicated by objects or conglomerations of matter, i.e., groups of atoms), nonbranching psychological identity [Parfit 1984] (identity is indicated by memories, popularly attributed to John Locke in the 17<sup>th</sup> century), closest continuer identity [Nozick 1981] (identity attaches to the later person deemed most similar to the earlier person), and spatio-temporal identity [Corabi, J. &amp; Schneider 2012; Searle 2005; Wiggins 1967] (identity is restricted to continuous movement through 4D spacetime in the same way as physical objects). There are many less popularized models as well, such as Bamford and Danaher\u2019s social identity [Bamford &amp; Danaher 2017]. The existing model closest to the stream of consciousness model underlying the general description is phenomenal identity, in which identity is indicated by diachronic streams of experience [Dainton 2004]. Careful analysis of most of these models shows them to be rather poor models of metaphysical personal identity. Some encounter paradoxes and contradictions of logical reasoning, as shown by Parfit. Others potentially commit serious category errors regarding the fundamental properties of abstract identity (e.g., spatio-temporal identity with its imposition of physical traits of location and movement, as explained earlier). These other models are not the thrust of the general description and its intended defense of the conjecture, so their implications for mind uploading will have to be left to other writings. This article only considers the validity of stream of consciousness identity, especially as it is sometimes used to defend the conjecture.</p> <p>The conjecture is generally presented in terms of stream of consciousness identity, a model of identity that assigns personal identity to purportedly persistent temporal streams of experience, i.e., consciousness, essentially Dainton\u2019s phenomenal continuity identity model [Dainton 2004, Dainton 2008]. Curiously, I find myself in near perfect disagreement with Dainton\u2019s conclusions regarding phenomenal and psychological continuity in his own VR-4 scenarios (i.e., Nozick\u2019s experience machines, or for lack of a lengthier description, the technology underlying the plot of the film Total Recall) [Dainton 2008]. To avoid disrupting this paper, I have pushed my counterargument to Dainton to the end. For now, let\u2019s plunge forward into stream of consciousness identity and its implications for wakeful, nondestructive mind uploading.</p> <p>So, a supporting argument of stream of consciousness identity will be based on an interpretation of the preoperative person\u2019s stream of consciousness and what it would (presumably) feel like to be that person, with their stream, throughout the procedure. We saw this in the general description. Let\u2019s explore whether the stream of consciousness has the necessary properties to support such an argument, hopefully in the less circular rephrasing offered above. We will first consider the external traits of experience (vision in particular) and then the internal traits (our diachronic stream of speciously experienced moments).</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#visual-experience","title":"Visual experience","text":"<p>It can feel initially obvious that a person would have the experience provided in the general description when undergoing mind uploading. And much of that feeling comes from a person\u2019s visual sense of their surroundings (we will consider the inner qualities of the stream of consciousness, not quite so dependent on external stimuli, in the next section). After all, when we conclude that our stream of consciousness would seem to remain associated with one body instead of the other on the basis of our personal streamed experience during the procedure, we are making an observation about where we seem to be and what body we seem to inhabit. The general description claims that throughout the procedure we will have the experience of remaining \u201cbehind the eyes\u201d of the original body instead of relocating to a spot behind the eyes of the upload. So let\u2019s explore that expectation.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#being-moved-while-asleep-and-entering-virtual-reality","title":"Being moved while asleep, and entering virtual reality","text":"<p>If the maintenance of our metaphysical personal identity depends on experiencing a smooth continuity of our sense of location from moment to moment, then what should we make of a situation in which we are moved from one room to another while we are asleep [Wiley 2019]? Parents transport their children around while asleep all the time. We readily fall asleep in various vehicles, and while the interior of the vehicle may be recognizable upon our awakening, we nevertheless immediately recognize that our broader location has changed. Such experiences do not conform to a smooth continuity of our perception of location from one conscious moment to the next. Rather, we experience an abrupt and discontinuous change in our very real location between consecutive conscious experiences, albeit separated in time. We never judge our personal identity to be replaced with a doppelganger as a result of being moved while asleep. Conclusion one: the preservation of personal identity cannot possibly depend on experiencing a smooth continuity of our perception of physical changes in our true location.</p> <p>Likewise, we might be moved to a location that is identical to our previous location. Consider a scenario in which we fall asleep in a fairly simplistic visual environment such as a room with minimal furnishings. If we are once again moved, we could very well awaken and fail to distinguish our surroundings from the prior room. We would consider our identity preserved in this scenario. So, when our senses mislead us into believing we haven\u2019t changed location when, in fact, we have, our identity survives the experience nonetheless. Conclusion two: the preservation of our identity cannot depend on our having an accurate perception or understanding of our location based on the presumed location evidenced by our senses.</p> <p>Perhaps sleep is the confounding factor. But if the maintenance of our personal identity depends on our wakefully experiencing a smooth continuity of location, then what happens when we put a virtual reality headset on and find our visual (and auditory) experience\u2014and our sense of location and perceived body\u2014instantly relocated to a new perceived location? Multiple psychological experiments conducted with virtual reality confirm that subjects can experience an inner sensation of alternate body ownership by mere visual portrayal. No one has ever considered these experiments to render the subjects\u2019 streams of consciousness as copies or put their personal identity at risk of metaphysical erasure [Slater et. al.]. Conclusion three: the preservation of our personal identity doesn\u2019t require a continuity of perceived location or body even while fully awake. Even though true teleportation is impossible, simulating the conscious experience of teleportation or of sudden new body ownership imparts no harm to our metaphysical identity.</p> <p>To summarize:</p> <ol> <li>Experiencing a discontinuous change in location when waking from sleep has no effect on identity.</li> <li>Experiencing a fallaciously continuous location when waking from sleep has no effect on identity.</li> <li>Experiencing a discontinuous change in location, or even of body, while awake has no effect on identity.</li> </ol> <p>Consequently, it would seem that identity has the following traits regarding external conscious experience:</p> <ul> <li>A visual experience of discontinuous location or body neither proves we have actually moved or changed bodies, nor puts our identity at risk.</li> <li>A visual experience of continuous location or body neither proves we haven\u2019t actually moved or changed body, nor ensures we are in the location or have the body about which we believe, yet does not put our identity at risk.</li> </ul> <p>Identity is demonstrably neither dependent on our awareness of continuous location or motion (sleep), nor on an experience of continuous location or motion (virtual reality). By all accounts, our visual experience of location, motion, and perceived body has no causal relation to our identity. So why should we consider descriptions of such continuous experiences during a mind uploading procedure as indicative of identity status, either in favor (as applied to the original body) or against (as applied to the upload)? Apparently, we can\u2019t easily rely on our conscious perception of our apparent location or body to support the assertion that the preoperative identity has a stronger association with the original body than the upload\u2019s body. This realization implies that the general description actually provides no information about the conjecture\u2019s validity.</p> <p>At first, this exploration of the implications of visual experience may seem irrelevant. After all, we don\u2019t consider blind people to exist in a state of contentious identity status. But vision is merely an easy example to analyze. Any of our senses can be subjected to the same sorts of experimental manipulations described above and we should expect to draw comparable conclusions about the nature of identity in those cases as well, such as touch, as exemplified by the infamous rubber hand illusion. The point is that we apparently cannot use our sensory-fed stream of conscious experience of our external surroundings (including sensory-inspired perceptions of our bodies) to inform us about our identity one way or another.</p> <p>In more startling terms, neither person resulting from a mind uploading procedure can determine via their sensory and perceptual experiences if they are the original body or the upload. Read that again:</p> <p>Anyone undergoing nondestructive mind uploading won\u2019t actually know which person they are when the procedure has concluded!</p> <p>This is because they cannot necessarily trust the evidence of their own senses, and that is the only evidence available to inform them of who they are. But if you can\u2019t necessarily know which postoperative person you are, how can you seize priority to judge the outcome just because it superficially appears that you are associated with the original body in the original location? You could be wrong and actually be the upload! We will return to this discovery later.</p> <p>The conjecture claims that the postoperative stream of consciousness associated with the original body is more clearly identified with the preoperative stream than the postoperative stream associated with the upload. What traits could grant such an asymmetrical relation between the two postoperative streams and the single preoperative stream? We have just seen that the external traits of the stream of consciousness\u2014the consumption of sensory stimuli\u2014cannot adequately anchor the preoperative stream to one postoperative stream over the other. The only remaining possibility for such asymmetrical anchoring would have to be some feature of the sequence of inner thoughts that anchors the preoperative single stream to only one of the postoperative streams, apparently the one associated with the original body if purveyors of the conjecture and its general description are to be believed. In the next section, I investigate whether the inner stream could even conceivably support such asymmetrical properties.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#inner-stream-of-consciousness","title":"Inner stream of consciousness","text":"<p>Perhaps it is the inner stream of consciousness that is believed to have such causal power in the general description. If so, then it is very poorly worded indeed, since it is often phrased as shown above, with a heavy reliance on your perception of location, which set of eyes you feel like you are located behind, and what body you appear to inhabit.</p> <p>But even if the general description is badly phrased (it\u2019s already horrendously circular in its simpler form) we can\u2019t very well rely on the inner stream of moment-to-moment thoughts to support the conjecture either, because common presentations of the general description all but concede that the upload experiences a comparably smooth inner stream anyway, no less subjectively continuous than the original brain experiences; that concession is built into the thought experiment. We see it in the common retort that \u201cThe upload would feel like she is the valid continuation of the preoperative person; she is just wrong in this conviction.\u201d Such phrasing is an upfront admission that both postoperative people experience streams of consciousness that are equally satisfying of their continuity with the preoperative person and associated identity. So then what is there left for a proponent of the conjecture to cling to in claiming that the preoperative stream has an asymmetrical relation to the two postoperative streams?</p> <p>Initially there is a single person, experiencing an unbranched stream of thoughts prior to the procedure: thought A to thought B to thought C, etc. At some point, the one person becomes two (or perhaps more) and the conscious stream branches, with the final singular thought C leading to two thoughts D\u25b4 and D\u25be in two brains, and then to E\u25b4 and E\u25be and so on. Neither of these inner streams of consciousness is necessarily any less continuous than the other. In fact, the only feature of their circumstances that could possibly render one inner stream less continuous than the other is the integration of discontinuous sensory information resulting from a seeming teleportation by the upload if and only if his environment is not identical to the environment of the original body\u2014a sensory discontinuity that is demonstrably unindicative of actual relocation and therefore uninformative of identity status (and likewise, a continuity of apparent environment doesn\u2019t prove a lack of relocation). All other aspects of the inner stream will be equally continuous between both postoperative people, and therefore there is no discontinuity that would support the conjecture.</p> <p>A likely counterargument is that while our visual experience is not indicative of our identity, either our set of atoms (classical body identity), or our closest continuer (see above), or the smooth spatial motion of our bodies (spatio-temporal identity) is the proper indicator we are seeking, as briefly introduced earlier. But the general description is an argument based entirely on stream of consciousness identity. None of those other models were relevant when the general description was first posed. Retorting with other models of identity when the general description starts flailing is just plain goal-post moving frankly. Those other models are explored in other writings, but such considerations cannot reasonably fit into this paper with its focus on the stream of consciousness argument. We are investigating the validity of the stream of consciousness claim because it is the basis of the general description\u2019s defense.</p> <p>The discussion has converged on a seemingly backwards pair of conclusions:</p> <ul> <li>The continuity of a trait with direct impact on our conscious thoughts and experience (our visual perception of our location, whether correct or confused) is demonstrably irrelevant to our actual identity.</li> <li>The continuity of a trait that has no first-order causal bearing on our experience (our true bodily location, which can only be influential through second-order sensory receptions), and about which we can actually hold false or misleading beliefs based on erroneous sensory and perceptual receptions, should be deemed of critical importance to indicating the truth of our identity.</li> </ul> <p>This logic, in both of its parts, feels perfectly backwards. The reasoning should have led to the exact opposite conclusion, with our visual perceptions and their direct impact on our actual conscious experience holding tremendous influence over our metaphysical personal identity, while our true location and any continuity or lack thereof, of which we can be dreadfully unaware, and the facts about which we can hold utterly incorrect beliefs, should be assigned no important role to our identity.</p> <p>But let\u2019s explore the stream of consciousness further. It was the basis of the general description and we aren\u2019t done with it yet. Perhaps there are other reasons to rely on the stream of consciousness to defend the conjecture. I explore such reasons next.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#unconscious-nondestructive-mind-uploading","title":"Unconscious nondestructive mind uploading","text":"<p>This next section presents an argument I have offered in previous work [Wiley 2019] but which bears repeating when analyzing the general description\u2019s defense of the conjecture. We can feel the stream of consciousness argument when we envision a wakeful, nondestructive mind uploading scenario. Curiously, much of the conjecture should fall away if we propose to perform the procedure in an unconscious state, i.e., some sort of stasis. The point isn\u2019t necessarily to prescribe how mind uploading should actually be performed. The point is to investigate the philosophical implications for identity in a situation that removes the general description\u2019s primary evidence. Considerations of unconscious uploading often begin with a recognition that we consider sleep and related states of diminished consciousness to be identity-preserving. Dainton preserves identity across unconscious gaps by focusing on the mere potential for continuity of experience [Dainton 2012], but the general description is not about a gap in consciousness; it is about a fully realized stream of consciousness throughout the procedure.</p> <p>Some readers maintain the original claim\u2014a failure to preserve identity following a mind uploading procedure\u2014even under the unconscious scenario. But if the phrasing of the general description of the conjecture is entirely about the stream of conscious experience during mind uploading, then why continue to view the conjecture favorably if that stream is removed from consideration? One response is to abandon the stream of consciousness argument and switch on other models of identity to defend the conjecture, such as body identity, closest continuer identity, or spatio-temporal identity. But then why offer a stream of consciousness defense in the first place?</p> <p>Another response to the unconscious scenario is to claim that the stream of consciousness was not adequately broken by the method of stasis employed during the procedure. Rather than focus on a wakeful stream of consciousness, the altered claim now addresses some deeper neurological level where sufficient brain activity is maintained to preserve a continual stream of subconsciousness, thereby supporting psychological states and some form of subdued experience, and associated metaphysical identity. The new claim is that the reason sleep or some other stasis preserves identity is that it is a sufficiently neurologically vibrant state that doesn\u2019t constitute full unconsciousness. Rather, the stream of consciousness persists in some form. This argument fails dramatically however, as shown next.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#levels-of-diminution-of-the-stream-of-consciousness","title":"Levels of diminution of the stream of consciousness","text":"<p>When presented with considerations of unconsciousness, the new argument is that the brain remains busy with neural activity in conventional states of otherwise diminished consciousness. The continued neural activity and its associated psychological effects are then presumed to support the stream of subconsciousness that supports personal identity.</p> <p>While sleep is admittedly a neurological state flourishing with activity, general anesthesia is not quite so unassailable. In this state, the brain descends to a considerably lower level of activity and it is a weaker claim that whatever conscious states are crucial to our identity remain untouched, but admittedly, there is brain activity during anesthesia as well. However, we can go much deeper.</p> <p>Two real-world scenarios inform us about this proposal of maintained neurology and its metaphysical effects [Wiley 2019]. The first is a medical scenario called medically induced hypothermia, in which a patient is intentionally chilled to a very low temperature to reduce brain damage during cardiac surgery [Hemmen &amp; Lyden 2007, Mizrahi et. al. 1989, Percy et. al. 2009]. The second scenario is called rapid frigid drowning and occurs when a person falls into a nearly-freezing lake or a snow drift and quickly drowns or asphyxiates [Hilmo et. al. 2014]. A few such patients have been found, upwards of an hour later, brought to a hospital, and then slowly warmed back up and revived.</p> <p>Medically induced hypothermia and rapid frigid drowning involve drops in body temperature to below 14\u00b0C [Gilbert et. al. 2000, MSN 2014]. A proponent of the conjecture might object that this does not freeze the brain and therefore does not undo the argument. However, the neurophysiological facts betray such reasoning. A brain does not have to freeze into a block of ice to bring neural activity to a halt. Neurons cease to operate below approximately 21\u00b0C [Lomber et. al. 1999]. The sub-14\u00b0C brain of the current record-holding patient was consequently devoid of any neural activity. Across her 86 billion neurons, not one action potential fired for a full hour. She did not have any form of conscious experience, subconscious or otherwise. And yet, we regard such patients as preserved identities despite having temporarily lost all their neurological and psychological support structures. This is a critical point so let\u2019s summarize it again. There are real-world medical patients who have violated the assumption that identity preservation requires ongoing neural activity at some subdued level, with its consequently continuous psychological and purportedly metaphysical effects. The fact that we do not label such patients as doppelgangers proves that we have already decided identity does not require a persistent stream of consciousness at any diminished level.</p> <p>One interpretation of such medical cases is that the brain\u2019s primary role in producing psychological and cognitive traits, and in generating consciousness, derives not from action potential propagation, but rather from some entirely different aspect of neurology, one that apparently remains intact at frigid temperatures so as to maintain the physical features required to support metaphysical identity. In this way, the conjecture would remain valid, with the purported stream of consciousness persisting in association with the original body even in the case of an unconscious nondestructive uploading scenario. This assertion is problematic however, and not only for its abject, unjustified rejection of the bedrock of modern neuroscience, a serious challenge in its own right. The problem is worse than that.</p> <p>First of all, this would be a clear case of special pleading. The entire motive for appealing to some heretofore unappreciated paradigm of neural and psychological behavior would merely be to justify a predetermined conclusion. A second problem is that by assuming that some other physiological trait of the brain is responsible for maintaining the stream of consciousness even at frigid temperatures, we must then determine what temperature threshold suffices to preserve that other neurophysiological feature. There must be some temperature below which the physical activity of the brain becomes insufficient to operationalize the underpinnings of psychology critical to the stream of consciousness and personal identity (as stated, action potentials are the dominant paradigm and are already vetted above). If the procedure is performed at a temperature below this apparent threshold, we can conclude that the identity of the person prior to the uploading procedure has no asymmetrical relation to the various people resulting from the procedure; the stream of consciousness was deemed lost in this case and can no longer support the conjecture. In fact, the proper judgment of an uploading procedure performed below the threshold would be that both people are copies and the preoperative person perished.</p> <p>One might counter, \u201cOkay, good, that\u2019s how we know when someone is preserved or a copy\u201d, but what physical test or scan during or after mind uploading will uncover this temperature threshold that corresponds to metaphysical identity erasure and replacement, if not that of the paradigmatic action potential? Or is there a psychological test, some sort of cognitive interview, that would confirm or deny that identity has been preserved? We already know the answers to these questions. The premise of the thought experiments render such tests impossible. We expect no difference in outward behavior between the various postoperative people. Both people will respond in kind to any psychological evaluation, and therefore no difference in metaphysical status can be revealed by such an interview. These assumptions are the basis of the thought experiments. Likewise, any brain scan, biological or computational in nature, will confirm continuation of the original neural functionality. So again, it is defined away that any test could reveal which person persists the preoperative identity. There is no such thing as a metaphysical identity detection device, not even in principle. This makes such an assertion unfalsifiable. It makes the entire notion of branding people with various identities based on external, third party judgments unfalsifiable.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#the-problem-with-intuitive-reasoning","title":"The problem with intuitive reasoning","text":"<p>Even after reading the analysis of the purported stream of consciousness and its implications for identity in a nondestructive uploading scenario, the reader might still feel a strong inclination toward the general description. The answer to this conundrum is remarkably straightforward: intuition and surface-level observations in the absence of deeper analysis simply don\u2019t lead us to the truth (or to the most logical conclusion) in many cases. In fact, intuition can lead us to explicitly bad conclusions. On matters concerning the nature of mind, consciousness and identity, we often find ourselves feeling certain conclusions with great conviction, but numerous psychological experiments reveal that we don\u2019t possess anywhere near the level of introspective precision that we believe we do. We fall for illusions with reckless abandon. Our susceptibility to logical paradoxes and riddles, our gullibility in the presence of magic tricks, our manipulation in the face to leading evidence, false memory implantation, general misleading by others, psychological features such as change blindness and inattentional blindness, our hard-wired inclination to pareidolia: all of these examples should make us highly suspicious of conclusions concerning matters of psychology that we draw by simply feeling our way through a scenario to see where we end up. Only careful analysis can inform us when our intuition has led us to quickly but poorly reasoned conclusions.</p> <p>Regarding nondestructive mind uploading, readers are asked to give genuine consideration to the experience as witnessed by the upload, with her own stream of consciousness connecting herself to the preoperative stream, and with her own external stimuli (visual scenery) influencing her internal sequence of thoughts. If psychological states are the salient indicator of metaphysical personal identity, then all other traits (material preservation, aka body identity; various secondary similarities to the prior person, aka closest continuer identity; smoothness of motion through space, aka spatio-temporal identity), are irrelevant despite our intuitive sense that they ought to play a role. Likewise, even within psychological identity, if we feel again intuitively led to lean on the psychological stream of consciousness as a crucial component of identity, we find no apparent asymmetrical relation between the preoperative stream and the various postoperative streams that could impart an asymmetrical fate for metaphysical personal identity. The upload\u2019s experience of her own stream is just as psychologically informative as the original brain\u2019s experience and therefore an investigation into each of their respective streams of consciousness offers no insight as to what happens to the preoperative identity during the procedure.</p> <p>If we abandon the conjecture as invalid, we need to replace it with some other model of identity, one with radically different implications for the outcome of mind uploading, even in nondestructive scenarios, and even in wakeful scenarios. I present one such theory next, called branching psychological identity.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#branching-psychological-identity","title":"Branching psychological identity","text":"<p>What we need is some other model of identity, one not susceptible to the problems encountered by all the other models presented earlier, including of course stream of consciousness identity. We need a model of identity that is capable of representing metaphysical personal identity across the full range of hypothetical scenarios that come up in thought experiments of this variety (a thorough taxonomy of such scenarios is presented in [Wiley 2014]). The best model to date is branching psychological identity [Demarest 2016; Wiley 2014; Cerullo 2014]. Others have conceived of the notion of course. Consider that Parfit went so far as to explicitly write a nonbranching criterion into his philosophy on the matter, so the idea has been around for quite a while. More recently, Graziano gives a decent description of branching identity [Graziano 2019]. Nevertheless, branching identity remains challenging for many people to accept, presumably because superficial intuitive ponderings tend to lead in other directions.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#the-arrow-of-time-and-personal-identity","title":"The arrow of time and personal identity","text":"<p>Branching identity is best comprehended by reflecting backward in time instead of projecting forward in time. Instead of inquiring what will happen to a person as they flow through a mind uploading procedure, it is better to ask how various people retroactively reflect on their past. Instead of asking who in the future will also be you, it is better to ask who from the past was also you. There are two good reasons for this past-directed framing. First, again illuminating a way in which our intuition leads us astray, is it not the case there is one true future lying ahead of us. Rather, there is no particular future, or perhaps there are infinite futures, not yet disambiguated with a winning future specified. We can see an admission of this fact in the way we phrase hypothetical and speculative questions and thought experiments. We don\u2019t ask what will happen, as least not if we are honest about the likelihood of outcomes. We ask what would happen if events transpired a particular way. Such phrasing openly admits that the future is speculative at best. On the other hand, there is precisely one past. There is no speculative or hypothetical ambiguity regarding the past. We only ask what might have hypothetically happened in the context of rolling back the clock to a time prior to the point of speculation and then once again considering hypothetical paths forward from that past time\u2019s future. When we ask what actually happened, it is simply a historical inquiry of past events.</p> <p>The second reason why our considerations of identity in the context of mind uploading should only be directed backward in time is the nature of psychological identity itself, with its underpinning of memories. Memories only point backward in time. If our identity is indicated by the uniqueness of our memories and the ways in which our memories govern our ongoing cognition, then everything of relevance to\u2014and with any causal implications for\u2014our identity lies in the past. If the properties of identity are exclusively past-oriented, then the causal effects on identity should likewise be exclusively past-oriented.</p> <p>The implication that identity is a one-way relation breaks the rules of a rigorous mathematical identity, which imposes transitivity challenges to personal identity that philosophers have raked over for centuries. Parfit solved this problem by disregarding the importance of a mathematical-like identity in favor of his Relation R. I prefer to maintain the terminology of personal identity because we are deeply inclined to regard persons in such a manner, but I suggest acknowledging that simple linguistic sloppiness is the problem. Personal identity simply isn\u2019t the same concept as a mathematical identity and the reuse of the term has caused no end of consternation. I recommend recasting metaphysical identity as this looser concept, a one-way relation between a given pair of people, directed from a later person to an earlier person. A person can metaphysically personally identify with a past person if the necessary psychological properties are in place (i.e., contiguous memories upon which to form a speciously present experience of self, aka a stream of consciousness).</p> <p>If we restrict our considerations to past-oriented inquiries, branching identity falls out of the system for free. We can readily arrive in a situation in which multiple concurrent people past-identify with the same past person. Asking which of those current (present) people the past person became is simply a badly formed question because of its future orientation. Despite our intuitive sense that such a question ought to be reasonable, perhaps it just isn\u2019t. The only valid question is which person from the past any given present person once was. Likewise, asking who you will become is essentially a nonsense question. Instead, ask how future people will feel in regard to you. If any of them feel they experienced or survived uploading as you, then congratulations.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#branching-identity-and-personal-survival","title":"Branching identity and personal survival","text":"<p>The ostensible goal of mind uploading is for the preoperative person to actually experience becoming an upload, and in a destructive scenario, a related goal is to survive mind uploading. Branching identity implies that this desired outcome actually does occur, regardless of whether the original body is destroyed. The original goal was satisfied by the upload\u2019s branch in either case. The problem with nondestructive uploading isn\u2019t that it fails to yield a stream of consciousness that experiences uploading. That problem never existed to begin with, and as such it was never necessary or appropriate to brand that postoperative person with a secondary or copy identity status. The problem is that nondestructive uploading has a second, likely unintended, effect: one branch doesn\u2019t satisfy the goal of experiencing uploading. That\u2019s the problem that requires addressing.</p> <p>The solution to this problem isn\u2019t philosophical or metaphysical and requires no such debate. It is a practical problem with a mechanical solution, depending on an individual\u2019s preferences and goals. If a particular subject\u2019s goal is that none of the postoperative people have the potentially disappointing past-oriented (i.e. remembered) experience that the procedure failed, then nondestructive uploading is a bad option for that person. People with that concern\u2014and only people with that concern\u2014should insist on undergoing destructive uploading, confident of their survival and genuine experience of continuation in the only other postoperative person involved, the upload. Other people might have other goals however, such as ensuring that at least one branch carries the preoperative person\u2019s conscious experience, and personal identity, onward in uploaded form, while otherwise permitting some other branch to continue a nonuploaded life\u2014with no asymmetrical interpretation of originality or identity status implied. For anyone who is comfortable with that outcome, nondestructive mind uploading simply isn\u2019t problematic to begin with.</p> <p>One might ask what happens if a subject\u2019s mechanical desires are not properly addressed (if a malevolent machine operator surreptitiously performs a nondestructive upload against the subject\u2019s will, or in the popular thought experiment of a malfunctioning teletransporter that inadvertently leaves the older body conscious by accident). The solution to this quandary isn\u2019t to tear down all of metaphysics and attempt to rebuild a new model of identity from scratch in the hopes of achieving a bias-free and paradox-free nonbranching model, which probably can\u2019t be accomplished anyway. The solution is to hold a nonparadoxical model in the first place (branching identity) and then simply acknowledge that the initial subject\u2019s mechanical preferences were not properly addressed, thereby yielding an undesired psychological outcome: a postoperative person with a disappointing perspective on his or her circumstances. At that point, it is a matter for the lawyers, not the philosophers.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#a-branching-description-of-wakeful-nondestructive-mind-uploading","title":"A branching description of wakeful, nondestructive mind uploading","text":"<p>The general description is a common way of imagining what nondestructive mind uploading would feel like. Although intuitively tempting at first glance, this article has argued that such reasoning is not the best depiction of what it would actually feel like to be uploaded. There are other ways to imagine the conscious experience of undergoing such a procedure, ways that are more aligned with branching identity. Others have given reasonably unbiased descriptions of branching identity as well [Graziano 2019], but let\u2019s go over it here.</p> <p>Branching identity asks us to reframe how we envision experiencing a nondestructive uploading procedure, even a wakeful procedure. We must reject our inclination to imagine projecting ourselves forward in time over the course of the procedure because, first of all, references to the future of our identity are a logical error within a memory theory of identity, second because we can\u2019t imagine experiencing or feeling the future anyway since experience only comingles the specious present with our memories of the past, and third, because it is confounding to attempt to imagine branching forward into multiple descendant streams of conscious experience, much less without imposing unjustified biases on our imaginings, even if the concept is logically reasonable. All we can imagine is our reflection on our past at any given moment in time. Hence, we should imagine the experience of uploading by reflecting on our recent memories at any given moment. At the branch point, we must imagine each of two streams of conscious experience in parallel as they reflect on their respective recent pasts, each with equal validity to the pre-branched stream.</p> <p>The pre-branch person remembers walking into the mind uploading office and then goes through a sequence of moment by moment memories, up to the branch point: entering the room, lying down on the scanner bed or donning the scanner helmet, and musing as the procedure begins. At the branch point, we must begin considering the perspectives of multiple unfolding streams of experience as they blend recent memories with specious perceptions. Neither of the postoperative people can feel the branch event occur of course; they won\u2019t know when it happens. The upload will feel his stream of consciousness consistently tethering him along the timeline. His sense of self will never feel at risk. At some moment during the procedure, the upload might experience a visual change in location. This sense of relocation might consist of his visual surroundings seemingly blinking to a new location. Alternatively, he might experience his visual surroundings obscuring and then clarifying in new surroundings. Alternatively, as illustrated above, the upload may not experience a visual relocation at all if the environment is designed that way. If the location does differ in appearance, we could describe this experience as a perception of teleportation, but we don\u2019t have to suffer such incredulous terminology. More prosaically, we could describe it as the experience of wearing a virtual reality headset during the procedure and, at some point, suddenly finding ourselves in a completely new visual environment. Clearly, the upload\u2019s sense of self, his identity, and his conviction about who he is, will be no more put at risk by this visual experience than any other depiction of virtual reality. The upload will then continue to experience his stream of consciousness unfolding as the procedure wraps up, he exits the machine, and the procedure is complete, with his ongoing experience now squarely located in the visual vantage point of some new physical location. As I have defended, he is, by no reasonable definition, any sort of \u201ccopy\u201d as a result of this stream of conscious experience. He simply is one continuation of the preoperative person.</p> <p>Of course, we can also consider the experience of the postoperative person associated with the original body, who will not necessarily (see below) experience a visual shift over the course of the procedure. But that person\u2019s experience is not particularly interesting because it was already embraced by the general description anyway. If the reader would object that the critical difference supporting the conjecture is that the upload experiences a visual shift while the original body does not, we have seen that we can easily contrive circumstances to explicitly confound such a biased conclusion. The upload\u2019s new body could be located in an environment that is visually indistinguishable from the brain-scanning location, while the original body, if wearing a virtual reality headset, could suddenly experience a new visual location partway through the procedure (if for no other reason than to conduct psycho-metaphysical experiments of this sort). In this way, we could give the upload a smooth visual experience and the original body a discombobulating sense of teleportation. Without branching identity, the same stream of consciousness argument presented in the general description should properly conclude that this scenario inverts the implications of the conjecture, granting the preoperative identity to the upload and branding the original body as the copy! But the better conclusion is to acknowledge that these incidental aspects of our visual sensory experience, and their impact on our smoothly flowing stream of consciousness and our sense of our bodily location, have no relevance to our identity in the first place, specifically because our stream of consciousness is irrelevant to our identity status.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#objections","title":"Objections","text":"<p>Various objections were raised by early reviewers of this paper. Instead of greatly expanding the introduction of the paper, which would have tediously prolonged our march toward the main discussion, I pushed an exploration of those objections to the end, here.</p> <p>One objection was that the newer physical token (person) has false memories and that such a distinction differentiates the two people into original and copy status. The new person remembers standing at the Grand Canyon with light from that scene entering her eyes and exciting opsin molecules to produce visual perception\u2014but the claim is that these memories are false. Her newer legs never stood on the red earth of the Grand Canyon and her newer eyes never absorbed photons from that scenery. But that claim obviously falls into full-blown body identity, which Parfit put to bed long ago. The position proposed by this article is that those memories are not, in fact, false. They are memories of conscious experiences that the metaphysical person truly did phenomenologically perceive. It doesn\u2019t matter which set of atoms was involved in the events recalled. Consider the weakness of this objection in the face of material turnover of our bodies. Namely, note that the opsin molecules that received light at the Grand Canyon are not possessed by either of the two people following the mind uploading procedure years later. They are not even possessed by the preoperative person moments before the procedure; the older body replaced them far in advance. This seems like a relevant fact if we are going to judge the two people\u2019s identities on such a basis. An argument over piecemeal replacement of the body and identity is better left to copious other writings. This paper specifically addressed the stream of consciousness argument, not some other claim, such as material preservation or piecemeal replacement, and suddenly pivoting in this fashion is, yet again, goal-post moving. If one wishes to make a piecemeal identity argument when analyzing mind uploading thought experiments, so be it, but the stream of consciousness argument nevertheless remains poorly motivated, as shown in this paper. For a thorough analysis of piecemeal replacement in the context of mind uploading, please see [Wiley 2016].</p> <p>Another early objection was that the characterization of a mitosis is incorrect because of admitted body identity disparities. But I think it is correct after all. The physical bodies correspond to labels of original and copy; one physical token is an older pattern-arrangement of atoms than the other token. But the psychological metaphysical properties involved (conscious reflection on one\u2019s memories as well as on the specious present), have undergone metaphysical mitosis with no notion of original and copy. This falls perfectly in line with Platonic realism, which both Walker and I have considered previously [Walker 2014, Wiley 2014]. Platonic types don\u2019t have \u201ccopies\u201d from one another because they don\u2019t live in a temporal stream whereby one exists prior to another. Types exist all at once and eternally, even if only a subset are instantiated at any given time by Platonic occurrences. One might object that a person doesn\u2019t exist until their type is truly instantiated (a more Aristotelian realism, in effect), but the abstraction of an unrealized person is acknowledged in our musings quite comfortably, such as when we contemplate historical counterfactuals, parallel universes, alternate timelines, etc. The people populating such \u201cwhat-if\u201d scenarios are existent but uninstantiated Platonic types and we find considerations of such persons to be fairly easy to accommodate.</p> <p>Consider the following example: How many \u201ccopies\u201d of Beethoven\u2019s Fifth Symphony exist? A hint to the answer is found in the phrasing of the question, which refers to the symphony in singular form. Read the question again more carefully: How many \u201ccopies\u201d of Beethoven\u2019s Fifth Symphony (singular!) exist? We have all but conceded the answer to the question in its phrasing; it is clearly a singular entity. Digging more deeply, the answer depends on what we are inquiring about. Are we asking how many physical recordings and/or manuscripts of the symphony exist? In that case, thousands exist, for those are occurrences, aka tokens, of the Beethoven\u2019s Fifth Platonic type (the information pattern encoding that particular symphony). But perhaps we are asking how many times the idea of arranging notes in that particular way exists, i.e., the Platonic type, the arrangement of notes that represents the information pattern of the symphony. That pattern exists precisely once. In fact, Platonic realism does not even allow the concept of multi-existence of a type. That\u2019s what a Platonic type is. When we make a new manuscript of the symphony by glancing back and forth between a manuscript and a blank page, recreating the ink in a new token, we utterly fail to duplicate the type. There are precisely the same number of conceptual patterns of the symphony before and after the copying process, and that number is always exactly one. We all but admit this in our phrasing of such matters; we refer to the fifth symphony in singular form all the time, such as when we say we are attending a performance (one occurrence) of the symphony (a singular type). We are perfectly comfortable with such phrasing.</p> <p>To restate, we are all fine with the notion that a symphony\u2019s type exists once yet can be instantiated by numerous tokens. Branching identity makes the exact same claim regarding the psychological traits of people. The pattern representing a person\u2019s mind and life memories up to a given point in time is a Platonic type, and as such, cannot exist twice by the rules of Platonic realism. A nondestructive uploading process initially yields two tokens of a single person type. They will of course diverge at some later time (perhaps almost immediately after the procedure, or perhaps much later if the process is performed under stasis), by the consumption of differing sensory stimuli and corresponding formation of differing memories. Such divergence will then represent two separate types (two minds with slightly different memories) each instantiated by a separate token, but with prior shared histories of diachronic evolution. This is how branching identity works. For a more thorough description of this model of personal identity, see my former work on the matter [Wiley 2014].</p> <p>I mentioned earlier that Dainton\u2019s phenomenological/psychological fission scenario leads me to the exact opposite conclusion that he himself draws from his proposed scenario. In essence, it is just as clear to me that identity follows the psychological stream in Dainton\u2019s phenomenological/psychological fission machine as it is clear to him that identity follows the phenomenological stream. He doesn\u2019t seem to even consider the possibility of my disagreement. His phrasing is that it is plainly obvious that all readers will immediately and completely agree with him\u2014and yet I do not. We seem to hold starkly different perspectives on what it would actually feel like to consciously experience one\u2019s available memories in the specious present following his described procedure, toward the goal of determining one\u2019s own identity at that later time. While Dainton leans heavily on descriptions of smooth phenomenal experience as the preserver of identity, even in the presence of total psychological annihilation, it seems equally clear to me that at some later time after his described experiment, the final owner of the original identity will be the person whose psychology informs themself that they are the original and not the invoked new psychology, with absolutely no associations to that past person, as per Dainton\u2019s own description. Phenomenal experience that erases all your memories is not identity-preserving, it is identity-obliterating. Dainton defends his position by observing that we consider ourselves to be the same people who experience our dreams despite a lack of strong psychological connectedness with our dream persons\u2014but we remember our dreams! Fresh phenomenal experience at that later time is what ties our later awakened identity back to the dream identity, namely a cohesive recollection of our dream and even a memory of the discombobulating experience of awakening, a discombobulation which he includes in his own descriptions. Without speciously present conscious reflection on the memory of that experience at some later time, his identity model no longer works. Once again, while Dainton is correct that phenomenal experience is a major player in identity preservation, he completely overlooks that it is our phenomenal experience of our memories, i.e., psychology, that is doing the identity-preserving work. If you have the phenomenology of recollecting a different set of memories, that remembering experience indicates a different identity at that later time.</p> <p>The explanation for how identity can reassociate with the psychology preserver in his VR-4 scenarios is similar to a Sorites paradox. While it might not be clear at each consecutive moment during his described psychology replacement that identity is steadily reassociating with the person who carries the psychological continuity instead of the phenomenal continuity, it can nevertheless be the case at some eventual later time following the completion of the procedure, that the identity now belongs to the psychology preserver, as would be indicated by the later speciously conscious experiences of those two people when they reflect on who they actually are. The one who will remember\u2014and feel and believe\u2014that they are the original person will be the one who preserved the psychology and explicitly not the one who preserved the moment-to-moment phenomenal experience in Dainton\u2019s scenario. It is an empty question to ask precisely which moment in time (i.e., which transient conscious moment in the smooth phenomenological stream) was the one where identity suddenly reassociated to the psychological stream, the same way it is empty to ask which grain of sand, the addition of which to a set of grains, transformed the set into a singular heap (the classic Sorites paradox example). The backward-in-time identity relation presented earlier further clarifies how the Sorites paradox operates in this case: only retrospective remembrances (i.e. the experience of reflecting on one\u2019s memories) can possibly be relevant to determining what happened to personal identity at the end of the procedure because memory (and our conscious experience thereof) only points to the past.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#conclusion","title":"Conclusion","text":"<p>I have offered a counterargument to the conjecture that wakeful, nondestructive mind uploading has the effect of preserving the preoperative identity with an association exclusively tied to the original brain and body, to the detriment of the upload\u2019s brain and body, and with the upload then receiving a newly spawned identity with no metaphysical attachments to the preoperative person, and thereby labeled a copy. The conjecture was defended via the general description of what it would feel like to experience such an uploading procedure, a description that presumes the stream of consciousness experienced by the original brain and body would attach asymmetrically to the two postoperative people, namely attaching to the original body and not the upload.</p> <p>The counterargument first investigated why the description characterizes such an experience as seemingly remaining stuck in the original body. It was determined that it is a person\u2019s sense of location, both relative to their surroundings, and relative to which pair of eyes they feel they are \u201cbehind\u201d, based on external stimuli such as vision, that indicates such apparent facts about one\u2019s location and bodily association. I then considered several examples by which one\u2019s sensory evidence can be misleading to such a degree that I ultimately concluded our sensory experience doesn\u2019t yield sufficiently reliable information about our actual location. This analysis led to the rather shocking realization that neither of the two people resulting from a mind uploading procedure can confidently determine whether they are associated with the original body or the upload\u2019s body!</p> <p>This left the only remaining property of a stream of consciousness that might be the property supporting the conjecture to be the inner sequence of thoughts running through one\u2019s mind, not the stream of external sensory perceptions and processing. But that inner stream was never properly in contention to begin with because common presentations of the general description concede that the upload will experience a comparable inner stream anyway, with the branching event offering no inner psychological or metaphysical traits that would seemingly grant priority to one branched stream over the other. External experience seems to be the only conceivable source of differentiation between the two streams of consciousness, and those were shown to be untrustworthy and uninformative to the point of complete irrelevance on the matter.</p> <p>I then explored a different way in which the stream of consciousness might be argued to persist in the original body, a purported maintenance of the stream\u2019s underlying psychological and yet deeper neurological support structures, argued to preserve a persistent metaphysical stream that remains consistently bound to the body in which it originated. But we saw that the neurological support structures involved can physically dwindle to such a degree (illustrated by real world medical cases, not philosophical thought experiments) that their support of the stream of consciousness\u2014which is itself purportedly supporting the preservation of identity\u2014necessarily ceases, thereby undermining the claim that a persistent stream of consciousness can be the reason to expect the preoperative singular identity to persist asymmetrically between the two resulting postoperative people, namely in favor of the original body.</p> <p>Finally, after dismissing the general description of experiencing wakeful, nondestructive mind uploading, which was used to support the conjecture based on a stream of consciousness identity model, and consequently after dismissing the conjecture itself, I then offered an alternative theory of personal identity, called branching psychological identity, and illustrated how that model would interpret such a scenario through the respective experiences of the various people involved at various points in time throughout the procedure. And we saw that according to such a model, with its strictly backward-in-time identity relation between pairs of considered people, all postoperative people, with their respective streams of consciousness and their bodies, will have equal primacy of metaphysical identity relative to the preoperative identity. To put it succinctly, everyone resulting from a mind uploading procedure has an equally visceral stream of conscious experience connecting them to the preoperative person, and therefore is equally metaphysically identified with the preoperative person. This is branching identity.</p>"},{"location":"Resources/Writing/2023_NondestructuveMU/Post/#references","title":"References","text":"<p>Bamford, S., &amp; Danaher, J. (2017) Transfer of Personality to a Synthetic Human (\u2018Mind Uploading\u2019) and the Social Construction of Identity, Journal of Consciousness Studies (JoCS), 24(11\u201312), pp. 6\u201330.</p> <p>Cerullo, M. (Feb 2015) Uploading and branching identity, Minds and Machines, Springer Netherlands, 25(1), pp. 17\u201336. doi: 10.1007/s1102.</p> <p>Corabi, J. &amp; Schneider, S. (2012) The metaphysics of uploading, Journal of Consciousness Studies (JoCS), 19(7\u20138), pp. 26\u201344.</p> <p>Dainton, B. (2004) The Self and the Phenomenal, Ratio, Blackwell Publishing Ltd. 2004, 17(4), pp. 365\u2013389.</p> <p>Dainton, B. (2008) The Phenomenal Self. Oxford University Press.</p> <p>Dainton, B. (2012) On Singularities and Simulations, Journal of Consciousness Studies (JoCS), 19(1\u20132), pp. 42\u201385.</p> <p>Demarest, H. (2016) Fission May Kill You (But not for the Reasons You Thought), Philosophy and Phenomenological Research, 93(3).</p> <p>Gilbert M., Busund R., Skagseth A., Nilsen P. &amp; Solb\u00bf J. (2000) Resuscitation from accidental hypothermia of 13.7\u00b0C with circulatory arrest, The Lancet, 355(9201), pp. 375\u2013376. doi:10.1016/S0140-6736(00)01021-7.</p> <p>Graziano, M. (2019). Rethinking Consciousness: A Scientific Theory of Subjective Experience, W. W. Norton &amp; Company.</p> <p>Hemmen, T. &amp; Lyden, P. (2007) Induced hypothermia for acute stroke, Stroke, 38(2), pp. 794\u2013799. doi: 10.1161/01.STR.0000247920.15708.fa</p> <p>Hilmo, J., Naesheim, T., &amp; Gilbert, M. (2014) \u201cNobody is dead until warm and dead\u201d: Prolonged resuscitation is warranted in arrested hypothermic victims also in remote areas \u2013 A retrospective study from northern Norway, Resuscitation, 85(9), pp. 1204\u20131211. doi: 10.1016/j.resuscitation.2014.04.029</p> <p>Lomber. S, Payne B. &amp; Horel J. (1999) The cryoloop: an adaptable reversible cooling deactivation method for behavioral or electrophysiological assessment of neural function. Journal of Neuroscience Methods, 86(2), pp. 179\u201394.</p> <p>Mizrahi, E., Patel, V., Crawford, E., Coselli, J., &amp; Hess K. (1989) Hypothermic-induced electrocerebral silence, prolonged circulatory arrest, and cerebral protection during cardiovascular surgery. Electroencephalography and clinical neurophysiology.</p> <p>MSN (2014), Girl survives 13 degree body temperature, MSN News. https://www.msn.com/en-gb/news/other/girl-survives-13-degree-body-temperature/ar-AAmSEW</p> <p>Nozick, R. (1981) Philosophical Explanations, Harvard University Press.</p> <p>Percy, A., Widman S., Rizzo J., Tranquilli M. &amp; Elefteriades J. (2009) Deep hypothermic circulatory arrest in patients with high cognitive needs: full preservation of cognitive abilities, The Annals of thoracic surgery, 87(1), pp. 117\u2013123. doi: 10.1016/j.athoracsur.2008.10.025</p> <p>Parfit, D. (1984) Reasons and Persons, Oxford University Press.</p> <p>Piccinini, G. (2021). The myth of mind uploading, The Mind-Technology Problem: Investigating Minds, Selves and 21<sup>st</sup> Century Artefacts, Hip\u2014lito, I., Clowes, R. &amp; G\u0160rtner K. (eds.), 125-144.</p> <p>Searle, J. (2005) Mind: A Brief Introduction, New York, Oxford University Press.</p> <p>Shermer, M. (2017) Who Are You? Scientific American. Jun 20; 317(1):73. doi: 10.1038/scientificamerican0717-73.</p> <p>Slater, M., Spanlang, B., Sanchez-Vives M. &amp; Blanke, O. (2010) First Person Experience of Body Transfer in Virtual Reality, PLOS ONE.</p> <p>Wiggins, D. (1967) Identity and Spatio-Temporal Continuity, Basil Blackwell, Oxford.</p> <p>Walker, M. (2014) Uploading and Personal Identity, in Intelligence Unbound: The Future of Uploaded and Machine Minds, Blackford, R. &amp; Broderick, D. (eds.), John Wiley &amp; Son, Inc.</p> <p>Wiley, K. B. (2014) A Taxonomy and Metaphysics of Mind-Uploading, Humanity+ Press and Alautun Press. https://www.amazon.com/dp/0692279849</p> <p>Wiley, K. B. and Koene, R. A. (2016) The Fallacy of Favoring Gradual Replacement Mind Uploading Over Scan-and-Copy. Journal of Consciousness Studies (JoCS), 23(3\u20134), pp. 212\u2013235.</p> <p>Wiley, K. B. (2019) The Stream of Consciousness and Personal Identity, SSRN: https://ssrn.com/abstract=3438285</p>"},{"location":"Sponsor/","title":"Sponsorship","text":""},{"location":"Sponsor/#about-us","title":"About Us","text":"<p>At Carboncopies Foundation, we are at the forefront of computational neuroscience, pioneering technologies and methodologies to reconstruct the brain from scanned data. Our goal is not only to advance our understanding of the brain but also to contribute to disease research, the development of biologically inspired AI, and potentially achieve full brain emulation.</p> <p>Sample biological neural network \"grown\" in our software platform</p> <p></p>"},{"location":"Sponsor/#why-support-us","title":"Why Support Us?","text":"<p>By sponsoring Carboncopies, you will be directly contributing to cutting-edge research that has the potential to revolutionize our understanding of the brain and its functions. Your support will provide us with the necessary compute power to process and analyze complex neural data, enabling breakthroughs in:</p> Disease ResearchBiologically Inspired AIBrain Emulation <p>In the future, our platform's focus on brain emulation could offer unprecedented insights into the mechanisms of neurological diseases. By enabling the creation of detailed and functional models of brain structures and functions, it could allow researchers to simulate disease processes within brain tissues and observe their effects on neural circuits. This capability has the potential to lead to improved diagnostic tools, facilitating earlier and more accurate identification of neurological conditions. Understanding the details of what's going on in brain tissue could help combat brain diseases by providing a clearer picture of disease mechanisms.  </p> <p>Additionally, the platform could aid in the development of new treatments by providing a virtual environment to test therapeutic interventions. This might significantly reduce the time and cost associated with clinical trials in the future.</p> <p>In the future, our platform's focus on brain emulation, informed by the brain's computational principles, could enable the development of AI systems that mimic human neural processes. This approach, known as neuromorphic engineering, could facilitate the creation of AI systems that are not only more efficient but also capable of learning and adapting in ways similar to biological brains. By leveraging insights from brain function and understanding detailed brain mechanisms, the platform could inform the development of advanced AI architectures. These architectures could process information akin to human cognition, leading to breakthroughs in adaptive learning and problem-solving capabilities.  </p> <p>The potential for human-AI interaction is immense, with biologically inspired AI systems capable of more natural and intuitive interactions with humans. This could lead to advancements in fields such as robotics, healthcare, and personalized assistants, where AI needs to understand and respond to human behavior and emotions.</p> <p>In the future, our platform's focus on brain emulation aims to achieve a comprehensive understanding of brain function by allowing researchers to explore how different regions of the brain interact and contribute to cognitive processes. By enabling the creation of detailed emulations of brain structures and observing brain tissue in action, it could offer unprecedented insights into human cognition and consciousness, potentially revolutionizing our understanding of the mind.  </p> <p>Emulating the brain through the platform could facilitate integration with other cutting-edge technologies, such as brain-computer interfaces and advanced neural prosthetics. This integration might lead to new therapeutic devices and technologies that restore or enhance brain function in the future.  </p> <p>Furthermore, brain emulation could open the door to future applications such as advanced neural prosthetics and novel brain-computer interfaces. These technologies have the potential to transform the lives of individuals with neurological disorders and injuries by restoring lost functions and improving quality of life in the future.</p> <p>Spike timing diagram generated by the platform</p> <p></p>"},{"location":"Sponsor/#collaborations","title":"Collaborations","text":"<p>We are proud to collaborate with a range of prestigious institutions and organizations on our research initiatives, including but not limited to:</p> <ul> <li>U.Penn</li> <li>U.Oxford</li> <li>U.Melbourne</li> <li>U.Nottingham (Horizon Center)</li> <li>Brain Preservation Foundation</li> <li>Foresight Institute</li> <li>Janelia Research</li> <li>Allen Brain Institute</li> <li>Max Planck Institute (Juelich, Germany)</li> <li>EBRAINS (Human Brain Project)</li> <li>MIT Media Lab</li> <li>UCSC</li> <li>UC Berkeley</li> <li>USC (&amp; Medical Center)</li> </ul> <p>and many more. </p> <p>Network topology of sample neural network in our platform</p> <p></p>"},{"location":"Sponsor/#how-your-sponsorship-helps","title":"How Your Sponsorship Helps","text":"<p>We are currently seeking sponsors to help us secure the compute power needed to drive our platform forward. With your support, we can:</p> <ul> <li>Enhance our computational capabilities to handle larger and more complex datasets.</li> <li>Accelerate the development and training of our neural reconstruction systems.</li> <li>Expand our research initiatives and collaborations with leading experts in the field.</li> </ul>"},{"location":"internal/","title":"Team Information - Internal","text":"<p>Dear Carboncopies Team!</p> <p>This page is the top page for useful (but not critically secret) information intended for Carboncopies Team members. We hope this is useful, but please let us know about possible improvements and any information you think should be added here. You can message us about it in the \"Carboncopies Core Team\" Google Space channel.</p>"},{"location":"internal/#carboncopies-connect","title":"Carboncopies Connect","text":"<p>Carboncopies Connect is both our newsletter and a repository for whole brain emulation related news, fun facts, helpful hints and tips for new team members, new papers or blog articles, new videos and other media worth knowing about, accomplishments within CCF projects, and more.</p> <p>As a CCF team member we would like you to think of Carboncopies Connect as a \"habit\", something that comes to mind immediately when you encouter or achieve anything that you think other people at Carboncopies (or our newsletter readers) would be interested in.</p> <p>Did you just finish something that contributes to our mission? Did you just make or come across something cool? Go ahead to the page linked here and use the embedded form to send it to Carboncopies Connect for editing and inclusion in a future issue of the Carboncopies Connect newsletter, on our social media, or in our video channels.</p> <p>Send to Carboncopies Connect</p>"},{"location":"internal/CarboncopiesConnect/","title":"Send to Carboncopies Connect","text":"<p>Carboncopies Connect is both our newsletter and a repository for whole brain emulation related news, fun facts, helpful hints and tips for new team members, new papers or blog articles, new videos and other media worth knowing about, accomplishments within CCF projects, and more.</p> <p>As a CCF team member we would like you to think of Carboncopies Connect as a \"habit\", something that comes to mind immediately when you encouter or achieve anything that you think other people at Carboncopies (or our newsletter readers) would be interested in.</p> <p>Did you just finish something that contributes to our mission? Did you just make or come across something cool? Go ahead to the page linked here and use the embedded form to send it to Carboncopies Connect for editing and inclusion in a future issue of the Carboncopies Connect newsletter, on our social media, or in our video channels.</p> <p>Some examples:</p> <ul> <li>You came across news of some interesting new development in neuroscience.</li> <li>You read an academic paper with an interesting brain data collection method,   modeling method, insights about cognition or consciousness.</li> <li>You saw an interesting video related to our field of work.</li> <li>You found a cool new tool that team members could benefit from.</li> <li>You discovered something related to working on CCF activities that you think   every new team member should know.</li> <li>There is a workshop, conference or talk that you think team members may be   interested in.</li> <li>There an output, development or insight from activities in one of the CCF   projects you're involved with that you'd like to share.</li> </ul> <p>Note: If you wish to submit content to Carboncopies Connect, but issues with cookies on the carboncopies.org site are interfering with your ability to use the embedded form, please click this link to go straight to the Google Form.</p> Loading\u2026"}]}